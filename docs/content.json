{"pages":[{"title":"","text":"关于我","link":"/about/index.html"}],"posts":[{"title":"Hash算法","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-hash.html 什么是HashHash 也称散列、哈希，对应的英文都是 Hash。基本原理就是把任意长度的输入，通过 Hash 算法变成固定长度的输出。这个映射的规则就是对应的 Hash 算法，而原始数据映射后的二进制串就是哈希值。活动开发中经常使用的 MD5 和 SHA 都是历史悠久的 Hash 算法。 12echo md5(&quot;嗨客网（www.haicoder.net）&quot;);// 输出结果：c039822701479838d74267c87495db39 在这个例子里，这是一个测试文案是原始值，c039822701479838d74267c87495db39 就是经过 hash 算法得到的 Hash 值。整个 Hash 算法的过程就是把原始任意长度的值空间，映射成固定长度的值空间的过程。 Hash的特点一个优秀的 hash 算法，需要什么样的要求呢？ 从 hash 值不可以反向推导出原始的数据，这个从上面 MD5 的例子里可以明确看到，经过映射后的数据和原始数据没有对应关系。 输入数据的微小变化会得到完全不同的 hash 值，相同的数据会得到相同的值 echo md5(&quot;嗨客网（www.haicoder.net）&quot;); 的输出结果：c039822701479838d74267c87495db39。echo md5(&quot;嗨客网（haicoder.net）&quot;); 的输出结果：45d3a6204814003ddd13d395ccd00d7d。可以看到我们只改了三个字母，但是整个得到的 hash 值产生了非常大的变化。 哈希算法的执行效率要高效，长的文本也能快速地计算出哈希值。 hash 算法的冲突概率要小由于 hash 的原理是将输入空间的值映射成 hash 空间内，而 hash 值的空间远小于输入的空间。根据抽屉原理，一定会存在不同的输入被映射成相同输出的情况。那么作为一个好的 hash 算法，就需要这种冲突的概率尽可能小。 Hash碰撞的解决方案前面提到了 hash 算法是一定会有冲突的，那么如果我们如果遇到了 hash 冲突需要解决的时候应该怎么处理呢？比较常用的算法是链地址法和开放地址法。 链地址法链表地址法是使用一个链表数组，来存储相应数据，当 hash 遇到冲突的时候依次添加到链表的后面进行处理，如下图： 链地址在处理的流程为：添加一个元素的时候，首先计算元素 key 的 hash 值，确定插入数组中的位置。如果当前位置下没有重复数据，则直接添加到当前位置。当遇到冲突的时候，添加到同一个 hash 值的元素后面，行成一个链表。 这个链表的特点是同一个链表上的 Hash 值相同。**Java** 的数据结构 HashMap 使用的就是这种方法来处理冲突，JDK1.8 中，针对链表上的数据超过 8 条的时候，使用了红黑树进行优化。 开放地址法开放地址法是指大小为 M 的数组保存 N 个键值对，其中 M &gt; N。我们需要依靠数组中的空位解决碰撞冲突。基于这种策略的所有方法被统称为 “开放地址” 哈希表。线性探测法，就是比较常用的一种 “开放地址” 哈希表的一种实现方式。线性探测法的核心思想是当冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。简单来说就是：一旦发生冲突，就去寻找下 一个空的散列表地址，只要散列表足够大，空的散列地址总能找到。 线性探测法的数学描述是：h(k, i) = (h(k, 0) + i) mod m，i 表示当前进行的是第几轮探查。i=1 时，即是探查 h(k, 0) 的下一个；i=2，即是再下一个。这个方法是简单地向下探查。mod m 表示：到达了表的底下之后，回到顶端从头开始。 对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，二次探测（Quadratic probing）和双重散列（Double hashing）。但是不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。 散列表的装载因子=填入表中的元素个数/散列表的长度。装载因子越大，说明冲突越多，性能越差。 案例链表法：假设散列长为 7，散列函数 H(K)=K mod 6，给定的关键字序列为 {20, 12, 23, 1, 19, 28, 7}，当使用链表法时，相应的数据结构如下图所示： 线性探测法：当使用线性探测法时，相应的数据结果如下图所示： 这里的两种算法的区别是在线性探测法遇到冲突时会将冲突数据放到下一个空的位置下面。 Hash应用在日常运营活动中，我们活动开发经常遇到的应用场景是信息加密、数据校验、负载均衡。下面分别对这三种应用场景进行讲解。 信息加密2011 年 CSDN 脱库事件，导致超过 600W 的用户的密码泄露，让人失望的是，CSDN 是明文存储用户的注册邮箱和密码的。作为用户的非常隐私的信息，最简单的保护措施就是对密码进行 hash 加密。在客户端对用户输入的密码进行 hash 运算，然后在服务端的数据库中保存用户密码的 hash 值。由于服务器端也没有存储密码的明文，所以目前很多网站也就不再有找回密码的功能了。 看到这里有些同学会觉得那么我们是不是对用户输入的密码进行一次 MD5 加密就可以了呢，这样就算恶意用户知道了 hash 值，也没有办法拿到用户的真实密码。假设用户的密码是 123456，经过一次 md5 以后得到的值是： 1e10adc3949ba59abbe56e057f20f883e 那么是不是使用了这个加密后的字符串来存密码就万无一失了呢，理想总是很丰满，而现实总是很骨感的。我们可以使用这个网站： 1https://www.cmd5.com/ 进行 MD5 破解，运行结果如下： 我们看到，我们通过加密后的字符串反解出了原始字符串，那么一般针对这种问题，我们的解决之道就是引入salt(加盐)，即利用特殊字符（盐）和用户的输入合在一起组成新的字符串进行加密。通过这样的方式，增加了反向查询的复杂度。但是这样的方式也不是万无一失，如果发生了盐被泄露的问题，就需要所有用到的地方来重置密码。 针对 salt 泄露的问题，其实还有一种解决办法，即使用 HMAC 进行加密（Hash-based Message Authentication Code）。这种算法的核心思路是加密使用的 key 是从服务器端获取的，每一个用户的是不一样的。如果发生了泄露，那么也就是这一个用户的会被泄露，不会影响到全局。 数据校验使用过 git 的同学都应该清楚，每次 git 提交后都有一个 commit id，比如: 15075586d67ca32a50fd46984fa30fdfe94d0e61f 就是一次 git commit 的结果，那么这个 id 是如何生成出来的呢？查阅了相关资料，使用如下代码可以进行查看： 1printf “commit %s0” $(git cat-file commit HEAD | wc -c); git cat-file commit HEAD 执行结果如下图所示： git 的 commit id 主要包括了以下几部分内容：Tree 哈希，parent 哈希、作者信息和本次提交的备注。针对这些信息进行 SHA-1 算法后得到值就是本次提交的 commit id。简单来讲，就是对于单次提交的头信息的一个校验和。 Linux kernel 开创者和 Git 的开发者——Linus 说，Git 使用了 sha1 并非是为了安全性，而是为了数据的完整性；它可以保证，在很多年后，你重新 checkout 某个 commit 时，一定是它多年前的当时的状态，完全一摸一样，完全值得信任。 但最新研究表明，理论上对其进行哈希碰撞（hash collision，不同的两块数据有相同的 hash 值）的攻击可以在2^51（2的51次方）左右的次数内实现。不过由于 commit id 是针对单个仓库里的，所以实际应用中我们可以认为如果两个文件的 SHA-1 值是相同的，那么它们确是完全相同的内容。 在数据校验方面的另一个应用场景就是版权的保护或者违禁信息的打击，比如某个小视频，第一个用户上传的时候，我们认为是版权所有者，计算一个 hash 值存下来。当第二个用户上传的时候，同样计算 hash 值，如果 hash 值一样的话，就算同一个文件。这种方案其实也给用户传播违禁文件提高了一些门槛，不是简单的换一个名字或者改一下后缀名就可以躲避掉打击了。（当然这种方式也是可以绕过的，图片的你随便改一下颜色，视频去掉一帧就又是完全不同的 hash 值了。） 负载均衡对于同一个客户端上的请求，尤其是已登录用户的请求，需要将其会话请求都路由到同一台机器，以保证数据的一致性，这可以借助哈希算法来实现，通过用户 ID 尾号对总机器数取模（取多少位可以根据机器数定），将结果值作为机器编号。 分布式缓存分布式缓存和其他机器或数据库的分布式不一样，因为每台机器存放的缓存数据不一致，每当缓存机器扩容时，需要对缓存存放机器进行重新索引（或者部分重新索引），这里应用到的也是哈希算法的思想。 唯一标识比如 URL 字段或者图片字段要求不能重复，这个时候就可以通过对相应字段值做 md5 处理，将数据统一为 32 位长度从数据库索引构建和查询角度效果更好，此外，还可以对文件之类的二进制数据做 md5 处理，作为唯一标识，这样判定重复文件的时候更快捷。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/hash%E7%AE%97%E6%B3%95/"},{"title":"MAC 终端优化","text":"最终效果： 进行以下步骤前先备份~/.zshrc。 一、安装 oh-my-zsh官网 https://ohmyz.sh/ 运行以下命令直接安装 1sh -c &quot;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; 二、安装 spaceship 主题官网 https://github.com/denysdovhan/spaceship-prompt 执行下方脚本直接安装 12git clone https://github.com/denysdovhan/spaceship-prompt.git &quot;$ZSH_CUSTOM/themes/spaceship-prompt&quot; --depth=1ln -s &quot;$ZSH_CUSTOM/themes/spaceship-prompt/spaceship.zsh-theme&quot; &quot;$ZSH_CUSTOM/themes/spaceship.zsh-theme&quot; 脚本运行之后，需要在 ~/.zshrc 中找到相应位置并设置 ZSH_THEME=&quot;spaceship&quot; 三、安装插件1234# 命令高亮git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting# 命令提示git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions 之后在 ~/.zshrc 中找到相应位置并设置插件 plugins=(git safe-paste zsh-autosuggestions zsh-syntax-highlighting) 四、iterm2 主题Preferences -&gt; Profiles -&gt; Colors 右下角导入下面链接的主题 https://raw.githubusercontent.com/mbadolato/iTerm2-Color-Schemes/master/schemes/PaleNightHC.itermcolors Background 设置为 1c223a 五、拓展功能代理开关，在有代理的情况下配置。 1234567891011# proxyfunction proxy() { export http_proxy=&quot;http://127.0.0.1:1087&quot; export https_proxy=$http_proxy echo -e &quot;已开启代理&quot;}function proxyOff(){ unset http_proxy unset https_proxy echo -e &quot;已关闭代理&quot;}","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/mac-%E7%BB%88%E7%AB%AF%E4%BC%98%E5%8C%96/"},{"title":"Redis HyperLoglog","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-hyperloglog.html 什么是HyperLoglogHyperLoglog 是 Redis 新支持的两种类型中的另外一种(还有一种是位图类型 Bitmaps)，主要适用场景是海量数据的计算。特点是速度快，占用空间小。 HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。在 Redis 里面，每个 HyperLogLog 键只需要花费 12KB 内存，就可以计算接近 2^64 个不同元素的基数。这和使用集合计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 特点 用来做基数统计的算法，在输入的元素的数量或者体积非常大的时候，计算基数所需的空间总是固定的，并且是很小的。 每一个 HyperLogLog 只需要花费 12KB 的内存就可以计算接近 2 的 64 次方不同元素的基数。 因为 HyperLogLog 只会根据输入的元素来计算基数，而不会存储输入元素本身，所以，HyperLogLog 不能像集合那样，返回输入的各个元素。 基数不存在重复的元素，例如：{1,3,4,5,6,6,7,8,9,9} 的基数集为 {1,3,4,5,6,7,8,9}，基数为 5，基数估计就是在误差可接受的范围内快速计算基数，但是该误差是在误差允许的范围内。 HyperLoglog说明 HyperLogLog 是一种算法，并非 redis 独有。 目的是做基数统计，故不是集合，不会保存元数据，只记录数量而不是数值。 耗空间极小，支持输入非常体积的数据量。 核心是基数估算算法，主要表现为计算时内存的使用和数据合并的处理。最终数值存在一定误差。 redis 中每个 hyperloglog key 占用了 12K 的内存用于标记基数（官方文档）。 pfadd 命令并不会一次性分配 12k 内存，而是随着基数的增加而逐渐增加内存分配；而 pfmerge 操作则会将 sourcekey 合并后存储在 12k 大小的 key 中，这由 hyperloglog 合并操作的原理（两个 hyperloglog 合并时需要单独比较每个桶的值）可以很容易理解。 误差说明：基数估计的结果是一个带有 0.81% 标准错误（standard error）的近似值。是可接受的范围。 Redis 对 HyperLogLog 的存储进行了优化，在计数比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阈值时才会一次性转变成稠密矩阵，才会占用 12k 的空间。 HyperLoglog与bitmaps同样是用于计算，HyperLoglog 在适用场景方面与 Bitmaps 方面有什么不同呢，Bitmaps 更适合用于验证的大数据，比如签到，记录某用户是不是当天进行了签到，签到了多少天的时候。也就是说，你不光需要记录数据，还需要对数据进行验证的时候使用 Bitmaps。 HyperLoglog 则用于只记录的时候，比如访问的 uv 统计。 应用 基数不大、数据量不到的时候就没必要用基数。 只能统计基数数量，不能获取具体内容，即：不能存储数据。 统计每一个用户点击博客的次数，只会计数一次，点击完第一次后，不会再随点击次数的增加而增加访问量。 原理HyperLogLog 原理思路是通过给定 n 个的元素集合，记录集合中数字的比特串第一个 1 出现位置的最大值k，也可以理解为统计二进制低位连续为零的最大个数。通过 k 值可以估算集合中不重复元素的数量 m，m 近似等于 2^k。 也可以说其实 Redis HyperLogLog 的原理就是一种概率算法。 HyperLoglog相关命令PFADD语法1PFADD key element [element ...] 时间复杂度O(1) 说明将除了第一个参数以外的参数存储到以第一个参数为变量名的 HyperLogLog 结构中。这个命令的一个副作用是它可能会更改这个 HyperLogLog 的内部来反映在每添加一个唯一的对象时估计的基数(集合的基数)。 如果一个 HyperLogLog 的估计的近似基数在执行命令过程中发了变化，PFADD 返回 1，否则返回 0，如果指定的 key 不存在，这个命令会自动创建一个空的 HyperLogLog 结构（指定长度和编码的字符串）。 如果在调用该命令时仅提供变量名而不指定元素也是可以的，如果这个变量名存在，则不会有任何操作，如果不存在，则会创建一个数据结构。 返回值如果 HyperLoglog 的内部被修改了，那么返回 1，否则返回 0。 PFCOUNT语法1PFCOUNT key [key ...] 说明当参数为一个 key 时，返回存储在 HyperLogLog 结构体的该变量的近似基数，如果该变量不存在，则返回 0。当参数为多个 key 时，返回这些 HyperLogLog 并集的近似基数，这个值是将所给定的所有 key 的 HyperLoglog 结构合并到一个临时的 HyperLogLog 结构中计算而得到的。 HyperLogLog 可以使用固定且很少的内存（每个 HyperLogLog 结构需要 12K 字节再加上 key 本身的几个字节）来存储集合的唯一元素。返回的可见集合基数并不是精确值， 而是一个带有 0.81% 标准错误（standard error）的近似值。 返回值PFADD 添加的唯一元素的近似数量。 PFMERGE语法1PFMERGE destkey sourcekey [sourcekey ...] 说明将多个 HyperLogLog 合并（merge）为一个 HyperLogLog，合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的可见集合（observed set）的并集。合并得出的 HyperLogLog 会被储存在目标变量（第一个参数）里面， 如果该键并不存在，那么命令在执行之前，会先为该键创建一个空的。 返回值这个命令只会返回 OK。 案例pfadd我们可以使用 pfadd 添加元素，具体过程如下： 我们使用了 pfadd 命令添加了五个元素到键 haicoder.net 中。 pfcount我们可以使用 pfcount 返回基数的个数，具体过程如下： 我们首先使用了 PFADD 添加了五个元素，接着，我们使用 PFCOUNT 查看基数的个数此时为 5，接着，我们再次使用 PFADD 添加一个元素，此时返回了 6，最后，我们添加一个已经存在的元素，此时基数的个数并未增加。 pfmerge我们可以使用 pfadd 添加元素，具体过程如下： 我们可以看出，使用 pfmerge 合并两个键时，重复的元素只会被算一次。 Redis HyperLoglog应用说明 基数不大，数据量不大就用不上，会有点大材小用浪费空间。 有局限性，就是只能统计基数数量，而没办法去知道具体的内容是什么。 和 bitmap 相比，属于两种特定统计情况，简单来说，HyperLogLog 去重比 bitmap 方便很多。 一般可以 bitmap 和 hyperloglog 配合使用，bitmap 标识哪些用户活跃，hyperloglog 计数。 一般使用 统计注册 IP 数 统计每日访问 IP 数 统计页面实时 UV 数 统计在线用户数 统计用户每天搜索不同词条的个数","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis-hyperloglog/"},{"title":"On Java 8","text":"《On Java 8》是 Java 编程思想 基于 jdk8 的新书。 第八章：复用 组合、继承、委托 第九章：多态 多态是同一个行为具有多个不同表现形式或形态的能力。 多态就是同一个接口,使用不同的实例而执行不同操作。 第十章：接口 默认方法、静态方法。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/on-java-8/"},{"title":"Redis 16个数据库","text":"原文： https://haicoder.net/note/redis-interview/redis-interview-redis-database.html 描述在实际项目中 Redis 常被应用于做缓存，分布式锁、消息队列等。但是在搭建配置好 Redis 服务器后很多朋友应该会发现和有这样的疑问，为什么 Redis 默认建立了 16 个数据库。 查看Redis数据库我们在使用 redis-cli 连接到 Redis 服务器时，可以使用 SELECT 命令切换 Redis 的库，比如我们切换到第 16 号库，具体命令如下： 1SELECT 15 执行完毕后，终端输出如下： 我们看到，Redis 的提示符前面显示 [15] 表明我们已经切换到了第 16 号库，现在，我们再次切换到第 10 号库，具体命令如下： 1SELECT 11 执行完毕后，终端输出如下： 我们看到，现在我们切换到了第 11 号库，我们切换一个不存在的库，执行完毕后，终端输出如下： 我们看到，此时提示我们数据库不存在。 16个数据库的由来Redis 是一个字典结构的存储服务器，一个 Redis 实例提供了多个用来存储数据的字典，客户端可以指定将数据存储在哪个字典中。这与在一个关系数据库实例中可以创建多个数据库类似，所以可以将其中的每个字典都理解成一个独立的数据库。 Redis 默认支持 16 个数据库，可以通过调整 Redis 的配置文件 redis.conf 中的 databases 来修改这一个值，设置完毕后重启 Redis 便完成配置，具体配置如下： 客户端与 Redis 建立连接后会默认选择 0 号数据库，不过可以随时使用 SELECT 命令更换数据库如上操作所示。 Redis的“数据库”概念由于 Redis 不支持自定义数据库的名字，所以每个数据库都以编号命名。开发者则需要自己记录存储的数据与数据库的对应关系。另外 Redis 也不支持为每个数据库设置不同的访问密码，所以一个客户端要么可以访问全部数据库，要么全部数据库都没有权限访问。但是，要正确地理解 Redis 的 “数据库” 概念这里不得不提到一个命令： 12# 清空一个Redis实例中所有数据库中的数据redis 127.0.0.1:6379&gt; FLUSHALL 该命令可以清空实例下的所有数据库数据，这与我们所熟知的关系型数据库所不同。关系型数据库多个库常用于存储不同应用程序的数据 ，且没有方式可以同时清空实例下的所有库数据。 所以对于 Redis 来说这些 db 更像是一种命名空间，且不适宜存储不同应用程序的数据。比如可以使用 0 号数据库存储某个应用生产环境中的数据，使用 1 号数据库存储测试环境中的数据，但不适宜使用 0 号数据库存储 A 应用的数据而使用 1 号数据库 B 应用的数据，不同的应用应该使用不同的 Redis 实例存储数据。Redis 非常轻量级，一个空 Redis 实例占用的内在只有 1M 左右，所以不用担心多个 Redis 实例会额外占用很多内存。 集群要注意以上所说的都是基于单体 Redis 的情况。而在集群的情况下不支持使用 SELECT 命令来切换 db，因为 Redis 集群模式下只有一个 db0。再扩展一些集群与单机 Reids 的区别： KEY 批量操作支持有限：例如 mget、mset 必须在一个 slot KEY 事务和 Lua 支持有限：操作的 KEY 必须在一个节点 KEY 是数据分区的最小粒度：不支持 bigkey 分区 不支持多个数据库：集群模式下只有一个 db0 复制只支持一层：不支持树形复制结构 总结Redis 实例默认建立了 16 个db，由于不支持自主进行数据库命名所以以 dbX 的方式命名。默认数据库数量可以修改配置文件的 database 值来设定。 对于 db 正确的理解应为 “命名空间”，多个应用程序不应使用同一个 Redis 不同库，而应一个应用程序对应一个 Redis 实例，不同的数据库可用于存储不同环境的数据。最后要注意，Redis 集群下只有 db0，不支持多 db。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis-16%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"title":"Redis pipeline","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-pipeline.html 什么是Redis pipelineRedis 中的 Pipeline 指的是管道技术，指的是客户端允许将多个请求依次发给服务器，过程中而不需要等待请求的回复，在最后再一并读取结果即可。 为什么需要pipelineredis 客户端执行一条命令分 4 个过程： 这个过程称为 Round trip time(简称 RTT, 往返时间)，Redis 中的 mget 和 mset 有效节约了 RTT，但大部分命令（如 **hgetall**，并没有 mhgetall）不支持批量操作，需要消耗 N 次 RTT ，这个时候需要 pipeline 来解决这个问题。 pipeline管道性能如果我们使用正常的一次发送一条命令，具体的流程如下图所示： Redis 通过 TCP 来对外提供服务，Client 通过 Socket 连接发起请求，每个请求在命令发出后会阻塞等待 Redis 服务器进行处理，处理完毕后将结果返回给 client。 Redis 的 Client 和 Server 是采用一问一答的形式进行通信，请求一次给一次响应。而这个过程在排除掉 Redis 服务本身做复杂操作时的耗时的话，可以看到最耗时的就是这个网络传输过程。每一个命令都对应了发送、接收两个网络传输，假如一个流程需要 0.1 秒，那么 1 秒最多只能处理 10 个请求，将严重制约 Redis 的性能。 在很多场景下，我们要完成一个业务，可能会对 redis 做连续的多个操作，譬如库存减一、订单加一、余额扣减等等，这有很多个步骤是需要依次连续执行的。 如果我们使用 Redis 的管道 pipeline 来优化上述流程，那么具体的流程图如下图所示： 在未使用管道 pipeline 技术时，一个请求会遵循两个步骤，即首先客户端向服务端发送一个查询请求，并监听 Socket 返回，通常是以阻塞模式，等待服务端响应。 最后服务端处理命令，并将结果返回给客户端。 Redis 管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。这样可以最大限度的利用 Redis 的高性能并节省不必要的网络 IO 开销。 原生批命令与Pipeline对比 原生批命令是原子性，pipeline 是非原子性（原子性概念：一个事务是一个不可分割的最小工作单位，要么都成功要么都失败。原子操作是指你的一个业务逻辑必须是不可拆分的，处理一件事情要么都成功，要么都失败，原子不可拆分。） 原生批命令一命令多个 key, 但 pipeline 支持多命令（存在事务），非原子性。 原生批命令是服务端实现，而 pipeline 需要服务端与客户端共同完成。 pipeline原理管道（pipeline）可以一次性发送多条命令并在执行完后一次性将结果返回，pipeline 通过减少客户端与 redis 的通信次数来实现降低往返延时时间，而且 Pipeline 实现的原理是队列，而队列的原理是时先进先出，这样就保证数据的顺序性。 Pipeline 的默认的同步的个数为 53 个，也就是说 arges 中累加到 53 条数据时会把数据提交。其过程可以理解为 client 可以将多个命令放到一个 tcp 报文一起发送，server 则可以将多条命令的处理结果放到一个 tcp 报文返回。 pipeline “打包命令” 客户端将多个命令缓存起来，缓冲区满了就发送(将多条命令打包发送)；有点像 “请求合并”。服务端接受一组命令集合，切分后逐个执行并一起返回。 Pipeline使用注意不过在编码时请注意，pipeline 期间将 “独占” 链接，此期间将不能进行非 “管道” 类型的其他操作，直到 pipeline 关闭；如果你的 pipeline 的指令集很庞大，为了不干扰链接中的其他操作，你可以为 pipeline 操作新建 Client 链接，让 pipeline 和其他正常操作分离在 2 个 client 中。 不过 pipeline 事实上所能容忍的操作个数，和 socket-output 缓冲区大小/返回结果的数据尺寸都有很大的关系；同时也意味着每个 redis-server 同时所能支撑的 pipeline 链接的个数，也是有限的，这将受限于 server 的物理内存或网络接口的缓冲能力。 同时，使用 pipeline 方式打包命令发送，redis 必须在处理完所有命令前先缓存起所有命令的处理结果。打包的命令越多，缓存消耗内存也越多。所以并不是打包的命令越多越好。具体多少合适需要根据具体情况测试。 pipeline的局限性pipeline 只能用于执行连续且无相关性的命令，当某个命令的生成需要依赖于前一个命令的返回时(或需要一起执行时)，就无法使用 pipeline 了。通过 scripting 功能，可以规避这一局限性。 有些系统可能对可靠性要求很高，每次操作都需要立马知道这次操作是否成功，是否数据已经写进 redis 了，如 Redis 实现分布式锁等，那这种场景就不适合了。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis-pipeline/"},{"title":"Redis bitmap","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-bitmap.html 什么是Redis bitmapRedis 的 bitmap 是通过一个 bit 位来表示某个元素对应的值或者状态，其中的 key 就是对应元素本身。Bitmaps 本身不是一种数据结构，实际上它就是字符串（key 对应的 value 就是上图中最后的一串二进制），但是它可以对字符串的位进行操作。 Bitmaps 单独提供了一套命令，所以在 Redis 中使用 Bitmaps 和使用字符串的方法不太相同。可以把 Bitmaps 想象成一个以 “位” 为单位的数组，数组的每个单元只能存储 0 和 1，数组的下标在 Bitmaps 中叫做偏移量。 bitmap特点Bitmaps 本身不是一种数据结构， 实际上它就是字符串，但是它可以对字符串的位进行操作。 Bitmaps 单独提供了一套命令， 所以在 Redis 中使用 Bitmaps 和使用字符串的方法不太相同。 可以把 Bitmaps 想象成一个以位为单位的数组， 数组的每个单元只能存储 0 和 1，数组的下标在 Bitmaps 中叫做偏移量。 bitmap优缺点优点 基于最小的单位 bit 进行存储，所以非常省空间。 设置时候时间复杂度 O(1)、读取时候时间复杂度 O(n)，操作是非常快的。 二进制数据的存储，进行相关计算的时候非常快。 方便扩容。 限制redis 中 bit 映射被限制在 512MB 之内，所以最大是 2^32 位。建议每个 key 的位数都控制下，因为读取时候时间复杂度 O(n)，越大的串读的时间花销越多。 bitmap命令详解设置值SETBIT语法1SETBIT key offset value 说明对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。位的设置或清除取决于 value 参数，可以是 0 也可以是 1 。当 key 不存在时，自动生成一个新的字符串值。 字符串会进行伸展(grown)以确保它可以将 value 保存在指定的偏移量上。当字符串值进行伸展时，空白位置以 0 填充。offset 参数必须大于或等于 0 ，小于 2^32 (bit 映射被限制在 512 MB 之内)。对使用大的 offset 的 SETBIT 操作来说，内存分配可能造成 Redis 服务器被阻塞。 返回值字符串值指定偏移量上原来储存的位(bit)。 示例 从以上示例我们可以看出，我们使用 SETBIT 命令可以设置某个位的值，如果没有设置值的位默认值为 0，同时，SETBIT 只能设置 0 和 1，我们设置了 2，提示我们出错了。 获取值GETBIT语法1GETBIT key offset 说明对 key 所储存的字符串值，获取指定偏移量上的位(bit)。当 offset 比字符串值的长度大，或者 key 不存在时，返回 0。 返回值字符串值指定偏移量上的位(bit)。 示例 从以上示例我们可以看出，我们使用 SETBIT 命令可以设置某个位的值，使用 GETBIT 可以获取某个位的值。 获取值为1个数BITCOUNT语法1BITCOUNT key start 说明计算给定字符串中，被设置为 1 的比特位的数量。一般情况下，给定的整个字符串都会被进行计数，通过指定额外的 start 或 end 参数，可以让计数只在特定的位上进行。 start 和 end 参数的设置和 GETRANGE 命令类似，都可以使用负数值： 比如 -1 表示最后一个字节，-2 表示倒数第二个字节，以此类推。不存在的 key 被当成是空字符串来处理，因此对一个不存在的 key 进行 BITCOUNT 操作，结果为 0。 返回值被设置为 1 的位的数量。 示例 从以上示例我们可以看出，我们使用 SETBIT 命令设置某个位的值，最后我们使用 BITCOUNT 可以获取被设置为 1 的位的个数。 注意BITCOUNT 命令返回的是一个指定 key 中位的值为 1 的个数(是以 byte 为单位不是 bit)”，这就是坑的所在。所以 bitcount 0 0 那么就应该是第一个 “字节” 中 1 的数量的，注意是字节，第一个字节也就是 1,2,3,4,5,6,7,8 这八个位置上。 bitmap运算BITOP语法1BITOP operation destkey key [key ...] 说明对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。operation 可以是 AND 、 OR 、 NOT 、 XOR 这四种操作中的任意一种： BITOP AND destkey key [key …] ，对一个或多个 key 求逻辑并，并将结果保存到 destkey。 BITOP OR destkey key [key …] ，对一个或多个 key 求逻辑或，并将结果保存到 destkey。 BITOP XOR destkey key [key …] ，对一个或多个 key 求逻辑异或，并将结果保存到 destkey。 BITOP NOT destkey key ，对给定 key 求逻辑非，并将结果保存到 destkey。 除了 NOT 操作之外，其他操作都可以接受一个或多个 key 作为输入。当 BITOP 处理不同长度的字符串时，较短的那个字符串所缺少的部分会被看作 0。空的 key 也被看作是包含 0 的字符串序列。 返回值保存到 destkey 的字符串的长度，和输入 key 中最长的字符串长度相等。 示例AND 操作具体如下： 从以上示例我们可以看出，使用 BITOP 可以操作两个或者多个 bitmaps，并且只有两位都是 1 时，结果对应的位才为 1。 注意BITOP 的复杂度为 O(N) ，当处理大型矩阵(matrix)或者进行大数据量的统计时，最好将任务指派到附属节点(slave)进行，避免阻塞主节点。 计算偏移量语法1BITPOS key bit [start][end] 说明返回字符串里面第一个被设置为 1 或者 0 的 bit 位。返回一个位置，把字符串当做一个从左到右的字节数组，第一个符合条件的在位置 0，其次在位置 8，等等。 GETBIT 和 SETBIT 相似的也是操作字节位的命令。默认情况下整个字符串都会被检索一次，只有在指定 start 和 end 参数(指定 start 和 end 位是可行的)，该范围被解释为一个字节的范围，而不是一系列的位。所以 start=0 并且 end=2 是指前三个字节范围内查找。 注意，返回的位的位置始终是从 0 开始的，即使使用了 start 来指定了一个开始字节也是这样。和 GETRANGE 命令一样，start 和 end 也可以包含负值，负值将从字符串的末尾开始计算，-1 是字符串的最后一个字节，-2 是倒数第二个，等等。不存在的 key 将会被当做空字符串来处理。 返回值命令返回字符串里面第一个被设置为 1 或者 0 的 bit 位。如果我们在空字符串或者 0 字节的字符串里面查找 bit 为 1 的内容，那么结果将返回 -1。如果我们在字符串里面查找 bit 为 0 而且字符串只包含 1 的值时，将返回字符串最右边的第一个空位。 如果有一个字符串是三个字节的值为 0xff 的字符串，那么命令 BITPOS key 0 将会返回 24，因为 0-23 位都是 1。基本上，我们可以把字符串看成右边有无数个 0。然而，如果你用指定 start 和 end 范围进行查找指定值时，如果该范围内没有对应值，结果将返回 -1。 示例 我们首先使用了 SETBIT 设置位的值，接着，我们分别使用了 BITPOS 获取了第一个 1 的偏移量和第一位为 0 的偏移量，我们可以看出，第一个为 1 的偏移量就是我们设置的 100. bitmap使用场景视频属性的无限延伸需求描述一个拥有亿级数据量的短视频 app，视频存在各种属性(是否加锁、是否特效等等)，需要做各种标记。 可能想到的解决方案 存储在 mysql 中，肯定不行，一个是随着业务增长属性一直增加，并且存在有时间限制的属性，直接对数据库进行加减字段是非常不合理的做法。即使是存在一个字段中用 json 等压缩技术存储也存在读效率的问题，并且对于大几亿的数据来说，废弃的字段回收起来非常麻烦。 直接记录在 redis 中，根据业务属性＋uid 为 key 来存储。读写效率角度没毛病，但是存储的角度来说key的数据量都大于 value 了，太耗费空间了。即使是用 json 等压缩技术来存储。也存在问题，解压需要时间，并且大几亿的数据回收也是难题。 设计方案使用 redis 的 bitmap 进行存储。key 由属性 id＋视频分片 id 组成。value 按照视频 id 对分片范围取模来决定偏移量 offset。10 亿视频一个属性约 120m 还是挺划算的。 用户在线状态需求描述需要对子项目提供一个接口，来提供某用户是否在线？ 设计方案使用 bitmap 是一个节约空间效率又高的一种方法，只需要一个 key，然后用户 id 为偏移量 offset，如果在线就设置为 1，不在线就设置为 0，3 亿用户只需要 36MB 的空间。 统计活跃用户需求描述需要计算活跃用户的数据情况。 设计方案使用时间作为缓存的 key，然后用户 id 为 offset，如果当日活跃过就设置为 1。之后通过 bitOp 进行二进制计算算出在某段时间内用户的活跃情况。 用户签到需求分析用户需要进行签到，对于签到的数据需要进行分析与相应的运运营策略。 设计方案使用 redis 的 bitmap，由于是长尾的记录，所以 key 主要由 uid 组成，设定一个初始时间，往后每加一天即对应 value 中的 offset 的位置。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis-bitmap/"},{"title":"Redis为什么这么快","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-fast.html Redis有多快Redis 采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由 C 语言 编写，官方提供的数据是可以达到 100000+ 的 QPS（每秒内查询次数）。这个数据不比采用单进程多线程的同样基于内存的 KV 数据库 Memcached 差！ Redis 具体 QPS 如下图所示： 横轴是连接数，纵轴是 QPS。 此时，这张图反映了一个数量级！ Redis为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是 O(1)； 数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的； 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路 I/O 复用模型，非阻塞 IO； 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 多路I/O复用模型多路 I/O 复用模型是利用 select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。 这里 “多路” 指的是多个网络连接，“复用” 指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响 Redis 性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。 Redis 内部实现采用 epoll。 为什么Redis是单线程的因为 Redis 是基于内存的操作，CPU 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了（毕竟采用多线程会有很多麻烦！）。 但是，我们使用单线程的方式是无法发挥多核 CPU 性能，不过我们可以通过在单机开多个 Redis 实例来完善！ 这里我们一直在强调的单线程，只是在处理我们的网络请求的时候只有一个线程来处理，一个正式的 Redis-Server 运行的时候肯定是不止一个线程的，这里需要大家明确的注意一下！例如 Redis 进行持久化的时候会以子进程的方式执行；例如我在测试服务器上查看 Redis 进程，然后找到该进程下的线程： 我们可以看到，这里显示了三个 Redis—Server 的线程，ps 命令的 “-T” 参数表示显示线程（Show threads, possibly with SPID column.）“SID” 栏表示线程 ID，而 “CMD” 栏则显示了线程名称。 Redis单线程对比多线程好处上下文的切换上下文其实不难理解，它就是 CPU 寄存器和程序计数器。主要的作用就是存放没有被分配到资源的线程，多线程操作的时候，不是每一个线程都能够直接获取到 CPU 资源的，我们之所以能够看到我们电脑上能够运行很多的程序，是应为多线程的执行和 CPU 不断对多线程的切换。但是总有线程获取到资源，也总有线程需要等待获取资源，这个时候，等待获取资源的线程就需要被挂起，也就是我们的寄存。这个时候我们的上下文就产生了，当我们的上下文再次被唤起，得到资源的时候，就是我们上下文的切换。 竞争资源竞争资源相对来说比较好理解，CPU 对上下文的切换其实就是一种资源分批，但是在切换之前，到底切换到哪一个上下文，就是资源竞争的开始。在我 redis 中由于是单线程的，所以所有的操作都不会涉及到资源的竞争。 锁的消耗对于多线程的情况来讲，不能回避的就是锁的问题。如果说多线程操作出现并发，有可能导致数据不一致，或者操作达不到预期的效果。这个时候我们就需要锁来解决这些问题。当我们的线程很多的时候，就需要不断的加锁，释放锁，该操作就会消耗掉我们很多的时间。 总结Redis 为什么是单线程的是因为 Redis 的瓶颈不是 cpu 的运行速度，而往往是网络带宽和机器的内存大小。再说了，单线程切换开销小，容易实现既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。 如果万一 CPU 成为你的 Redis 瓶颈了，或者，你就是不想让服务器其他核闲置，那怎么办？那也很简单，你多起几个 Redis 进程就好了。Redis 是 keyvalue 数据库，又不是关系数据库，数据之间没有约束。只要客户端分清哪些 key 放在哪个 Redis 进程上就可以了。redis-cluster 可以帮你做的更好。 单线程可以处理高并发请求吗？当然可以了，Redis 都实现了。有一点概念需要澄清，并发并不是并行。（相关概念：并发性 I/O 流，意味着能够让一个计算单元来处理来自多个客户端的流请求。并行性，意味着服务器能够同时执行几个事情，具有多个计算单元）","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB/"},{"title":"Redis主从模式","text":"原文： https://haicoder.net/note/redis-interview/redis-interview-redis-master-slave.html 什么是Redis主从模式使用一个 Redis 实例作为主机，其余的作为备份机。主机和备份机的数据完全一致，主机支持数据的写入和读取等各项操作，而从机则只支持与主机数据的同步和读取。也就是说，客户端可以将数据写入到主机，由主机自动将数据的写入操作同步到从机。 主从模式很好的解决了数据备份问题，并且由于主从服务数据几乎是一致的，因而可以将写入数据的命令发送给主机执行，而读取数据的命令发送给不同的从机执行，从而达到读写分离的目的。 Redis 的主从复制功能非常强大，一个 master 可以拥有多个 slave，而一个 slave 又可以拥有多个 slave，如此下去，形成了强大的多级服务器集群架构。 主从模式架构Redis 主从模式的架构图如下图所示： 我们可以看到，在主从模式中，只有一个是主机，其他的都是从机，并且从机下面还可以有任意多个从机。 Redis主从复制注意点 默认配置下，master 节点可以进行读和写，slave 节点只能进行读操作，写操作被禁止。 不要修改配置让 slave 节点支持写操作，没有意义，因为，首先写入的数据不会被同步到其他节点，其次，当 master 节点修改同一条数据后，slave 节点的数据会被覆盖掉。 master 节点挂了以后，redis 就不会对外提供写服务了，因为剩下的 slave 节点不会成为 master。 master 节点挂了以后，不影响 slave 节点的读，master 节点启动后 Redis 将重新对外提供写服务。 slave 节点挂了不影响其他 slave 节点的读和 master 节点的读和写，重新启动后会将数据从 master 节点同步过来。 主从复制优缺点优点 读写分离，提高效率 数据热备份，提供多个副本 缺点 主节点故障，集群则无法进行工作，可用性比较低，从节点升主节点需要人工手动干预 单点容易造成性能低下 主节点的存储能力受到限制 主节点的写受到限制（只有一个主节点） 全量同步可能会造成毫秒或者秒级的卡顿现象 特点只能 master 到 slave，单向的 Redis主从模式配置我们首先使用 vim 创建 master 的配置文件，具体命令如下： 1vim redis/master-6739.conf 如下图所示： 我们写入如下配置： 123456bind 0.0.0.0port 6379logfile &quot;6379.log&quot;dbfilename &quot;dump-6379.rdb&quot;daemonize yesrdbcompression yes 即，我们配置了主节点的端口为 6379，现在，我们再次创建 slave1 节点的配置，具体命令如下： 1vim redis/slave1-6380.conf 我们写入如下配置： 1234567bind 0.0.0.0port 6380logfile &quot;6380.log&quot;dbfilename &quot;dump-6380.rdb&quot;daemonize yesrdbcompression yesslaveof 192.168.33.133 6379 即，我们配置了第一个从节点的端口为 6380，同时，我们通过 slaveof 配置指定了该从节点的主节点是什么，现在，我们再次创建 slave2 节点的配置，具体命令如下： 1vim redis/slave2-6381.conf 我们写入如下配置： 1234567bind 0.0.0.0port 6381logfile &quot;6381.log&quot;dbfilename &quot;dump-6381.rdb&quot;daemonize yesrdbcompression yesslaveof 192.168.33.133 6379 我们指定了 slave2 节点的端口为 6381，并且指定了其主节点为 6379 的配置，现在，我们分别启动三个服务器，具体命令如下： 123redis-server redis/master-6739.confredis-server redis/slave1-6380.confredis-server redis/slave2-6381.conf 启动完毕之后，我们使用 ps 命令查看所有的 redis-server 服务，具体命令如下： 1ps -ef | grep redis-server 执行完毕后，如下图所示： 至此，我们的所有配置都已经完成了，并且服务都已经启动成功了，现在，我们分别登录到 master 和两个 slave 查看键 name 是否存在，具体命令如下： 1get name 执行完毕后，如下图所示： 我们看到，此时三个节点都没有 name 键，现在，我们在 master 上设置 name 的值，具体命令如下： 1set name haicoder 执行完毕后，我们再次分别在 master 和两个 slave 获取数据，如下图所示： 我们可以看出，我们在 master 上设置了一个键，最后在两个 slave 都获取到了这个键的值，即，master 的数据会自动同步到 slave 节点。现在，我们尝试在 slave 设置键，具体命令如下： 1set name1 haicoder1 执行完毕后，如下图所示： 我们看到，此时提示我们不能在 slave 写入数据，即 master 可以读写数据，但 slave 只能读取数据。 注意，使用主从模式时应注意 matser 节点的持久化操作，matser 节点在未使用持久化的情况详情下如果宕机，并自动重新拉起服务，从服务器会出现丢失数据的情况。因为 master 服务挂了之后，重启服务后，slave 节点会与 master 节点进行一次完整的重同步操作，所以由于 master 节点没有持久化，就导致 slave 节点上的数据也会丢失掉。所以在配置了 Redis 的主从模式的时候，应该打开主服务器的持久化功能。 查看主从节点我们要查看当前节点是 master 节点还是 slave 节点，我们可以使用 info 命令，具体命令如下： 1info 我们在 master 上执行如下图所示： 我们可以看到，此时显示的 Replication 配置项下面的 role 为 master，现在，我们再次在 slave 节点下查看，执行如下图所示： 我们看到，此时显示的是 slave，同时，我们还可以直接使用 info 加要查看的节点，来查看具体的配置，具体命令如下： 1info Replication 我们首先在 master 上查看，输出如下： 我们看到，此时直接显示了 Replication 节点的信息，现在，我们再次查看 slave 节点的信息，输出如下： 我们看到，此时就显示了是 slave 节点了。 主从复制原理流程当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。 slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。 主从复制的断点续传从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 resynchronization。 无磁盘化复制master 在内存中直接创建 RDB ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 repl-diskless-sync yes 即可。具体配置如下： 1234repl-diskless-sync yes# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来repl-diskless-sync-delay 5 过期key处理slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。 主从复制的完整流程流程slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 host 和 ip ，但是复制流程没开始。 slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 ping 命令给 master node。 如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node 第一次执行全量复制，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。 全量复制 master 执行 bgsave ，在本地生成一份 rdb 快照文件。 master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s) master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。 1client-output-buffer-limit slave 256MB 64MB 60 slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时基于旧的数据版本对外提供服务。 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。 增量复制 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。 master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。 master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。 heartbeat主从节点互相都会发送 heartbeat 信息。 master 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。 异步复制master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F/"},{"title":"Redis事务","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-transaction.html 什么是Redis事务Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。 也就说说 redis 事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。 Redis事务特性单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 Redis 事务没有隔离级别的概念：批量操作在发送 EXEC 命令前被放入队列缓存，并不会被实际执行，也就不存在事务内的查询要看到事务里的更新，事务外查询不能看到。 Redis不保证原子性：Redis 中，单条命令是原子性执行的，但事务不保证原子性，且没有回滚。事务中任意命令执行失败，其余的命令仍会被执行。 Redis事务命令命令| 命令 | 描述 | | ——- | ———————————————————— | | MULTI | 标记一个事务块的开始 | | EXEC | 执行所有事务块内的命令 | | DISCARD | 取消事务，放弃执行事务块内的所有命令 | | WATCH | 监视一个（或多个）key，如果在事务执行之前这个（或多个）key被其他命令所改动，那么事务将被打断 | | UNWATCH | 取消 WATCH 命令对所有 keys 的监视 | 说明MULTI 命令用于开启一个事务，它总是返回 OK 。 MULTI 执行之后， 客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行， 而是被放到一个队列中， 当 EXEC 命令被调用时， 所有队列中的命令才会被执行。 另一方面， 通过调用 DISCARD ， 客户端可以清空事务队列， 并放弃执行事务。 事务执行三个阶段Redis 事务可以大体分为三个阶段： 开启事务（multi） 命令入队（业务操作） 执行事务（exec）或取消事务（discard） 案例123456789&gt; multiOK&gt; incr starQUEUED&gt; incr starQUEUED&gt; exec(integer) 1(integer) 2 上面的指令演示了一个完整的事务过程，所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。 Redis 事务可以一次执行多个命令，本质是一组命令的集合。一个事务中的所有命令都会序列化，按顺序地串行化执行而不会被其它命令插入，不许加塞。 可以保证一个队列中，一次性、顺序性、排他性的执行一系列命令（Redis 事务的主要作用其实就是串联多个命令防止别的命令插队）。也就是说事务可以一次执行多个命令， 并且带有以下两个重要的保证： 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 案例正常执行可以批处理，挺爽，每条操作成功的话都会各取所需，互不影响，具体过程如下： 我们看到，我们正常的使用 MULTI 开启事务，使用 EXEC 执行事务。 放弃事务discard 操作表示放弃事务，之前的操作都不算数，具体过程如下： 我们可以看到， 我们使用了 DISCARD 放弃了事务的执行之后，再次使用 GET 获取设置的值，并未获取到，因为事务被放弃执行了。 事务中的错误上边规规矩矩的操作，看着还挺好，可是事务是为解决数据安全操作提出的，我们用 Redis 事务的时候，可能会遇上以下两种错误： 事务在执行 EXEC 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误等等），或者其他更严重的错误，比如内存不足（如果服务器使用 maxmemory 设置了最大内存限制的话）。 命令可能在 EXEC 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。 Redis 针对如上两种错误采用了不同的处理策略，对于发生在 EXEC 执行之前的错误，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务（Redis 2.6.5 之前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败）。 对于那些在 EXEC 命令执行之后所产生的错误， 并没有对它们进行特别处理： 即使事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行。 全体连坐某一条操作记录报错的话，exec 后所有操作都不会成功，具体过程如下： 我们可以看到，我们写错了一个命令，属于语法错误，结果我们使用 EXEC 命令执行事务，事务执行失败，并且所有的键都未设置成功。 冤头债主只有在执行的时候才可以判断出语句错误，其他正确的会被正常执行，具体过程如下： 我们看到，除了 DECR 命令执行失败了，其他命令都执行成功了，因为 DECR 命令需要在执行时才会被发现错误。 Redis事务回滚如果你有使用关系式数据库的经验，那么 “Redis 在事务失败时不进行回滚，而是继续执行余下的命令” 这种做法可能会让你觉得有点奇怪。以下是官方的自夸： Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。 因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。 有种观点认为 Redis 处理事务的做法会产生 bug，然而需要注意的是，在通常情况下，回滚并不能解决编程错误带来的问题。 举个例子，如果你本来想通过 INCR 命令将键的值加上 1，却不小心加上了 2，又或者对错误类型的键执行了 INCR，回滚是没有办法处理这些情况的。 鉴于没有任何机制能避免程序员自己造成的错误，并且这类错误通常不会在生产环境中出现，所以 Redis 选择了更简单、更快速的无回滚方式来处理事务。 带Watch的事务WATCH 命令用于在事务开始之前监视任意数量的键：当调用 EXEC 命令执行事务时，如果任意一个被监视的键已经被其他客户端修改了，那么整个事务将被打断，不再执行，直接返回失败。 WATCH 命令可以被调用多次。对键的监视从 WATCH 执行之后开始生效，直到调用 EXEC 为止。用户还可以在单个 WATCH 命令中监视任意多个键，就像这样： 12redis&gt; WATCH key1 key2 key3 OK 当 EXEC 被调用时，不管事务是否成功执行，对所有键的监视都会被取消。另外，当客户端断开连接时，该客户端对键的监视也会被取消。我们看个简单的例子，用 watch 监控我的账号余额： 但这个卡，还绑定了我媳妇的微信，如果在我消费的时候，她也消费了，会怎么样呢？现在，我开始消费了两笔，一笔是 20 元，一笔是 10元，但此时我还没确认支付，也就是事务还没提交，如下： 现在，我媳妇使用了另一个客户端，对我卡内余额进行了消费，也就是使用了另一个 Redis 客户端连接到 Redis 服务器，对 balance 变量进行修改，如下： 现在，我开始消费，也就是提交事务，如下： 我们看到，此时事务返回了 nil，即事务执行失败了，因为，在我们使用 WATCH 监控的时候，某个数据被修改了，因此，事务执行失败。 同时，使用无参数的 UNWATCH 命令可以手动取消对所有键的监视。 对于一些需要改动多个键的事务，有时候程序需要同时对多个键进行加锁，然后检查这些键的当前值是否符合程序的要求。 当值达不到要求时，就可以使用 UNWATCH 命令来取消目前对键的监视，中途放弃这个事务，并等待事务的下次尝试。 注意Redis 事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络 IO 时间也会线性增长。所以通常 Redis 的客户端在执行事务时都会结合 pipeline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E4%BA%8B%E5%8A%A1/"},{"title":"Redis内存碎片","text":"原文： https://haicoder.net/note/redis-interview/redis-interview-redis-mem-fragme.html 查看Redis内存碎片率在 Redis 使用过程中，经常会产生内存碎片，如果我们需要查看 Redis 的内存碎片率，我们可以使用 INFO 命令，具体命令如下： 1INFO Memory 执行完毕后，如下图所示： 其中，mem_fragmentation_ratio 显示的就是内存使用率，其具体的计算公式为： 1mem_fragmentation_ratio = used_memory_rss / used_memory 其中，used_memory_rss 是 Redis 向操作系统申请的内存。used_memory 是 Redis 中的数据占用的内存。 内存碎片如何产生的Redis 内部有自己的内存管理器，为了提高内存使用的效率，来对内存的申请和释放进行管理。Redis 中的值删除的时候，并没有把内存直接释放，交还给操作系统，而是交给了 Redis 内部有内存管理器。 Redis 中申请内存的时候，也是先看自己的内存管理器中是否有足够的内存可用。Redis 的这种机制，提高了内存的使用率，但是会使 Redis 中有部分自己没在用，却不释放的内存，导致了内存碎片的发生。 碎片率的意义mem_fragmentation_ratio 的不同值，说明不同的情况。 大于1：说明内存有碎片，一般在 1 到 1.5 之间是正常的。 大于1.5：说明内存碎片率比较大，需要考虑是否要进行内存碎片清理，要引起重视。 小于1：说明已经开始使用交换内存，也就是使用硬盘了，正常的内存不够用了，需要考虑是否要进行内存的扩容。 解决碎片率大的问题低于4.0版本的Redis如果你的 Redis 版本是 4.0 以下的，Redis 服务器重启后，Redis 会将没用的内存归还给操作系统，碎片率会降下来。 高于4.0版本的RedisRedis 4.0 版本开始，可以在不重启的情况下，线上整理内存碎片。自动碎片清理，只要设置了如下的配置，内存就会自动清理了： 1config set activedefrag yes 如果想把 Redis 的配置，写到配置文件中去： 1config rewrite 如果你对自动清理的效果不满意，可以使用如下命令，直接试下手动碎片清理： 1memory purge","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87/"},{"title":"Redis内存淘汰机制","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-memory-eliminat.html 描述Redis 的用途非常广泛。作为一个高性能的内存数据库，它经常被用于缓存的业务场景。所谓缓存，即在第一次获取到数据的时候，把它暂存在内存中。这样下次需要这个数据的时候，就直接从内存中取，不用再去查询数据库或调用远程接口，这样可以极大地提高应用程序的性能。 如果缓存中的数据永久存在，那占用的内存就会变得越来越大。而内存是有限的，所以缓存系统需要在需要的时候删除一些不必要的缓存数据以节约内存空间。Redis 提供了两种机制配合来达到上述目的：**过期策略** 和内存淘汰机制。 过期策略使用过 Redis 的同学应该知道，我们在设置一个 KEY 之后，可以指定这个 KEY 的过期时间。那么这个 KEY 到了过期时间就会立即被删除吗？Redis 是如何删除这些过期 KEY 的呢？ 先说结论：Redis 是使用定期删除+惰性删除两者配合的过期策略。 定期删除定期删除指的是 Redis 默认每隔 100ms 就随机抽取一些设置了过期时间的 KEY，检测这些 KEY 是否过期，如果过期了就将其删掉。因为 KEY 太多，如果全盘扫描所有的 KEY 会非常耗性能，所以是随机抽取一些 KEY 来删除。这样就有可能删除不完，需要惰性删除配合。 惰性删除惰性删除不再是 Redis 去主动删除，而是在客户端要获取某个 KEY 的时候，Redis 会先去检测一下这个 KEY 是否已经过期，如果没有过期则返回给客户端，如果已经过期了，那么 Redis 会删除这个 KEY，不会返回给客户端。 所以惰性删除可以解决一些过期了，但没被定期删除随机抽取到的 KEY。但有些过期的 KEY 既没有被随机抽取，也没有被客户端访问，就会一直保留在数据库，占用内存，长期下去可能会导致内存耗尽。所以 Redis 提供了内存淘汰机制来解决这个问题。 为什么不使用定时删除？所谓定时删除，指的是用一个定时器来负责监视 KEY，当这个 KEY 过期就自动删除，虽然内存及时释放，但是十分消耗 CPU 资源，因此一般不推荐采用这一策略。 内存淘汰机制Redis 在使用内存达到某个阈值（通过 maxmemory 配置)的时候，就会触发内存淘汰机制，选取一些 KEY 来删除。内存淘汰有许多策略，下面分别介绍这几种不同的策略。具体配置如下： 具体每一种策略解释如下： | 名称 | 描述 | | ————— | —————————————————— | | volatile-lru | 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰 | | volatile-lfu | 从已设置过期时间的数据集中挑选最不经常使用的数据淘汰 | | volatile-ttl | 从已设置过期时间的数据集中挑选将要过期的数据淘汰 | | volatile-random | 从已设置过期时间的数据集中挑选任意数据淘汰 | | allkeys-lru | 当内存不足写入新数据时淘汰最近最少使用的KEY | | allkeys-random | 当内存不足写入新数据时随机选择KEY淘汰 | | allkeys-lfu | 当内存不足写入新数据时移除最不经常使用的KEY | | no-eviction | 当内存不足写入新数据时，写入操作会报错，同时不删除数据 | 其中 no-eviction 是默认策略也就是当内存不足以容纳新写入数据时，新写入操作会报错。 如何选取合适的策略？比较推荐的是两种 lru 策略。根据自己的业务需求。如果你使用 Redis 只是作为缓存，不作为 DB 持久化，那推荐选择 allkeys-lru；如果你使用 Redis 同时用于缓存和数据持久化，那推荐选择 volatile-lru。 持久化与内存淘汰RDB 生成 rdb 文件：生成时，程序会对键进行检查，过期键不放入 rdb 文件。 载入 rdb 文件：载入时，如果以主服务器模式运行，程序会对文件中保存的键进行检查，未过期的键会被载入到数据库中，而过期键则会忽略；如果以从服务器模式运行，无论键过期与否，均会载入数据库中，过期键会通过与主服务器同步而删除。 AOF 当服务器以 aof 持久化模式运行时，如果数据库中的某个键已经过期，但它还没有被删除，那么 aof 文件不会因为这个过期键而产生任何影响；当过期键被删除后，程序会向 aof 文件追加一条 del 命令来显式记录该键已被删除。 aof 重写过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写后的 aof 文件中。 复制当服务器运行在复制模式下时，从服务器的过期删除动作由主服务器控制： 主服务器在删除一个过期键后，会显式地向所有从服务器发送一个 del 命令，告知从服务器删除这个过期键; 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续像处理未过期的键一样来处理过期键; 从服务器只有在接到主服务器发来的 del 命令后，才会删除过期键。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6/"},{"title":"Redis分布式锁","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-dislock.html 什么是分布式锁要介绍分布式锁，首先要提到与分布式锁相对应的是线程锁、进程锁。 线程锁：主要用来给方法、代码块加锁。当某个方法或代码使用锁，在同一时刻仅有一个线程执行该方法或该代码段。线程锁只在同一 JVM 中有效果，因为线程锁的实现在根本上是依靠线程之间共享内存实现的，比如 synchronized 是共享对象头，显示锁 Lock 是共享某个变量（state）。 进程锁：为了控制同一操作系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，因此无法通过 synchronized 等线程锁实现进程锁。 分布式锁：当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问。 分布式锁的使用场景线程间并发问题和进程间并发问题都是可以通过分布式锁解决的，但是强烈不建议这样做！因为采用分布式锁解决这些小问题是非常消耗资源的！分布式锁应该用来解决分布式情况下的多进程并发问题才是最合适的。 有这样一个情境，线程 A 和线程 B 都共享某个变量 X。如果是单机情况下（单 JVM），线程之间共享内存，只要使用线程锁就可以解决并发问题。如果是分布式情况下（多 JVM），线程 A 和线程 B 很可能不是在同一 JVM 中，这样线程锁就无法起到作用了，这时候就要用到分布式锁来解决。 分布式锁实现说明分布式锁一般有三种实现方式即，数据库乐观锁、基于 Redis 的分布式锁和基于 ZooKeeper 的分布式锁。 可靠性首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 具有容错性。只要大部分的 Redis 节点正常运行，客户端就可以加锁和解锁。 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 代码实现组件依赖首先我们要通过 Maven 引入 Jedis 开源组件，在 pom.xml 文件加入下面的代码： 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;2.9.0&lt;/version&gt;&lt;/dependency&gt; 加锁代码正确姿势Talk is cheap, show me the code。先展示代码，再带大家慢慢解释为什么这样实现： 1234567891011121314151617181920public class RedisTool { private static final String LOCK_SUCCESS = &quot;OK&quot;; private static final String SET_IF_NOT_EXIST = &quot;NX&quot;; private static final String SET_WITH_EXPIRE_TIME = &quot;PX&quot;; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) { String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) { return true; } return false; }} 可以看到，我们加锁就一行代码： 1jedis.set(String key, String value, String nxxx, String expx, int time) 这个 set() 方法一共有五个形参： 第一个为 key，我们使用 key 来当锁，因为 key 是唯一的。 第二个为 value，我们传的是 requestId，很多童鞋可能不明白，有 key 作为锁不就够了吗，为什么还要用到 value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给 value 赋值为 requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId 可以使用 UUID.randomUUID().toString() 方法生成。 第三个为 nxxx，这个参数我们填的是 NX，意思是 SET IF NOT EXIST，即当 key 不存在时，我们进行 set 操作；若 key 已经存在，则不做任何操作； 第四个为 expx，这个参数我们传的是 PX，意思是我们要给这个 key 加一个过期的设置，具体时间由第五个参数决定。 第五个为 time，与第四个参数相呼应，代表 key 的过期时间。 总的来说，执行上面的 set() 方法就只会导致两种结果： 当前没有锁（key 不存在），那么就进行加锁操作，并对锁设置个有效期，同时 value 表示加锁的客户端。 已有锁存在，不做任何操作。 心细的童鞋就会发现了，我们的加锁代码满足我们可靠性里描述的三个条件。首先，set() 加入了 NX 参数，可以保证如果已有 key 存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。 其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即 key 被删除），不会发生死锁。 最后，因为我们将 value 赋值为 requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。由于我们只考虑 Redis 单机部署的场景，所以容错性我们暂不考虑。 错误示例1比较常见的错误示例就是使用 jedis.setnx() 和 jedis.expire() 组合实现加锁，代码如下： 1234567public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, int expireTime) { Long result = jedis.setnx(lockKey, requestId); if (result == 1) { // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); }} setnx() 方法作用就是 SET IF NOT EXIST，expire() 方法就是给锁加一个过期时间。乍一看好像和前面的 set() 方法结果一样，然而由于这是两条 Redis 命令，不具有原子性，如果程序在执行完 setnx() 之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。网上之所以有人这样实现，是因为低版本的 jedis 并不支持多参数的 set() 方法。 错误示例2这一种错误示例就比较难以发现问题，而且实现也比较复杂。实现思路：使用 jedis.setnx() 命令实现加锁，其中key 是锁，value 是锁的过期时间。执行过程： 通过 setnx() 方法尝试加锁，如果当前锁不存在，返回加锁成功。 如果锁已经存在则获取锁的过期时间，和当前时间比较，如果锁已经过期，则设置新的过期时间，返回加锁成功。 代码如下： 1234567891011121314151617181920public static boolean wrongGetLock2(Jedis jedis, String lockKey, int expireTime) { long expires = System.currentTimeMillis() + expireTime; String expiresStr = String.valueOf(expires); // 如果当前锁不存在，返回加锁成功 if (jedis.setnx(lockKey, expiresStr) == 1) { return true; } // 如果锁存在，获取锁的过期时间 String currentValueStr = jedis.get(lockKey); if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) { // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间 String oldValueStr = jedis.getSet(lockKey, expiresStr); if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) { // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才有权利加锁 return true; } } // 其他情况，一律返回加锁失败 return false;} 那么这段代码问题在哪里？ 由于是客户端自己生成过期时间，所以需要强制要求分布式下每个客户端的时间必须同步。 当锁过期的时候，如果多个客户端同时执行 jedis.getSet() 方法，那么虽然最终只有一个客户端可以加锁，但是这个客户端的锁的过期时间可能被其他客户端覆盖。 锁不具备拥有者标识，即任何客户端都可以解锁。 解锁代码正确姿势还是先展示代码，再带大家慢慢解释为什么这样实现： 123456789101112131415161718public class RedisTool { private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) { String script = &quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end&quot;; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) { return true; } return false; }} 可以看到，我们解锁只需要两行代码就搞定了！第一行代码，我们写了一个简单的 Lua 脚本代码。第二行代码，我们将 Lua 代码传到 jedis.eval() 方法里，并使参数 KEYS[1] 赋值为 lockKey，ARGV[1] 赋值为 requestId。eval() 方法是将 Lua 代码交给 Redis 服务端执行。 那么这段 Lua 代码的功能是什么呢？其实很简单，首先获取锁对应的 value 值，检查是否与 requestId 相等，如果相等则删除锁（解锁）。那么为什么要使用 Lua 语言来实现呢？因为要确保上述操作是原子性的。那么为什么执行 eval() 方法可以确保原子性，源于 Redis 的特性，下面是官网对 eval 命令的部分解释： 简单来说，就是在 eval 命令执行 Lua 代码的时候，Lua 代码将被当成一个命令去执行，并且直到 eval 命令执行完成，Redis 才会执行其他命令。 错误示例1最常见的解锁代码就是直接使用 jedis.del() 方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。 123public static void wrongReleaseLock1(Jedis jedis, String lockKey) { jedis.del(lockKey);} 错误示例2这种解锁代码乍一看也是没问题，甚至我之前也差点这样实现，与正确姿势差不多，唯一区别的是分成两条命令去执行，代码如下： 1234567public static void wrongReleaseLock2(Jedis jedis, String lockKey, String requestId) { // 判断加锁与解锁是不是同一个客户端 if (requestId.equals(jedis.get(lockKey))) { // 若在此时，这把锁突然不是这个客户端的，则会误解锁 jedis.del(lockKey); }} 如代码注释，问题在于如果调用 jedis.del() 方法的时候，这把锁已经不属于当前客户端的时候会解除他人加的锁。那么是否真的有这种场景？ 答案是肯定的，比如客户端 A 加锁，一段时间之后客户端 A 解锁，在执行 jedis.del() 之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端 A 再执行 del() 方法，则将客户端 B 的锁给解除了。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"},{"title":"Redis压缩列表","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-ziplist.html Redis 中的压缩列表不是基础数据结构，而是 Redis 自己设计的一种数据存储结构。它有点儿类似数组，通过一片连续的内存空间，来存储数据。不过，它跟数组不同的一点是，它允许存储的数据大小不同。 压缩列表详解说明听到 “压缩” 两个字，直观的反应就是节省内存。之所以说这种存储结构节省内存，是相较于数组的存储思路而言的。我们知道，数组要求每个元素的大小相同，如果我们要存储不同长度的字符串，那我们就需要用最大长度的字符串大小作为元素的大小(假设是 20 个字节)。存储小于 20 个字节长度的字符串的时候，便会浪费部分存储空间。 数组的优势占用一片连续的空间可以很好的利用 CPU 缓存访问数据。如果我们想要保留这种优势，又想节省存储空间我们可以对数组进行压缩。 但是这样有一个问题，我们在遍历它的时候由于不知道每个元素的大小是多少，因此也就无法计算出下一个节点的具体位置。这个时候我们可以给每个节点增加一个 length 的属性。 那么，此时数组就如下图所示： 如此。我们在遍历节点的之后就知道每个节点的长度(占用内存的大小)，就可以很容易计算出下一个节点再内存中的位置。这种结构就像一个简单的压缩列表了。 压缩列表的构成压缩列表是 Redis 为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型(sequential)数据结枃。一个压缩列表可以包含任意多个节点(entry)，每个节点可以保存一个字节数组或者一个整数值，如下图： zlbytes：存储一个无符号整数，固定四个字节长度，用于存储压缩列表所占用的字节，当重新分配内存的时候使用，不需要遍历整个列表来计算内存大小。 zltail：存储一个无符号整数，固定四个字节长度，代表指向列表尾部的偏移量，偏移量是指压缩列表的起始位置到指定列表节点的起始位置的距离。 zllen：压缩列表包含的节点个数，固定两个字节长度，源码中指出当节点个数大于 2^16-2 个数的时候，该值将无效，此时需要遍历列表来计算列表节点的个数。 entryX：列表节点区域，长度不定，由列表节点紧挨着组成。 zlend：一字节长度固定值为 255，用于表示列表结束。 示例 如上图，展示了一个总长为 80 字节，包含 3 个节点的压缩列表。如果我们有一个指向压缩列表起始地址的指针 p，那么表为节点的地址就是 P+60。 压缩列表节点构成压缩列表的节点如下图所示： previous_entry_length：previous_entry_length 记录了前一个节点的长度，程序可以通过指针运算，根据当前节点的起始地址拉算出前一个节点的其实地址。 压缩列表从表尾向表头的遍历就是使用这一原理实现的。 encoding：encoding 记录了节点的 content 属性所保存的数据类型及长度。 content：content 负责保存节点的值，节点值可以是一个字节数组或者整数，值的类型和长度由 encoding 属性决定。 连锁更新每个节点的 previous_entry_length 属性都记录了前一个节点的长度： 如果前一节点的长度小于 254 字节，那么 previous_entry_length 属性需要用 1 字节长的空间来保存这个长度值。 如果前一节点的长度大于等于 254 字节，那么 previous_entry_length 属性需要用 5 字节长的空间来保存这个长度值。 假设在一个压缩列表中，有多个连续的、长度介于 250 到 253 字节之间的节点 e1 至 eN： 因为 e1 至 eN 所有节点长度都小于 254 字节，所以这些节点长度的 previous_entry_length 都是 1 字节的。这时，如果在压缩列表头添加一个长度大于等于 254 字节的新节点： 因为 e1 的 previous_entry_length 属性仅长 1 字节，无法保存新节点的程度，所以程序将对压缩列表进行空间重分配，并将 e1 的 previous_entry_length 从原来的 1 字节长扩展为 5 字节长。 这时 e1 的 previous_entry_length 属性新增了四个字节，e1 的长度大于等于 254 字节了，这样用 1 字节长的 previous_entry_length 就无法保存。 因此，e2 的 previous_entry_length 属性也会被扩展。依次类推，后面所有节点都会被扩展，造成连锁更新。 类似地，删除节点操作也可能会引发连锁更新： 因为连锁更新最坏情况下需要对压缩列表执行 N 次空间重分配，而每次空间重分配复杂度最坏为 O(N)，所以连锁更新最坏复杂度为 O(N^2) 尽管连锁更新复杂度较高，但真正造成性能问题的几率很低： 压缩列表里恰好有多个连续的、长度介于 250 到 253 字节之间的节点。 即便出现连锁更新，只要被更新节点数目不多，影响就不大。 所以添加删除节点的操作平均复杂度仅为 O(N)。 Redis压缩列表压缩列表(zip1ist)是列表和哈希的底层实现之一。 当一个列表只包含少量列表项，并且每个列表项要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做列表的底层实现。 当一个哈希只包含少量键值对，比且每个键值对的键和值要么就是小整数值，要么就是长度比较短的字符串，那么 Redis 就会使用压缩列表来做哈希的底层实现。 常用操作的时间复杂度| 操作 | 时间复杂度 | | ———————————————————— | ———————————————————— | | 创建一个新的压缩列表 | O(1) | | 创建一个包含给定值的新节点,并将这个新节点添加到压缩列表的表头或者表尾 | 平均 O(N)，最坏O(N^2)(可能发生连锁更新) | | 将包含给定值的新节点插人到给定节点之后 | 平均 O(N)，最坏O(N^2)(可能发生连锁更新) | | 返回压缩列表给定索引上的节点 | O(N) | | 在压缩列表中査找并返回包含了给定值的节点 | 因为节点的值可能是一个字节数组,所以检查节点值和给定值是否相同的复杂度为 O(N),而查找整个列表的复杂度则为(N^2) | | 返回给定节点的下一个节点 | O(1) | | 返回给定节点的前一个节点 | O(1) | | 获取给定节点所保存的值 | O(1) | | 从压缩列表中删除给定的节点 | 平均 O(N)，最坏 O(N^2)(可能发生连锁更新) | | 删除压缩列表在给定索引上的连续多个 | 平均 O(N)，最坏 O(N^2)(可能发生连锁更新) | | 返回压缩列表目前占用的内存字节数 | O(1) | | 返回压缩列表目前包含的节点数量 | 点数量小于 65535 时为 O(1),大于 65535 时为 O(N) | 总结 压缩列表是 Redis 为节约内存自己设计的一种顺序型数据结构。 压缩列表被用作列表键和哈希键的底层实现之一。 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 添加新节点到压缩列表，或者从压缩列表中删除节点，可能会引发连锁更新操作，但这种操作出现的几率并不高。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%8E%8B%E7%BC%A9%E5%88%97%E8%A1%A8/"},{"title":"Redis哨兵模式","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-sentinel.html 什么是Redis哨兵模式Redis Sentinel 是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols)来接收关于主服务器是否下线的信息，并使用投票协议（agreement protocols）来决定是否执行自动故障迁移，以及选择哪个从服务器作为新的主服务器。 虽然 Redis Sentinel 释出为一个单独的可执行文件 redis-sentinel ， 但实际上它只是一个运行在特殊模式下的 Redis 服务器，你可以在启动一个普通 Redis 服务器时通过给定 --sentinel 选项来启动 Redis Sentinel 。 哨兵模式简介Sentinel(哨兵)是用于监控 redis 集群中 Master 状态的工具，是 Redis 的高可用性解决方案，sentinel 哨兵模式已经被集成在 redis2.4 之后的版本中。sentinel 是 redis 高可用的解决方案，sentinel 系统可以监视一个或者多个 redis master 服务，以及这些 master 服务的所有从服务；当某个 master 服务下线时，自动将该 master 下的某个从服务升级为 master 服务替代已下线的 master 服务继续处理请求。 sentinel 可以让 redis 实现主从复制，当一个集群中的 master 失效之后，sentinel 可以选举出一个新的 master 用于自动接替 master 的工作，集群中的其他 redis 服务器自动指向新的 master 同步数据。一般建议 sentinel 采取奇数台，防止某一台 sentinel 无法连接到 master 导致误切换。 Redis Sentinel作用Sentinel 系统用于管理多个 Redis 服务器（instance）， 该系统执行以下三个任务： 监控（Monitoring）： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时，Sentinel 会开始一次自动故障迁移操作，它会将失效主服务器的其中一个从服务器升级为新的主服务器，并让失效主服务器的其他从服务器改为复制新的主服务器；当客户端试图连接失效的主服务器时，集群也会向客户端返回新主服务器的地址， 使得集群可以使用新主服务器代替失效服务器。 Sentinel的工作方式 每个 Sentinel 以每秒钟一次的频率向它所知的 Master，Slave 以及其他 Sentinel 实例发送一个 PING 命令。 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值，则这个实例会被 Sentinel 标记为主观下线。 如果一个 Master 被标记为主观下线，则正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 的确进入了主观下线状态。 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态，则 Master 会被标记为客观下线。 在一般情况下，每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令。 当 Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次。 若没有足够数量的 Sentinel 同意 Master 已经下线，Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复，Master 的主观下线状态就会被移除。 Redis Sentinel优缺点优点 监控主数据库和从数据库是否正常运行 主数据库出现故障时，可以自动将从数据库转换为主数据库，实现自动切换 如果 redis 服务出现问题，会发送通知 缺点 主数据库出现故障时，选举切换的时候容易出现瞬间断线现象 不能自动扩容 Redis Sentinel原理首先， 哨兵模式是一种特殊的模式，它是 Redis 高可用的一种实现方案。首先哨兵是一个独立的进程， 可以实现对 Redis 实例的监控、通知、自动故障转移。 实际上，每个哨兵节点每秒通过 ping 去进行心跳监测（包括所有 redis 实例和 sentinel 同伴），并根据回复判断节点是否在线。 如果某个 sentinel 线程发现主库没有在给定时间（ down-after-milliseconds）内响应这个 PING，则这个 sentinel 线程认为主库是不可用的，这种情况叫 “主观失效”（即SDOWN）；这种情况一般不会引起马上的故障自动转移，但是当多个 sentinel 线程确实发现主库是不可用并超过 sentinel.conf 里面的配置项 sentinel monitor mymaster #ip #port #number 中的 #number 时候（这里实际上采用了流言协议），一般其余 sentinel 线程会通过 RAFT 算法推举领导的 sentinel 线程负责主库的客观下线并同时负责故障自动转移，这种情况叫 “客观失效”（即 ODOWN）。 具体流程如下图所示： 哨兵模式的配置项| 配置项 | 参数类型 | 作用 | | ——————————– | —————————- | ———————————————————— | | port | 整数 | 启动哨兵进程端口 | | dir | 文件夹目录 | 哨兵进程服务临时文件夹，默认为/tmp，要保证有可写入的权限 | | sentinel down-after-milliseconds | &lt;服务名称&gt;&lt;毫秒数（整数）&gt; | 指定哨兵在监控Redis服务时，当Redis服务在一个默认毫秒数内都无法回答时，单个哨兵认为的主观下线时间，默认为30000（30秒） | | sentinel parallel-syncs | &lt;服务名称&gt;&lt;服务器数（整数）&gt; | 指定可以有多少个Redis服务同步新的主机，一般而言，这个数字越小同步时间越长，而越大，则对网络资源要求越高 | | sentinel failover-timeout | &lt;服务名称&gt;&lt;毫秒数（整数）&gt; | 指定故障切换允许的毫秒数，超过这个时间，就认为故障切换失败，默认为3分钟 | | sentinel notification-script | &lt;服务名称&gt;&lt;脚本路径&gt; | 指定sentinel检测到该监控的redis实例指向的实例异常时，调用的报警脚本。该配置项可选，比较常用 | Redis哨兵模式配置说明Redis 三主三从可以最完整的保证数据的完整性，但是所需要的服务器资源也是最多的。在一般情况，统筹兼顾数据完整性和方案经济性，一般最优解是采用一主两从三哨兵的模式，我们使用的配置如下所示： | 实例 | IP | 端口 | 备注 | | ————- | ————– | —– | ——– | | Redis（主） | 192.168.33.135 | 9500 | | | Redis（从） | 192.168.33.136 | 9501 | | | Redis（从） | 192.168.33.133 | 9502 | | | Sentinel（1） | 192.168.33.135 | 26379 | 默认端口 | | Sentinel（2） | 192.168.33.136 | 26379 | 默认端口 | | Sentinel（3） | 192.168.33.133 | 26379 | 默认端口 | 创建目录首先，我们在 135 机器上，创建配置存放的目录，命令如下： 12mkdir -p /usr/local/redis/mastermkdir -p /usr/local/redis/sentinel 创建完毕，如下图所示： 接着，我们在 136 机器上，创建类似的目录，命令如下： 12mkdir -p /usr/local/redis/slavemkdir -p /usr/local/redis/sentinel 创建完毕，如下图所示： 最后，我们在 133 机器上，创建目录，命令如下： 12mkdir -p /usr/local/redis/slavemkdir -p /usr/local/redis/sentinel 创建完毕，如下图所示： 至此，所有的目录都创建完毕。 创建主从配置我们首先，在 135 机器上，创建 master 的配置，使用 vim 创建对应的配置文件，具体命令如下： 1vim /usr/local/redis/master/redis-master.conf 接着，我们写入如下配置内容： 123456bind 0.0.0.0port 9500logfile &quot;9500.log&quot;dbfilename &quot;dump-9500.rdb&quot;daemonize yesrdbcompression yes 接着，我们在 136 机器上，配置从的配置，使用 vim 创建对应的配置文件，具体命令如下： 1vim /usr/local/redis/slave/redis-slave.conf 接着，我们写入如下配置内容： 1234567bind 0.0.0.0port 9501logfile &quot;9501.log&quot;dbfilename &quot;dump-9501.rdb&quot;daemonize yesrdbcompression yesslaveof 192.168.33.135 9500 我们再次配置 133 机器上的从配置，使用 vim 创建对应的配置文件，具体命令如下： 1vim /usr/local/redis/slave/redis-slave.conf 接着，我们写入如下配置内容： 1234567bind 0.0.0.0port 9502logfile &quot;9502.log&quot;dbfilename &quot;dump-9502.rdb&quot;daemonize yesrdbcompression yesslaveof 192.168.33.135 9502 至此，我们的主从配置已经配置完毕了。 创建sentinel配置我们首先，在 135 机器上，创建 sentinel 的配置，使用 vim 创建对应的配置文件，具体命令如下： 1vim /usr/local/redis/sentinel/sentinel.conf 接着，我们写入如下配置内容： 123456789101112131415port 26379logfile &quot;26379.log&quot;daemonize yes# 这里定义主库的IP和端口，还有最后的2表示要达到2台sentinel认同才认为主库已经挂掉sentinel monitor mymaster 192.168.33.135 9500 2# 主库在30000毫秒（即30秒）内没有反应就认为主库挂掉（即主观失效） sentinel down-after-milliseconds mymaster 30000# 若新主库当选后，允许最大可以同时从新主库同步数据的从库数 sentinel parallel-syncs mymaster 1 # 若在指定时间（即180000毫秒，即180秒）内没有实现故障转移，则会自动再发起一次 sentinel failover-timeout mymaster 180000 接着，在 136 和 133 机器创建同样的配置文件，写入一模一样的配置内容。 启动我们首先，在 135 机器启动 Redis 主，具体命令如下： 1redis-server /usr/local/redis/master/redis-master.conf 接着，我们在 136 机器启动 Redis 从，具体命令如下： 1redis-server /usr/local/redis/slave/redis-slave.conf 同样，我们在 133 机器启动 Redis 从，具体命令如下： 1redis-server /usr/local/redis/slave/redis-slave.conf 至此，我们的主从已经启动完毕，现在，我们启动哨兵，首先在 135 机器启动，具体命令如下： 1redis-server /usr/local/redis/sentinel/sentinel.conf --sentinel 接着，在 133 和 136 输入相同的命令启动即可。注意，这里我们直接使用了 redis-server 命令启动了 sentinel，也可以直接使用 redis 提供的 redis-sentinel 工具直接启动。全部启动完毕之后，我们可以使用 ps 命令，查看，具体命令如下： 1ps -ef | grep redis-server 全部启动成功，则输出如下： 主从数据同步我们首先，使用 redis-cli 登录 redis master，即 135 机器的 9500 端口，具体命令如下： 1redis-cli -p 9500 接着，我们使用 GET 命令，查看键 URL 的内容，具体命令如下： 1GET URL 执行完毕后，如下图所示： 同时，我们在 136 机器的 slave 上即 9501 端口，同样查看 URL 的值，执行完毕后，如下图所示： 最后，我们同样在 133 的 slave 上即 9502 端口查看 URL 的值，执行完毕后，如下图所示： 我们看到，此时三个机器上的 URL 都为空，现在，我们在 135 机器的 9500 端口也就是 redis master 上设置 URL 的值，具体命令如下： 1SET URL www.haicoder.net 执行完毕后，如下图所示： 现在，我们可以在两台 slave 上，再次查看 URL 的值，我们发现，这两台 slave 都有对应的值了，如下图所示： 即，我们的主从配置完毕了。 高可用主从切换现在，我们验证高可用，也就是能够实现自动的主动切换，我们首先停掉 master，也就是 135 机器的 9500 端口，我们执行如下命令即可： 1shutdown 执行完毕后，如下图所示： 此时，我们模拟了主节点宕机了，现在，我们分别查看两个 slave 节点的配置，我们分别登录 133 和 136 机器的 slave，执行如下命令： 1INFO Replication 在 9501 端口执行后，输出如下： 我们看到，此时原来是 slave 的已经自动切换为了 master，这就是哨兵在起作用，实现了故障后的主备切换，如果这时候我们在新的 9501 的 master 上设置数据，并在 9502 端口查看数据，此时也是可以同步数据的。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F/"},{"title":"Redis底层数据结构","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-implement.html Redis 的五大数据类型也称五大数据对象，即分别为 **string**、 **list**、 **hash**、 set 和 **zset**，但 Redis 并没有直接使用这些结构来实现键值对数据库，而是使用这些结构构建了一个对象系统 redisObject。 这个对象系统包含了五大数据对象，字符串对象（string）、列表对象（list）、哈希对象（hash）、集合（set）对象和有序集合对象（zset）；而这五大对象的底层数据编码可以用命令 OBJECT ENCODING 来进行查看。 Redis对象Redis 基于上述的数据结构自定义一个 Object 系统，Object 结构，即 redisObject 结构： 123456789typedef struct redisObject{ //类型 unsigned type:4; //编码 unsigned encoding:4; //指向底层实现数据结构的指针 void *ptr; …..} Object 系统包含五种 Object： String：字符串对象 List：列表对象 Hash：哈希对象 Set：集合对象 ZSet：有序集合 Redis 使用对象来表示数据库中的键和值，即每新建一个键值对，至少创建有两个对象，而且使用对象的具有以下好处： redis 可以在执行命令前会根据对象的类型判断一个对象是否可以执行给定的命令。 针对不同的使用场景，为对象设置不同的数据结构实现，从而优化对象的不同场景夏的使用效率。 对象系统还可以基于引用计数计数的内存回收机制，自动释放对象所占用的内存，或者还可以让多个数据库键共享同一个对象来节约内存。 redis 对象带有访问时间记录信息，使用该信息可以进行优化空转时长较大的 key，进行删除！ 对象的 ptr 指针指向对象的底层现实数据结构，而这些数据结构由对象的 encoding 属性决定，对应关系： | 编码常量 | 编码对应的底层数据结构 | | ————————- | ————————— | | REDIS_ENCODING_INT | long 类型的整数 | | REDIS_ENCODING_EMBSTR | embstr 编码的简单动态字符串 | | REDIS_ENCODING_RAW | 简单动态字符串 | | REDIS_ENCODING_HT | 字典 | | REDIS_ENCODING_LINKEDLIST | 双向链表 | | REDIS_ENCODING_ZIPLIST | 压缩列表 | | REDIS_ENCODING_INTSET | 整数集合 | | REDIS_ENCODING_SKIPLIST | 跳跃表和字典 | 每种 Object 对象至少有两种不同的编码，对应关系： | 类型 | 编码 | 对象 | | ———- | ———- | —————– | | String | int | 整数值实现 | | String | embstr | sds实现 &lt;=39 字节 | | String | raw | sds实现 &gt; 39字节 | | List | ziplist | 压缩列表实现 | | List | linkedlist | 双端链表实现 | | Set | intset | 整数集合使用 | | Set | hashtable | 字典实现 | | Hash | ziplist | 压缩列表实现 | | Hash | hashtable | 字典使用 | | Sorted set | ziplist | 压缩列表实现 | | Sorted set | skiplist | 跳跃表和字典 | String对象实现说明字符串对象底层数据结构实现为简单动态字符串（SDS）和直接存储，但其编码方式可以是 int、raw 或者 embstr，区别在于内存结构的不同。 结构int编码字符串保存的是整数值，并且这个正式可以用 long 类型来表示，那么其就会直接保存在 redisObject 的 ptr 属性里，并将编码设置为 int，如图： raw编码字符串保存的大于 32 字节的字符串值，则使用简单动态字符串（SDS）结构，并将编码设置为 raw，此时内存结构与 SDS 结构一致，内存分配次数为两次，创建 redisObject 对象和 sdshdr 结构，如图： embstr编码字符串保存的小于等于 32 字节的字符串值，使用的也是简单的动态字符串（SDS 结构），但是内存结构做了优化，用于保存顿消的字符串；内存分配也只需要一次就可完成，分配一块连续的空间即可，如图： String对象之间的编码转换int 编码的字符串对象和 embstr 编码的字符串对象在条件满足的情况下，会被转换为 raw 编码的字符串对象。比如：对 int 编码的字符串对象进行 append 命令时，就会使得原来是 int 变为 raw 编码字符串。 C字符串与SDS| C 字符串 | SDS | | ———————————————- | —————————————— | | 获取字符串长度的复杂度为 O(N) | 获取字符串长度的复杂度为 O(1) | | API 是不安全的，可能会造成缓冲区溢出 | API 是安全的，不会造成缓冲区溢出 | | 修改字符串长度 N 次必然需要执行 N 次内存重分配 | 修改字符串长度 N 次最多执行 N 次内存重分配 | | 只能保存文本数据 | 可以保存二进制数据和文本文数据 | | 可以使用所有 &lt;String.h&gt; 库中的函数 | 可以使用一部分 &lt;string.h&gt; 库中的函数 | 总结 在 Redis 中，存储 long、double 类型的浮点数是先转换为字符串再进行存储的。 raw 与 embstr 编码效果是相同的，不同在于内存分配与释放，raw 两次，embstr 一次。 embstr 内存块连续，能更好的利用缓存在来的优势。 int 编码和 embstr 编码如果做追加字符串等操作，满足条件下会被转换为 raw 编码；embstr 编码的对象是只读的，一旦修改会先转码到 raw。 List对象说明list 对象可以为 ziplist 或者为 linkedlist，对应底层实现 ziplist 为压缩列表，linkedlist 为双向列表。 结构比如如下结构： 1Redis&gt; RPUSH numbers &quot;CcWw&quot; 520 1 用 ziplist 编码的 List 对象结构： 用 linkedlist 编码的 List 对象结构： 压缩表结构压缩表各部分组成说明如下： zlbytes：记录整个压缩列表占用的内存字节数，在压缩列表内存重分配，或者计算 zlend 的位置时使用。 zltail：记录压缩列表表尾节点距离压缩列表的起始地址有多少字节，通过该偏移量，可以不用遍历整个压缩列表就可以确定表尾节点的地址。 zllen：记录压缩列表包含的节点数量，但该属性值小于 UINT16_MAX（65535）时，该值就是压缩列表的节点数量，否则需要遍历整个压缩列表才能计算出真实的节点数量。 entryX：压缩列表的节点。 zlend：特殊值 0xFF（十进制 255），用于标记压缩列表的末端。 List对象的编码转换当 list 对象可以同时满足以下两个条件时，list 对象使用的是 ziplist 编码： list 对象保存的所有字符串元素的长度都小于 64 字节。 list 对象保存的元素数量小于 512 个。 不能满足这两个条件的 list 对象需要使用 linkedlist 编码。 Hash对象说明Hash 对象的编码可以是 ziplist 或者 hashtable，其中，ziplist 底层使用压缩列表实现： 保存同一键值对的两个节点紧靠相邻，键 key 在前，值 vaule 在后。 先保存的键值对在压缩列表的表头方向，后来在表尾方向。 hashtable 底层使用字典实现，Hash 对象种的每个键值对都使用一个字典键值对保存： 字典的键为字符串对象，保存键 key。 字典的值也为字符串对象，保存键值对的值。 结构比如 HSET 命令： 123456redis&gt;HSET author name &quot;Ccww&quot;(integer)redis&gt;HSET author age 18(integer)redis&gt;HSET author sex &quot;male&quot;(integer) ziplist 的底层结构： hashtable 底层结构： Hash对象的编码转换当 list 对象可以同时满足以下两个条件时，list 对象使用的是 ziplist 编码： list 对象保存的所有字符串元素的长度都小于 64 字节。 list 对象保存的元素数量小于 512 个。 不能满足这两个条件的 hash 对象需要使用 hashtable 编码，但这两个条件的上限值是可以修改的，可查看配置文件 hash-max-zaiplist-value 和 hash-max-ziplist-entries。 Set对象说明Set 对象的编码可以为 intset 或者 hashtable： intset 编码：使用整数集合作为底层实现，set 对象包含的所有元素都被保存在 intset 整数集合里面。 hashtable 编码：使用字典作为底层实现，字典键 key 包含一个 set 元素，而字典的值则都为 null。 结构inset 编码 Set 对象结构： 1redis&gt; SAD number 1 3 5 hashtable 编码 Set 对象结构： 1redis&gt; SAD Dfruits “apple” &quot;banana&quot; &quot; cherry&quot; Set对象的编码转换使用 intset 编码： set 对象保存的所有元素都是整数值。 set 对象保存的元素数量不超过 512 个。 不能满足这两个条件的 Set 对象使用 hashtable 编码。 ZSet对象说明ZSet 对象的编码可以为 ziplist 或者 skiplist，ziplist 编码，每个集合元素使用相邻的两个压缩列表节点保存，一个保存元素成员，一个保存元素的分值，然后根据分数进行从小到大排序。 结构ziplist 编码的 ZSet 对象结构： 1Redis&gt;ZADD price 8.5 apple 5.0 banana 6.0 cherry skiplist 编码的 ZSet 对象使用了 zset 结构，包含一个字典和一个跳跃表： 12345Type struct zset{ Zskiplist *zsl； dict *dict； ...} ZSet对象的编码转换当 ZSet 对象同时满足以下两个条件时，对象使用 ziplist 编码： 有序集合保存的元素数量小于 128 个。 有序集合保存的所有元素的长度都小于 64 字节。 不能满足以上两个条件的有序集合对象将使用 skiplist 编码，同时，可以通过配置文件中 zset-max-ziplist-entries 和 zset-max-ziplist-vaule 来改变这个数值。 Redis底层数据结构总结Redis 的 redisObject 结构如下图： 五大数据类型对应的底层数据结构如下图所示：","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"Redis线程模型","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-thread.html Redis事件不是讲线程模型吗？和事件有什么关系？实际上 Redis 是一个事件驱动程序，大白话理解一下：就是通过事件的方式来运行 Redis 的。比如客户端向服务端发起一个 get 请求，在做好了建连、发送请求、响应请求、关闭连接等准备操作后，就触发了一个事件。所以在了解线程模型之前，先来看看事件。 Redis 的事件分为两种，分别是文件事件和时间事件两种。 文件事件文件事件是 socket 的一个抽象，客户端发送请求到服务端，会先建立连接，然后通过连接发送命令请求，其中每个连接就是一个 socket。对于一个 Redis 服务端，在同一时刻会有很多 socket 连接，每一个 socket 都可以理解成一个文件事件。 每产生一个文件事件后，就将其交给文件事件处理器去处理，文件事件处理器是由 I/O 多路复用处理器、文件事件分发器、事件处理器几部分组成。服务端在接收到请求后，是怎么工作的呢？ 从上图可以看出，当客户端发送请求到服务端后； 首先服务端通过 I/O 多路复用处理器接收文件事件（即一个一个的 socket），并将接收到的文件事件插入到事件队列中。 接收文件事件分发器将接收到的时间按照事件类型分发给不同的事件处理器去执行；比如客户端发送了一个 get 请求，文件事件处理器就会将该请求发送给读取事件处理器去执行。 相应的事件处理器接收到请求后，就去执行相应的操作，然后将相应的结果返回。 当一个事件处理完毕并返回相应的结果后，文件事件分发器继续处理事件队列中的下一个请求，重复上述的动作，直到没有文件事件可以被处理。这个流程其实有点像生产者消费者的样子。 I/O 对路复用处理器在 Redis 中用很多种实现，比如 epool、select、evport、kquene 等等，Redis 服务端在运行的时候会根据预先设定的 include 宏定义来选择效率最高的模型去处理网络事件。 以上基本上就是 Redis 的线程工作模型，不过还差一点就是文章开头讲到的另外一种事件类型，时间事件。 时间事件时间事件，顾名思义就是和时间相关的一些事件操作。举个例子，在 Redis 中最不陌生的应该就是各种定时处理器，每隔一段时间就出发一个操作。具体的应用如 RDB 和 AOF 文件定时做持久化操作；如果集群是主从架构的，定时将主库上的数据同步给从库，定期发送心跳信息给集群内各个节点，检查节点是否还在正常提供服务；定期检查库里面设置了过期时间的 key 并将已过期的 key 从内存中提出等等一些实际应用。 时间事件是怎么实现的？ Redis 将所有时间事件通过链表串联起来，每个结点代表一个时间事件，每个结点上存储着当前时间下一次要发生的时间点；每隔一段时间，该链表就会被遍历一次，发现那个时间事件该执行就去执行对应的事件，然后更新其下一次应该执行的时间点。 文件事件和时间事件是怎么配合工作的？ 如上图，文件事件和时间事件配合工作流程图。 服务器启动后，开始监听文件事件，如果在一段时间内有监听到文件事件，则会执行文件事件，执行完文件事件后，开始遍历时间事件，这里需要注意的是，如果文件事件执行时间过长，不会让其一直执行，而是暂停，等待下一个周期在继续执行。 文件事件执行完，开始遍历执行时间事件，遇到需要执行的时间事件，比如定时持久化 RDB 和 AOF 等比较耗时的操作时，会 Fork 出一个子线程去执行，而不会夯住当前线程。 依次循环上述流程，就完成了文件事件和时间事件的配合工作的流程了。 Redis6.0为什么要引入多线程相信很多朋友已经知道了，2020 年 Redis 官方在 5 月份发布多了多线程版本，不过默认是不开启的，可通过 conf 配置开启。从目前 Redis 在实际生产环境中的使用情况看，其每秒钟支持的吞吐量已经非常高了。Redis 发展到目前，其主要的性能瓶颈主要在网络 I/O 和内存两个方面。 内存容量问题：如果采用集群部署的方式，可以通过部署多个端口，使得总容量得到提升，在一定程度上可以解决内存的问题。 网络 I/O 问题：在实际生产环境中，Redis 在执行命令时计算基于内存是可以在很快时间内完成的，但是数据传输过程中需要经过网络 I/O 操作，这一步才是真正耗时所在。所以 Redis 在 6.0 版本引入了所谓的多线程，其主要是在做网络 I/O 操作的时候采用了多线程的方式加快 I/O 操作，而命令的执行还是采用单线程进行工作的。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/"},{"title":"Redis整数集合","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-inset.html Redis 中的整数集合(intset)并不是一个基础的数据结构，而是 Redis 自己设计的一种存储结构，是集合键的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时, Redis 就会使用整数集合作为集合键的底层实现。 整数集合实现整数集合(intset)是 Redis 用于保存整数值的集合抽象数据结构，它可以保存类型为 int16_t、int32_t 或者 int64_t 的整数值，并且保证集合中不会出现重复元素。结构定义如下： 123456789//每个intset结构表示一个整数集合typedef struct intset{ //编码方式 uint32_t encoding; //集合中包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];} intset; contents 数组是整数集合的底层实现，整数集合的每个元素都是 contents 数组的个数组项(item)，各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项。 length 属性记录了数组的长度。 intset 结构将 contents 属性声明为 int8_t 类型的数组，但实际上 contents 数组并不保存任何 int8_t 类型的值, contents 数组的真正类型取决于 encoding 属性的值。encoding 属性的值为 INTSET_ENC_INT16 则数组就是 uint16_t 类型，数组中的每一个元素都是 int16_t 类型的整数值(-32768——32767)，encoding 属性的值为 INTSET_ENC_INT32 则数组就是 uint32_t 类型，数组中的每一个元素都是 int16_t 类型的整数值(-2147483648——2147483647)。 结构如下图所示： 如上图，为一 int16_t 类型的整数集合，我们可以看到数组中存储了 5 个 int16_t 类型的整数，它们按照从小到大的顺序依次排列。这个时候我们思考一个问题。如果这个时候存入一个 int32_t 类型的整数会怎么样？内存溢出？这个时候就要提到整数集合的升级。 整数集合的升级升级过程正如上面所提到的问题，每当我们要将一个新元素添加到整数集合里面，并且新元素的类型比整数集合现有所有元素的类型都要长时，整数集合需要先进行升级，然后才能将新元素添加到整数集合里面。升级整数集合并添加新元素主要分三步来进行。 根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间。 将底层数组现有的所有元素都转换成与新元素相同的类型，并将类型转换后的元素放置到正确的位上，而且在放置元素的过程中，需要继续维持底层数组的有序性质不变。 将新元素添加到底层数组里面。 整数集合升级的优点提升灵活性因为 C 语言 是静态类型语言，为了避免类型错误，我们通常不会将两种不同类型的值放在同一个数据结构里面。 例如，我们一般只使用 int16_t 类型的数组来保存 int16_t 类型的值，只使用 int32_t 类型的数组来保存 int32_t 类型的值，诸如此类。但是，因为整数集合可以通过自动升级底层数组来适应新元素，所以我们可以随意地将 int16_t、int32_t 或者 int64_t 类型的整数添加到集合中，而不必担心出现类型错误，这种做法非常灵活。 节约内存要让一个数组可以同时保存 int16_t、int32_t、int64_t 三种类型的值，最简单的做法就是直接使用 int64_t 类型的数组作为整数集合的底层实现。不过这样一来，即使添加到整数集合里面的都是 int16_t 类型或者 int32_t 类型的值，数组都需要使用 int64_t 类型的空间去保存它们，从而出现浪费内存的情况。 而整数集合现在的做法既可以让集合能同时保存三种不同类型的值，又可以确保升级操作只会在有需要的时候进行，这可以尽量节省内存。如果我们一直只向整数集合添加 int16_t 类型的值，那么整数集合的底层实现就会一直是 int16_t 类型的数组，只有在我们要将 int32_t 类型或者 int64_t 类型的值添加到集合时，程序才会对数组进行升级。 降级整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态。也就是说一旦我们向一个 int16_t 的整数集合内添加了一个 int32_t 的元素后，整数集合将升级到 int32_t 类型。即使后续的操作中我们删除了这个元素，整数集合还是会保持 int32_t 类型的状态。 整数集合常用操作时间复杂度| 操作 | 时间复杂度 | | ———————— | ———- | | 创建一个新的整数集合 | O(1) | | 添加指定元素到集合 | O(N) | | 移除指定元素 | O(N) | | 判断指定元素是否在集合中 | O(logN) | | 随机返回一个元素 | O(1) | | 取出在指定索引上的元素 | O(1) | | 返回集合包含的元素个数 | O(1) | | 返回集合占用的内存字节数 | O(1) | 总结 整数集合是 Redis 自己设计的一种存储结构，集合键的底层实现之一。 整数集合的底层实现为数组，这个数组以有序、无重复的方式保存集合元素，在有需要时，程序会根据新添加元素的类型，改变这个数组的类型。 升级操作为整数集合带来了操作上的灵活性，并且尽可能地节约了内存。 整数集合只支持升级操作，不支持降级操作。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E6%95%B4%E6%95%B0%E9%9B%86%E5%90%88/"},{"title":"Redis脚本","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-lua-script.html Redis为什么引入LuaRedis 是高性能的 key-value 内存数据库，在部分场景下，是对关系数据库的良好补充。Redis 提供了非常丰富的指令集，官网上提供了 200 多个命令。但是某些特定领域，需要扩充若干指令原子性执行时，仅使用原生命令便无法完成。Redis 意识到上述问题后，在 2.6 版本推出了 lua 脚本功能，允许开发者使用 Lua 语言编写脚本传到 Redis 中执行。 用户可以向 Redis 服务器发送 lua 脚本来执行自定义动作，获取脚本的响应数据。Redis 服务器会单线程原子性执行 lua 脚本，保证 lua 脚本在处理的过程中不会被任意其它请求打断。 使用Lua脚本好处减少网络开销：可以将多个请求通过脚本的形式一次发送，减少网络时延。 原子操作：Redis 会将整个脚本作为一个整体执行，中间不会被其他请求插入。因此在脚本运行过程中无需担心会出现竞态条件，无需使用事务。 复用：客户端发送的脚本会永久存在 redis 中，这样其他客户端可以复用这一脚本，而不需要使用代码完成相同的逻辑。 可嵌入性：可嵌入 **JAVA**，C# 等多种编程语言，支持不同操作系统跨平台交互。 什么是LuaLua 是一种轻量小巧的脚本语言，用标准 C 语言 编写并以源代码形式开放。其设计目的就是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。因为广泛的应用于：游戏开发、独立应用脚本、Web 应用脚本、扩展和数据库插件等。 比如：Lua 脚本用在很多游戏上，主要是 Lua 脚本可以嵌入到其他程序中运行，游戏升级的时候，可以直接升级脚本，而不用重新安装游戏。 Redis Lua相关命令| 命令 | 描述 | | ————- | —————————————————— | | EVAL | 执行 Lua 脚本 | | EVALSHA | 执行 Lua 脚本 | | SCRIPT EXISTS | 查看指定的脚本是否已经被保存在缓存当中 | | SCRIPT FLUSH | 从脚本缓存中移除所有脚本 | | SCRIPT KILL | 杀死当前正在运行的 Lua 脚本 | | SCRIPT LOAD | 将脚本 script 添加到脚本缓存中，但并不立即执行这个脚本 | EVAL命令语法1EVAL script numkeys key [key …] arg [arg …] 参数| 命令 | 描述 | | ———– | ———————————————————— | | script | 参数是一段 Lua5.1 脚本程序。脚本不必(也不应该 [^1] )定义为一个 Lua 函数 | | numkeys | 指定后续参数有几个 key，即：key [key …] 中 key 的个数。如没有 key，则为 0 | | key [key …] | 从 EVAL 的第三个参数开始算起，表示在脚本中所用到的那些 Redis 键(key)。在 Lua 脚本中通过 KEYS[1], KEYS[2] 获取 | | arg [arg …] | 附加参数。在 Lua 脚本中通过 ARGV[1], ARGV[2] 获取。 | 案例案例一： 123# 例1：numkeys=1，keys数组只有1个元素key1，arg数组无元素127.0.0.1:6379&gt; EVAL &quot;return KEYS[1]&quot; 1 key1&quot;key1&quot; 案例二： 123# 例2：numkeys=0，keys数组无元素，arg数组元素中有1个元素value1127.0.0.1:6379&gt; EVAL &quot;return ARGV[1]&quot; 0 value1&quot;value1&quot; 案例三： 123456789# 例3：numkeys=2，keys数组有两个元素key1和key2，arg数组元素中有两个元素first和second # 其实{KEYS[1],KEYS[2],ARGV[1],ARGV[2]}表示的是Lua语法中“使用默认索引”的table表，# 相当于java中的map中存放四条数据。Key分别为：1、2、3、4，而对应的value才是：KEYS[1]、KEYS[2]、ARGV[1]、ARGV[2]# 举此例子仅为说明eval命令中参数的如何使用。项目中编写Lua脚本最好遵从key、arg的规范。127.0.0.1:6379&gt; eval &quot;return {KEYS[1],KEYS[2],ARGV[1],ARGV[2]}&quot; 2 key1 key2 first second 1) &quot;key1&quot;2) &quot;key2&quot;3) &quot;first&quot;4) &quot;second&quot; 案例四： 12345678910# 例4：使用了redis为lua内置的redis.call函数# 脚本内容为：先执行SET命令，在执行EXPIRE命令# numkeys=1，keys数组有一个元素userAge（代表redis的key）# arg数组元素中有两个元素：10（代表userAge对应的value）和60（代表redis的存活时间）127.0.0.1:6379&gt; EVAL &quot;redis.call('SET', KEYS[1], ARGV[1]);redis.call('EXPIRE', KEYS[1], ARGV[2]); return 1;&quot; 1 userAge 10 60(integer) 1127.0.0.1:6379&gt; get userAge&quot;10&quot;127.0.0.1:6379&gt; ttl userAge(integer) 44 通过上面的例 4，我们可以发现，脚本中使用 redis.call() 去调用 redis 的命令。在 Lua 脚本中，可以使用两个不同函数来执行 Redis 命令，它们分别是： redis.call() 和 redis.pcall()。 这两个函数的唯一区别在于它们使用不同的方式处理执行命令所产生的错误，差别为，当 redis.call() 在执行命令的过程中发生错误时，脚本会停止执行，并返回一个脚本错误，错误的输出信息会说明错误造成的原因： 1234127.0.0.1:6379&gt; lpush foo a(integer) 1127.0.0.1:6379&gt; eval &quot;return redis.call('get', 'foo')&quot; 0(error) ERR Error running script (call to f_282297a0228f48cd3fc6a55de6316f31422f5d17): ERR Operation against a key holding the wrong kind of value 和 redis.call() 不同， redis.pcall() 出错时并不引发(raise)错误，而是返回一个带 err 域的 Lua 表(table)，用于表示错误： 12127.0.0.1:6379&gt; EVAL &quot;return redis.pcall('get', 'foo')&quot; 0(error) ERR Operation against a key holding the wrong kind of value SCRIPT LOAD命令和EVALSHA命令SCRIPT LOAD命令语法1SCRIPT LOAD script SCRIPT EVALSHA命令语法1EVALSHA sha1 numkeys key [key …] arg [arg …] 这两个命令放在一起讲的原因是：EVALSHA 命令中的 sha1 参数，就是 SCRIPT LOAD 命令执行的结果。SCRIPT LOAD 将脚本 script 添加到 Redis 服务器的脚本缓存中，并不立即执行这个脚本，而是会立即对输入的脚本进行求值。并返回给定脚本的 SHA1 校验和。如果给定的脚本已经在缓存里面了，那么不执行任何操作。 在脚本被加入到缓存之后，在任何客户端通过 EVALSHA 命令，可以使用脚本的 SHA1 校验和来调用这个脚本。脚本可以在缓存中保留无限长的时间，直到执行 SCRIPT FLUSH 为止。 案例1234567891011## SCRIPT LOAD加载脚本，并得到sha1值127.0.0.1:6379&gt; SCRIPT LOAD &quot;redis.call('SET', KEYS[1], ARGV[1]);redis.call('EXPIRE', KEYS[1], ARGV[2]); return 1;&quot;&quot;6aeea4b3e96171ef835a78178fceadf1a5dbe345&quot;## EVALSHA使用sha1值，并拼装和EVAL类似的numkeys和key数组、arg数组，调用脚本。127.0.0.1:6379&gt; EVALSHA 6aeea4b3e96171ef835a78178fceadf1a5dbe345 1 userAge 10 60(integer) 1127.0.0.1:6379&gt; get userAge&quot;10&quot;127.0.0.1:6379&gt; ttl userAge(integer) 43 SCRIPT EXISTS命令语法1SCRIPT EXISTS sha1 [sha1 …] 说明给定一个或多个脚本的 SHA1 校验和，返回一个包含 0 和 1 的列表，表示校验和所指定的脚本是否已经被保存在缓存当中。 案例1234567127.0.0.1:6379&gt; SCRIPT EXISTS 6aeea4b3e96171ef835a78178fceadf1a5dbe3451) (integer) 1127.0.0.1:6379&gt; SCRIPT EXISTS 6aeea4b3e96171ef835a78178fceadf1a5dbe3461) (integer) 0127.0.0.1:6379&gt; SCRIPT EXISTS 6aeea4b3e96171ef835a78178fceadf1a5dbe345 6aeea4b3e96171ef835a78178fceadf1a5dbe3661) (integer) 12) (integer) 0 SCRIPT FLUSH命令语法1SCRIPT FLUSH 说明清除 Redis 服务端所有 Lua 脚本缓存。 案例123456127.0.0.1:6379&gt; SCRIPT EXISTS 6aeea4b3e96171ef835a78178fceadf1a5dbe3451) (integer) 1127.0.0.1:6379&gt; SCRIPT FLUSHOK127.0.0.1:6379&gt; SCRIPT EXISTS 6aeea4b3e96171ef835a78178fceadf1a5dbe3451) (integer) 0 SCRIPT KILL命令语法1SCRIPT KILL 说明杀死当前正在运行的 Lua 脚本，当且仅当这个脚本没有执行过任何写操作时，这个命令才生效。 这个命令主要用于终止运行时间过长的脚本，比如一个因为 BUG 而发生无限 loop 的脚本，诸如此类。 假如当前正在运行的脚本已经执行过写操作，那么即使执行 SCRIPT KILL，也无法将它杀死，因为这是违反 Lua 脚本的原子性执行原则的。在这种情况下，唯一可行的办法是使用 SHUTDOWN NOSAVE 命令，通过停止整个 Redis 进程来停止脚本的运行，并防止不完整(half-written)的信息被写入数据库中。 Redis执行Lua文件编写Lua脚本文件123456789local key = KEYS[1]local val = redis.call(&quot;GET&quot;, key);if val == ARGV[1]then redis.call('SET', KEYS[1], ARGV[2]) return 1else return 0end 执行Lua脚本文件12# 执行命令： redis-cli -a 密码 --eval Lua脚本路径 key [key …] , arg [arg …] 如：redis-cli -a 123456 --eval ./Redis_CompareAndSet.lua userName , zhangsan lisi “–eval” 而不是命令模式中的 “eval”，一定要有前端的两个 -，脚本路径后紧跟 key [key …]，相比命令行模式，少了 numkeys 这个 key 数量值。 key [key …] 和 arg [arg …] 之间的 “ , ”，英文逗号前后必须有空格，否则死活都报错。 12345678910111213## Redis客户端执行127.0.0.1:6379&gt; set userName zhangsan OK127.0.0.1:6379&gt; get userName&quot;zhangsan&quot;## linux服务器执行## 第一次执行：compareAndSet成功，返回1## 第二次执行：compareAndSet失败，返回0[root@vm01 learn_lua]# redis-cli -a 123456 --eval Redis_CompareAndSet.lua userName , zhangsan lisi(integer) 1[root@vm01 learn_lua]# redis-cli -a 123456 --eval Redis_CompareAndSet.lua userName , zhangsan lisi(integer) 0 脚本超时Redis 的配置文件中提供了如下配置项来规定最大执行时长： 12# Lua脚本最大执行时间，默认5秒Lua-time-limit 5000 但这里有个坑，当一个脚本达到最大执行时长的时候，Redis 并不会强制停止脚本的运行，仅仅在日志里打印个警告，告知有脚本超时。为什么不能直接停掉呢？ 因为 Redis 必须保证脚本执行的原子性，中途停止可能导致内存的数据集上只修改了部分数据。如果时长达到 Lua-time-limit 规定的最大执行时间，Redis 只会做这几件事情： 日志记录有脚本运行超时。 开始允许接受其他客户端请求，但仅限于 SCRIPT KILL 和 SHUTDOWN NOSAVE 两个命令，其他请求仍返回 busy 错误。 脚本死循环怎么办Redis 的指令执行是个单线程，这个单线程还要执行来自客户端的 lua 脚本。如果 lua 脚本中来一个死循环，是不是 Redis 就完蛋了？Redis 为了解决这个问题，它提供了 script kill 指令用于动态杀死一个执行时间超时的 lua 脚本。 不过 script kill 的执行有一个重要的前提，那就是当前正在执行的脚本没有对 Redis 的内部数据状态进行修改，因为 Redis 不允许 script kill 破坏脚本执行的原子性。比如脚本内部使用了 redis.call(“set”, key, value) 修改了内部的数据，那么 script kill 执行时服务器会返回错误。 Script Kill的原理lua 脚本引擎功能太强大了，它提供了各式各样的钩子函数，它允许在内部虚拟机执行指令时运行钩子代码。比如每执行 N 条指令执行一次某个钩子函数，Redis 正是使用了这个钩子函数。 脚本的安全性如生成随机数这一命令，如果在 master 上执行完后，再在 slave 上执行会不一样，这就破坏了主从节点的一致性。为了解决这个问题， Redis 对 Lua 环境所能执行的脚本做了一个严格的限制，所有脚本都必须是无副作用的纯函数（pure function）。所有刚才说的那种情况压根不存在。Redis 对 Lua 环境做了一些列相应的措施： 不提供访问系统状态状态的库（比如系统时间库）。 禁止使用 loadfile 函数。 如果脚本在执行带有随机性质的命令（比如 RANDOMKEY ），或者带有副作用的命令（比如 TIME ）之后，试图执行一个写入命令（比如 SET ），那么 Redis 将阻止这个脚本继续运行，并返回一个错误。 如果脚本执行了带有随机性质的读命令（比如 SMEMBERS ），那么在脚本的输出返回给 Redis 之前，会先被执行一个自动的字典序排序，从而确保输出结果是有序的。 用 Redis 自己定义的随机生成函数，替换 Lua 环境中 math 表原有的 math.random 函数和 math.randomseed 函数，新的函数具有这样的性质：每次执行 Lua 脚本时，除非显式地调用 math.randomseed ，否则 math.random 生成的伪随机数序列总是相同的。 Redis脚本应用举例在我们项目中，有一个两对玩家进行 PK 的功能，这时候，我们需要存储每个玩家的 Id 与当前 PK 状态的映射关系，因为每组玩家都有好几个，同时，我们还要存储 PK 房间与 PK 的详细信息的映射，这些信息都是存储在 Redis 里面的，并且都需要是原子操作，因此，我们使用了 Lua 脚本来实现的。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E8%84%9A%E6%9C%AC/"},{"title":"Redis过期策略及实现原理","text":"原文: https://haicoder.net/note/redis-interview/redis-interview-redis-expire.html 描述我们在使用 Redis 时，一般会设置一个过期时间，当然也有不设置过期时间的，也就是永久不过期。当我们设置了过期时间，Redis 是如何判断是否过期，以及根据什么策略来进行删除的。 redis过期时间设置语法12345# 以秒为单位设置过期，这是最常用的方式EXPIRE KEY time# 字符串独有的方式SETEX KEY_NAME TIMEOUT VALUE 说明除了 字符串 自己独有设置过期时间的方法外，其他方法都需要依靠 EXPIRE 方法来设置时间，如果没有设置时间，那缓存就是永不过期。 如果设置了过期时间，之后又想让缓存永不过期，使用 **persist KEY**。 三种过期策略定时删除含义在设置 KEY 的过期时间的同时，为该 KEY 创建一个定时器，让定时器在 KEY 的过期时间来临时，对 KEY 进行删除。 优点该方法可以保证内存被尽快释放。 缺点若过期 KEY 很多，删除这些 KEY 会占用很多的 CPU 时间，在 CPU 时间紧张的情况下，CPU 不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些 KEY。 定时器的创建耗时，若为每一个设置过期时间的 KEY 创建一个定时器（将会有大量的定时器产生），性能影响严重。 懒汉式删除含义KEY 过期的时候不删除，每次通过 KEY 获取值的时候去检查是否过期，若过期，则删除，返回 null。 优点删除操作只发生在通过 KEY 取值的时候，而且只删除当前 KEY，所以对 CPU 时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的 KEY 了）。 缺点若大量的 KEY 在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）。 定期删除含义每隔一段时间执行一次删除过期 KEY 操作。 优点通过限制删除操作的时长和频率，来减少删除操作对 CPU 时间的占用。 缺点在内存友好方面，不如 ”定时删除”（会造成一定的内存占用，但是没有懒汉式那么占用内存），在 CPU 时间友好方面，不如 ”懒汉式删除”（会定期的去进行比较和删除操作，cpu 方面不如懒汉式，但是比定时好）。 难点是合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了），每次执行时间太长，或者执行频率太高对 cpu 都是一种压力。每次进行定期删除操作执行之后，需要记录遍历循环到了哪个标志位，以便下一次定期时间来时，从上次位置开始进行循环遍历。 说明memcached 只是用了惰性删除，而 redis 同时使用了惰性删除与定期删除，这也是二者的一个不同点（可以看做是 redis 优于 memcached 的一点）。 对于懒汉式删除而言，并不是只有获取 KEY 的时候才会检查 KEY 是否过期，在某些设置 KEY 的方法上也会检查，比如 SETNX 命令，因为 SETNX 命令是在 KEY 不存在的情况下才设置，因为，如果不做过期 KEY 检查，那么直接设置，就会与我们原来的意思相违背。 定时任务单线程的 redis，如何知道要运行定时任务？ redis 是单线程的，线程不但要处理定时任务，还要处理客户端请求，线程不能阻塞在定时任务或处理客户端请求上，那么，redis 是如何知道何时该运行定时任务的呢？ Redis 的定时任务会记录在一个称为最小堆的数据结构中。这个堆中，最快要执行的任务排在堆的最上方。在每个循环周期，Redis 都会将最小堆里面已经到点的任务立即进行处理。处理完毕后，将最快要执行的任务还需要的时间记录下来，这个时间就是接下来处理客户端请求的最大时长，若达到了该时长，则暂时不处理客户端请求而去运行定时任务。 配置Redis 中定期删除使用的是统一的一个定时器，定时器执行的时长默认为 10，具体配置如下： 提高它的值将会占用更多的 cpu，当然相应的 redis 将会更快的处理同时到期的许多 key，以及更精确的去处理超时。 hz 的取值范围是 1~500，通常不建议超过 100，只有在请求延时非常低的情况下可以将值提升到 100。 Redis采用的过期策略说明Redis 采用的是懒汉式删除+定期删除。 懒汉式删除流程 在进行 GET 或 SETNX 等操作时，先检查 KEY 是否过期； 若过期，删除 KEY，然后执行相应操作； 若没过期，直接执行相应操作； 定期删除流程简单而言，对指定 N 个库的每一个库随机删除小于等于指定 M 个过期 KEY，具体流程如下： 遍历每个数据库（就是 redis.conf 中配置的 ”database” 数量，默认为 16） 检查当前库中的指定个数个 KEY（默认是每个库检查 20 个 KEY，注意相当于该循环执行 20 次，循环体是下边的描述） 如果当前库中没有一个 KEY 设置了过期时间，直接执行下一个库的遍历随机 获取一个设置了过期时间的 KEY，检查该 KEY 是否过期，如果过期，删除 KEY 判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。 对于定期删除，在程序中有一个全局变量 current_db 来记录下一个将要遍历的库，假设有 16 个库，我们这一次定期删除遍历了 10 个，那此时的 current_db 就是 11，下一次定期删除就从第 11 个库开始遍历，假设 current_db 等于 15 了，那么之后遍历就再从 0 号库开始（此时 current_db==0）。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%8F%8A%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"},{"title":"Redis集群Twemproxy与Codis","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-twemproxy-codis.html Redis常见集群技术长期以来，**Redis** 本身仅支持单实例，内存一般最多 10~20GB。这无法支撑大型线上业务系统的需求。而且也造成资源的利用率过低——毕竟现在服务器内存动辄 100~200GB。 为解决单机承载能力不足的问题，各大互联网企业纷纷出手，“自助式” 地实现了集群机制。在这些非官方集群解决方案中，物理上把数据 “分片”（sharding）存储在多个 Redis 实例，一般情况下，每一 “片” 是一个 Redis 实例。 包括官方推出的 Redis Cluster，Redis 集群有三种实现机制，分别介绍如下，希望对大家选型有所帮助。 客户端分片这种方案将分片工作放在业务程序端，程序代码根据预先设置的路由规则，直接对多个 Redis 实例进行分布式访问。这样的好处是，不依赖于第三方分布式中间件，实现方法和代码都自己掌控，可随时调整，不用担心踩到坑。 这实际上是一种静态分片技术。Redis 实例的增减，都得手工调整分片程序。基于此分片机制的开源产品，现在仍不多见。 这种分片机制的性能比代理式更好（少了一个中间分发环节）。但缺点是升级麻烦，对研发人员的个人依赖性强——需要有较强的程序开发能力做后盾。如果主力程序员离职，可能新的负责人，会选择重写一遍。 所以，这种方式下，可运维性较差。出现故障，定位和解决都得研发和运维配合着解决，故障时间变长。这种方案，难以进行标准化运维，不太适合中小公司（除非有足够的 DevOPS）。 代理分片这种方案，将分片工作交给专门的代理程序来做。代理程序接收到来自业务程序的数据请求，根据路由规则，将这些请求分发给正确的 Redis 实例并返回给业务程序。 这种机制下，一般会选用第三方代理程序（而不是自己研发），因为后端有多个 Redis 实例，所以这类程序又称为分布式中间件。 这样的好处是，业务程序不用关心后端 Redis 实例，运维起来也方便。虽然会因此带来些性能损耗，但对于 Redis 这种内存读写型应用，相对而言是能容忍的。 这是我们推荐的集群实现方案。像基于该机制的开源产品 Twemproxy，便是其中代表之一，应用非常广泛。 Redis Cluster在这种机制下，没有中心节点（和代理模式的重要不同之处）。所以，一切开心和不开心的事情，都将基于此而展开。 Redis Cluster 将所有 Key 映射到 16384 个 Slot 中，集群中每个 Redis 实例负责一部分，业务程序通过集成的 Redis Cluster 客户端进行操作。客户端可以向任一实例发出请求，如果所需数据不在该实例中，则该实例引导客户端自动去对应实例读写数据。 Redis Cluster 的成员管理（节点名称、IP、端口、状态、角色）等，都通过节点之间两两通讯，定期交换并更新。由此可见，这是一种非常 “重” 的方案。已经不是 Redis 单实例的 “简单、可依赖” 了。可能这也是延期多年之后，才近期发布的原因之一。 这令人想起一段历史。因为 Memcache 不支持持久化，所以有人写了一个 Membase，后来改名叫 Couchbase，说是支持 Auto Rebalance，好几年了，至今都没多少家公司在使用。这是个令人忧心忡忡的方案。为解决仲裁等集群管理的问题，Oracle RAC 还会使用存储设备的一块空间。而 Redis Cluster，是一种完全的去中心化。本方案目前不推荐使用，从了解的情况来看，线上业务的实际应用也并不多见。 Twemproxy集群概念Twemproxy 是一种代理分片机制，由 Twitter 开源。Twemproxy 作为代理，可接受来自多个程序的访问，按照路由规则，转发给后台的各个 Redis 服务器，再原路返回。这个方案顺理成章地解决了单个 Redis 实例承载能力的问题。当然，Twemproxy 本身也是单点，需要用 Keepalived 做高可用方案。 我想很多人都应该感谢 Twemproxy，这么些年来，应用范围最广、稳定性最高、最久经考验的分布式中间件，应该就是它了。只是，他还有诸多不方便之处。Twemproxy 最大的痛点在于，无法平滑地扩容/缩容。 这样导致运维同学非常痛苦：业务量突增，需增加 Redis 服务器；业务量萎缩，需要减少 Redis 服务器。但对 Twemproxy 而言，基本上都很难操作（那是一种锥心的、纠结的痛……）。或者说，Twemproxy 更加像服务器端静态 sharding。有时为了规避业务量突增导致的扩容需求，甚至被迫新开一个基于 Twemproxy 的 Redis 集群。 Twemproxy 另一个痛点是，运维不友好，甚至没有控制面板。Codis 刚好击中 Twemproxy 的这两大痛点，并且提供诸多其他令人激赏的特性。 架构 特性Twemproxy 搭建 redis 集群有以下的优势： 快速 – 据测试，直连 twenproxy 和直连 redis 相比几乎没有性能损失，读写分离后更是能够极大地提高集群响应能力。 轻量级 – Twemproxy 通过透明连接池、内存零拷贝以及 epoll 模型实现了足够的快速和轻量化，源码较为简洁精炼。 降低负载 – 透明连接池保持前端的连接数，减少后端的连接数，让后端的 redis 节点负载大为降低。 分片 – Twemproxy 通过一致性 hash 算法将数据进行分片，从而实现 redis 集群的高速缓存，降低负载。 多协议 – 同时支持 redis 与 memcache 集群的搭建。 多算法 – 支持多种算法实现一致性哈希分片，包括 crc32，crc16，MD5 等。 配置简单 - 配置非常简单，易上手。 监控报警丰富 – 虽然他提供的原生监控功能一般较少使用，但其提供的统计信息，如发送了多少读写命令还是有很大的价值的。 缺点Twemproxy 也有着明显的缺点： 单点 – Twemproxy 只实现了静态分片的功能，本身不具备集群功能，但可以通过 keepalive 来解决。 运维不友好 – 没有提供控制面板。 无法平滑地扩容/缩容 – 这是一个非常大的缺陷，虽然我们可以通过技术手段和方案来尽量避免，但对于运维人员来说仍然是有很大压力的。 Codis集群概念Codis 由豌豆荚于 2014 年 11 月开源，基于 Go 语言 和 C 语言 开发，是近期涌现的、国人开发的优秀开源软件之一。现已广泛用于豌豆荚的各种 Redis 业务场景。 从 3 个月的各种压力测试来看，稳定性符合高效运维的要求。性能更是改善很多，最初比 Twemproxy 慢 20%；现在比 Twemproxy 快近100%（条件：多实例，一般 Value 长度）。 体系架构Codis 引入了 Group 的概念，每个 Group 包括 1 个 Redis Master 及至少 1 个 Redis Slave，这是和 Twemproxy 的区别之一。这样做的好处是，如果当前 Master 有问题，则运维人员可通过 Dashboard “自助式” 切换到 Slave，而不需要小心翼翼地修改程序配置文件。 为支持数据热迁移（Auto Rebalance），出品方修改了 Redis Server 源码，并称之为 Codis Server。 Codis 采用预先分片（Pre-Sharding）机制，事先规定好了，分成 1024 个 slots（也就是说，最多能支持后端 1024 个 Codis Server），这些路由信息保存在 ZooKeeper 中。ZooKeeper 还维护 Codis Server Group 信息，并提供分布式锁等服务。 性能对比测试Codis 目前仍被精益求精地改进中。其性能，从最初的比 Twemproxy 慢 20%（虽然这对于内存型应用而言，并不明显），到现在远远超过 Twemproxy 性能（一定条件下）。 我们进行了长达 3 个月的测试。测试基于 redis-benchmark，分别针对 Codis 和 Twemproxy，测试 Value 长度从 16B~10MB 时的性能和稳定性，并进行多轮测试。 一共有 4 台物理服务器参与测试，其中一台分别部署 codis 和 twemproxy，另外三台分别部署 codis server 和 redis server，以形成两个集群。 从测试结果来看，就 Set 操作而言，在 Value 长度 &lt;888B 时，Codis 性能优越优于 Twemproxy（这在一般业务的 Value 长度范围之内）。就 Get 操作而言，Codis 性能一直优于 Twemproxy。 架构图 Codis的优势Codis 有着以下优点： 数据热迁移 – 这是 Redis 最大的优势，这也是他被广为使用的最大原因。 运维界面友好 – 提供 slot 状态、Proxy 状态、group 状态、lock、action 等的丰富监控和显示。 故障处理灵活 – 本身只监控和报告故障，提供 API 对故障进行处理，从而让运维能够实现灵活的故障处理方案。 架构清晰 – 如上图所示，整个架构清晰，组件高度内聚，故障的发现和处理变得更为容易。 除此以外，Codis 还提供了从 Twemproxy 到 Codis 的一键迁移工具。 目前来说，国内对 Codis 的使用非常普遍，也是对其优点的群众认可吧。 Codis的缺点Codis 也具有以下明显的缺点： 版本滞后 – 因为在 redis 源码基础上进行二次开发，所以很难跟上最新版 redis 的脚步，目前最新的 Codis-3.2 基于 Redis-3.2.8 版本。 部署复杂 – 部署过程至少要进行 codis-dashboard、codis-proxy、codis-server、codis-fe 四个组件的部署和启动。 单节点性能低 – 如果仅有一个 codis-server，性能低于原生 redis 20% 左右。 更新频率低 codis和twemproxy区别codis 和 twemproxy 最大的区别有两个： codis 支持动态水平扩展，对 client 完全透明不影响服务的情况下可以完成增减 redis 实例的操作； codis 是用 go 语言写的并支持多线程，twemproxy 用 C 并只用单线程。 后者又意味着：codis 在多核机器上的性能会好于 twemproxy；codis 的最坏响应时间可能会因为 GC 的 STW 而变大。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E9%9B%86%E7%BE%A4twemproxy%E4%B8%8Ecodis/"},{"title":"Redis集群cluster","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-cluster.html 什么是Redis clusterRedis cluster 是 Redis 官方提供的分布式解决方案，在 3.0 版本后推出的，有效地解决了 Redis 分布式的需求，当一个 Redis 节点挂了可以快速的切换到另一个节点。当遇到单机内存、并发等瓶颈时，可以采用分布式方案要解决问题。 Redis cluster集群背景Redis 最开始使用 主从模式 做集群，若 master 宕机需要手动配置 slave 转为 master；后来为了高可用提出来哨兵模式，该模式下有一个哨兵监视 master 和 slave，若 master 宕机可自动将 slave 转为 master，但它也有一个问题，就是不能动态扩充；所以在 3.x 提出 cluster 集群模式。 Redis Cluster集群问题尽管属于无中心化架构一类的分布式系统，但不同产品的细节实现和代码质量还是有不少差异的，就比如 Redis Cluster 有些地方的设计看起来就有一些 “奇葩” 和简陋： 不能自动发现：无 Auto Discovery 功能。集群建立时以及运行中新增结点时，都要通过手动执行 MEET 命令或 redis-trib.rb 脚本添加到集群中。 不能自动 Resharding：不仅不自动，连 Resharding 算法都没有，要自己计算从哪些结点上迁移多少 Slot，然后还是得通过 redis-trib.rb 操作。 严重依赖外部 redis-trib：如上所述，像集群健康状况检查、结点加入、Resharding 等等功能全都抽离到一个 Ruby 脚本中了。还不清楚上面提到的缺失功能未来是要继续加到这个脚本里还是会集成到集群结点中？redis-trib 也许要变成 Codis 中 Dashboard 的角色。 无监控管理UI：即便未来加了 UI，像迁移进度这种信息在无中心化设计中很难得到。 只保证最终一致性：写 Master 成功后立即返回，如需强一致性，自行通过 WAIT 命令实现。但对于 “脑裂” 问题，目前 Redis 没提供网络恢复后的 Merge 功能，“脑裂” 期间的更新可能丢失。 Redis Cluster优缺点优点 集群模式是一个无中心的架构模式，将数据进行分片，分布到对应的槽中，每个节点存储不同的数据内容，通过路由能够找到对应的节点负责存储的槽，能够实现高效率的查询。 并且集群模式增加了横向和纵向的扩展能力，实现节点加入和收缩，集群模式是哨兵的升级版，哨兵的优点集群都有。 缺点 缓存的最大问题就是带来数据一致性问题，在平衡数据一致性的问题时，兼顾性能与业务要求，大多数都是以最终一致性的方案进行解决，而不是强一致性。 并且集群模式带来节点数量的剧增，一个集群模式最少要 6 台机，因为要满足半数原则的选举方式，所以也带来了架构的复杂性。 slave 只充当冷备，并不能缓解 master 的读的压力。 批量操作限制，目前只支持具有相同 slot 值的 key 执行批量操作，对 mset、mget、sunion 等操作支持不友好。 key 事务操作支持有线，只支持多 key 在同一节点的事务操作，多 key 分布不同节点时无法使用事务功能。 不支持多数据库空间，单机 redis 可以支持 16 个 db，集群模式下只能使用一个，即 db 0。 Redis集群原理架构图Redis-cluster 集群的架构图如下图所示： 我们可以看到： 所有的 Redis 节点彼此互联(PING-PONG 机制)，内部使用二进制协议优化传输速度和带宽。 节点的 fail 是通过集群中超过半数的节点检测失效时才生效。 客户端与 Redis 节点直连，不需要中间 proxy 层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。 Redis-cluster 把所有的物理节点映射到 [0-16383] slot 上，cluster 负责维护 node&lt;-&gt;slot&lt;-&gt;value。 Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点。 redis-cluster投票Redis-cluster 投票架构图如下图所示： 也就是说： 投票过程是集群中所有 master 参与，如果半数以上 master 节点与 master 节点通信超时(cluster-node-timeout)，认为当前 master 节点挂掉。 什么时候整个集群不可用(cluster_state:fail) 如果集群任意 master 挂掉，且当前 master 没有 slave。集群进入 fail 状态，也可以理解成集群的 slot 映射 [0-16383] 不完整时进入 fail 状态。 如果集群超过半数以上 master 挂掉，无论是否有 slave，集群进入 fail 状态。 Redis集群搭建安装Ruby环境12yum -y install rubyyum -y install rubygems redis配置文件修改现在已经准备好了，6 份干净的 redis，如下所示： 123456789101112[root@localhost redis-cluster]# pwd/usr/local/redis/redis-cluster[root@localhost redis-cluster]# lltotal 72drwxr-xr-x 2 root root 4096 Nov 2 00:17 redis1drwxr-xr-x 2 root root 4096 Nov 2 00:25 redis2drwxr-xr-x 2 root root 4096 Nov 2 00:25 redis3drwxr-xr-x 2 root root 4096 Nov 2 00:25 redis4drwxr-xr-x 2 root root 4096 Nov 2 00:25 redis5drwxr-xr-x 2 root root 4096 Nov 2 00:25 redis6-rwxr-xr-x 1 root root 48141 Nov 2 00:16 redis-trib.rb[root@localhost redis-cluster]# 将 redis 源文件 src 目录下的 redis-trib.rb 文件拷贝过来了。 redis-trib.rb 这个文件是 redis 集群的管理文件，ruby 脚本。我们将要设置的节点的 redis.conf 配置文件按照如下进行修改： 1234567891011121314151617181920212223################################ GENERAL ##################################### # By default Redis does not run as a daemon. Use 'yes' if you need it.# Note that Redis will write a pid file in /var/run/redis.pid when daemonized.daemonize yes # Accept connections on the specified port, default is 6379.# If port 0 is specified Redis will not listen on a TCP socket.port * ################################ REDIS CLUSTER ################################# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++# WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however# in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage# of users to deploy it in production.# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++## Normal Redis instances can't be part of a Redis Cluster; only nodes that are# started as cluster nodes can. In order to start a Redis instance as a# cluster node enable the cluster support uncommenting the following:#cluster-enabled yes 端口号如果是同一台主机的话，必须不同。不同主机可以相同。我这里是使用一台主机，所以我将六个节点的端口号修改为 7001-7006。 启动脚本start-all.sh123456789101112131415161718cd redis1./redis-server redis.confcd ..cd redis2./redis-server redis.confcd ..cd redis3./redis-server redis.confcd ..cd redis4./redis-server redis.confcd ..cd redis5./redis-server redis.confcd ..cd redis6./redis-server redis.confcd .. 停止脚本123456./redis1/redis-cli -p 7001 shutdown./redis1/redis-cli -p 7002 shutdown./redis1/redis-cli -p 7003 shutdown./redis1/redis-cli -p 7004 shutdown./redis1/redis-cli -p 7005 shutdown./redis1/redis-cli -p 7006 shutdown 两个脚本都放在如下所属目录: 1234567891011121314[root@localhost redis-cluster]# pwd/usr/local/redis/redis-cluster[root@localhost redis-cluster]# lltotal 80drwxr-xr-x 2 root root 4096 Nov 2 00:52 redis1drwxr-xr-x 2 root root 4096 Nov 2 00:51 redis2drwxr-xr-x 2 root root 4096 Nov 2 00:53 redis3drwxr-xr-x 2 root root 4096 Nov 2 00:53 redis4drwxr-xr-x 2 root root 4096 Nov 2 00:53 redis5drwxr-xr-x 2 root root 4096 Nov 2 00:53 redis6-rwxr-xr-x 1 root root 48141 Nov 2 00:16 redis-trib.rb-rw-r--r-- 1 root root 252 Nov 2 00:55 start-all.sh-rw-r--r-- 1 root root 216 Nov 2 00:57 stop-all.sh[root@localhost redis-cluster]# 修改权限1[root@localhost redis-cluster]# chmod -u+x start-all.sh stop-all.sh 启动节点1234567891011[root@localhost redis-cluster]# ./start-all.sh [root@localhost redis-cluster]# ps aux | grep redisroot 2924 0.8 0.1 33932 2048 ? Ssl Nov01 3:53 ./redis-server *:6379 [cluster]root 11924 0.0 0.1 33936 1948 ? Ssl 01:01 0:00 ./redis-server *:7001 [cluster]root 11928 0.0 0.1 33936 1952 ? Ssl 01:01 0:00 ./redis-server *:7002 [cluster]root 11932 0.0 0.1 33936 1948 ? Ssl 01:01 0:00 ./redis-server *:7003 [cluster]root 11936 0.0 0.1 33936 1952 ? Ssl 01:01 0:00 ./redis-server *:7004 [cluster]root 11940 0.0 0.1 33936 1952 ? Ssl 01:01 0:00 ./redis-server *:7005 [cluster]root 11944 0.0 0.1 33936 1948 ? Ssl 01:01 0:00 ./redis-server *:7006 [cluster]root 11948 0.0 0.0 4360 748 pts/2 S+ 01:01 0:00 grep redis[root@localhost redis-cluster]# 执行创建集群命令123[root@localhost redis-cluster]# pwd/usr/local/redis/redis-cluster[root@localhost redis-cluster]# ./redis-trib.rb create --replicas 1 192.168.37.131:7001 192.168.37.131:7002 192.168.37.131:7003 192.168.37.131:7004 192.168.37.131:7005 192.168.37.131:7006","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E9%9B%86%E7%BE%A4cluster/"},{"title":"一致性Hash","text":"原文: https://haicoder.net/note/redis-interview/redis-interview-uniformity-hash.html 什么是一致性Hash一致性哈希算法在 1997 年由麻省理工学院的 Karger 等人在解决分布式 Cache 中提出的，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和 CARP 十分类似。 一致性哈希修正了 CARP 使用的简单哈希算法带来的问题，使得 DHT 可以在 P2P 环境中真正得到应用。 一致性Hash现在一致性 hash 算法在分布式系统中也得到了广泛应用，研究过 memcached 缓存数据库的人都知道，memcached 服务器端本身不提供分布式 cache 的一致性，而是由客户端来提供，具体在计算一致性 hash 时采用如下步骤： 首先求出 memcached 服务器（节点）的哈希值，并将其配置到 0～232 的圆（continuum）上。 然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。 然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过 0～232 仍然找不到服务器，就会保存到第一台 memcached 服务器上。 从上图的状态中添加一台 memcached 服务器。余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但 Consistent Hashing 中，只有在圆（continuum）上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，如下图所示： 一致性Hash性质考虑到分布式系统每个节点都有可能失效，并且新的节点很可能动态的增加进来，如何保证当系统的节点数目发生变化时仍然能够对外提供良好的服务，这是值得考虑的，尤其实在设计分布式缓存系统时，如果某台服务器失效，对于整个系统来说如果不采用合适的算法来保证一致性，那么缓存于系统中的所有数据都可能会失效（即由于系统节点数目变少，客户端在请求某一对象时需要重新计算其 hash 值（通常与系统中的节点数目有关），由于 hash 值已经改变，所以很可能找不到保存该对象的服务器节点），因此一致性 hash 就显得至关重要，良好的分布式cahce 系统中的一致性 hash 算法应该满足以下几个方面： 平衡性(Balance)平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity)单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。简单的哈希算法往往不能满足单调性的要求，如最简单的线性哈希：x = (ax + b) mod §，在上式中，P 表示全部缓冲的大小。不难看出，当缓冲大小发生变化时(从 P1 到 P2)，原来所有的哈希结果均会发生变化，从而不满足单调性的要求。哈希结果的变化意味着当缓冲空间发生变化时，所有的映射关系需要在系统内全部更新。而在 P2P 系统内，缓冲的变化等价于 Peer 加入或退出系统，这一情况在 P2P 系统中会频繁发生，因此会带来极大计算和传输负荷。单调性就是要求哈希算法能够应对这种情况。 分散性(Spread)在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 平滑性(Smoothness)平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。 原理一致性哈希算法（Consistent Hashing）最早在论文《Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web》中被提出。简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为 0-232-1（即哈希值是一个 32 位无符号整形），整个哈希空间环如下： 整个空间按顺时针方向组织。0 和 232-1 在零点中方向重合。 下一步将各个服务器使用 Hash 进行一个哈希，具体可以选择服务器的 ip 或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中四台服务器使用 ip 地址哈希后在环空间的位置如下： 接下来使用如下算法定位数据访问到相应服务器：将数据 key 使用相同的函数 Hash 计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针 “行走”，第一台遇到的服务器就是其应该定位到的服务器。 例如我们有 Object A、Object B、Object C、Object D 四个数据对象，经过哈希计算后，在环空间上的位置如下： 根据一致性哈希算法，数据 A 会被定为到 Node A 上，B 被定为到 Node B 上，C 被定为到 Node C 上，D 被定为到 Node D 上。 下面分析一致性哈希算法的容错性和可扩展性。现假设 Node C 不幸宕机，可以看到此时对象 A、B、D 不会受到影响，只有 C 对象被重定位到 Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 下面考虑另外一种情况，如果在系统中增加一台服务器 Node X，如下图所示： 此时对象 Object A、B、D 不受影响，只有对象 C 需要重定位到新的 Node X 。一般的，在一致性哈希算法中，如果增加一台服务器，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 另外，一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。例如系统中只有两台服务器，其环分布如下， 此时必然造成大量数据集中到 Node A 上，而只有极少量会定位到 Node B 上。为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在服务器 ip 或主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node A#1”、“Node A#2”、“Node A#3”、“Node B#1”、“Node B#2”、“Node B#3” 的哈希值，于是形成六个虚拟节点： 同时数据定位算法不变，只是多了一步虚拟节点到实际节点的映射，例如定位到 “Node A#1”、“Node A#2”、“Node A#3” 三个虚拟节点的数据均定位到 Node A 上。这样就解决了服务节点少时数据倾斜的问题。在实际应用中，通常将虚拟节点数设置为 32 甚至更大，因此即使很少的服务节点也能做到相对均匀的数据分布。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E4%B8%80%E8%87%B4%E6%80%A7hash/"},{"title":"linux中的sh、dash、bash的区别","text":"一、常见shell类型1. Bourne shell (sh)UNIX 最初使用，且在每种 UNIX 上都可以使用。在 shell 编程方面相当优秀，但在处理与用户的交互方面做得不如其他几种shell。 2. C shell (csh)csh, the C shell, is a command interpreter with a syntax similar to the C programming language.一个语法上接近于C语言的shell。 3. Korn shell (ksh)完全向上兼容 Bourne shell 并包含了 C shell 的很多特性。 4. Bourne Again shell (bash)因为Linux 操作系统缺省的 shell。即 bash 是 Bourne shell 的扩展，与 Bourne shell 完全向后兼容。在 Bourne shell 的基础上增加、增强了很多特性。可以提供如命令补全、命令编辑和命令历史表等功能。包含了很多 C shell 和 Korn shell 中的优点，有灵活和强大的编程接口，同时又有很友好的用户界面。 5. Debian Almquist Shell(dash)原来bash是GNU/Linux 操作系统中的 /bin/sh 的符号连接，但由于bash过于复杂，有人把 bash 从 NetBSD 移植到 Linux 并更名为 dash，且/bin/sh符号连接到dash。Dash Shell 比 Bash Shell 小的多（ubuntu16.04上，bash大概1M，dash只有150K），符合POSIX标准。Ubuntu 6.10开始默认是Dash。 把sh改为指向bash的方法： 方法一：ln -s /bin/bash /bin/sh； 方法二：配置shellsudo dpkg-reconfigure dash 二、shell 相关命令查看当前系统可用的 shell cat /etc/shells 查看当前使用的 shell，随便打一个错误命令，会有提示。 查看用户登录后默认的 shell cat /etc/passwd |grep 用户名 三、规范和建议每个脚本开头都使用”#!”，#!实际上是一个2字节魔法数字，这是指定一个文件类型的特殊标记，在这种情况下，指的就是一个可执行的脚本。在#!之后，接一个路径名，这个路径名指定了一个解释脚本命令的程序，这个程序可以是shell，程序语言或者任意一个通用程序。 标记为 “#!/bin/sh” 的脚本不应使用任何 POSIX 没有规定的特性 (如 let 等命令, 但 “#!/bin/bash” 可以)。bash支持的写法比dash（ubuntu中的sh）多很多。想要支持 sh xx.sh 运行的，必须遵照 POSIX 规范去写。想要脚本写法多样化，不需要考虑效率的，可以将文件头定义为 #!/bin/bash , 而且不要使用 sh xx.sh 这种运行方式 四、bash和dash区别语法上的主要的区别有: 1. 定义函数bash: function在bash中为关键字 dash: dash中没有function这个关键字 2. select var in list; do command; donebash:支持 dash:不支持, 替代方法:采用while+read+case来实现 3. echo {0..10}bash:支持{n..m}展开 dash:不支持，替代方法, 采用seq外部命令 4. here stringbash:支持here string dash:不支持, 替代方法:可采用here documents 5. &gt;&amp;word重定向标准输出和标准错误bash: 当word为非数字时，&gt;&amp;word变成重定向标准错误和标准输出到文件word dash: &gt;&amp;word, word不支持非数字, 替代方法: &gt;word 2&gt;&1; 常见用法 &gt;/dev/null 2&gt;&amp;1 6. 数组bash: 支持数组, bash4支持关联数组 dash: 不支持数组，替代方法, 采用变量名+序号来实现类似的效果 7. 子字符串扩展bash: 支持parameter:offset:length,parameter:offset:length,{parameter:offset} dash: 不支持， 替代方法:采用expr或cut外部命令代替 8. 大小写转换bash: 支持parameterpattern,parameterpattern,{parameter^^pattern},parameter,pattern,parameter,pattern,{parameter,,pattern} dash: 不支持，替代方法:采用tr/sed/awk等外部命令转换 9. 进程替换&lt;(command), &gt;(command)bash: 支持进程替换 dash: 不支持, 替代方法, 通过临时文件中转 10. [ string1 = string2 ] 和 [ string1 == string2 ]bash: 支持两者 dash: 只支持= 11. [[ 加强版testbash: 支持[[ ]], 可实现正则匹配等强大功能 dash: 不支持[[ ]], 替代方法，采用外部命令 12. for (( expr1 ; expr2 ; expr3 )) ; do list ; donebash: 支持C语言格式的for循环 dash: 不支持该格式的for, 替代方法，用while+((expression))实现13.let命令和((expression))bash:有内置命令let,也支持((expression))方式dash:不支持，替代方法，采用((expression))实现13.let命令和((expression))bash:有内置命令let,也支持((expression))方式dash:不支持，替代方法，采用((expression))或者外部命令做计算 14. $((expression))bash: 支持id++,id–,++id,–id这样到表达式 dash: 不支持++,–, 替代方法:id+=1,id-=1, id=id+1,id=id-1 15. 其它常用命令bash: 支持 echo -e, 支持 declare dash: 不支持。 原文：https://blog.csdn.net/weixin_39212776/article/details/81079727","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/linux%E4%B8%AD%E7%9A%84sh%E3%80%81dash%E3%80%81bash%E7%9A%84%E5%8C%BA%E5%88%AB/"},{"title":"《小狗钱钱》","text":"大多数人并不清楚自己想要的是什么，他们只知道，自己想得到更多的东西。 对于快乐的认知。人的感觉自是激素化学反应的结果。 好奇是好的，但是绝不能让好奇阻碍你做事。太多的人做事犹豫不决，就是因为他们觉得没有完全弄懂这件事。真正付诸实践要比纯粹的思考有用多了。 “尝试”纯粹是一种借口，你还没有做，就已经给自己想好了退路。 学习就是认识新观念和新想法的过程。假如人们始终以同一种思维方式来考虑问题的话，那么始终只会得到同样的结果。没有想象力的人是很难成就大事的。我们对一件事投入的精力越多，成功的可能性也越大。可是大多数人把精力放在自己并不喜欢的事情上，而不去想象自己希望的到的东西。 机会到处都是，但是只有在你寻找它的时候，你才能看见它。 金先生是一位不同寻常的人，他总是做一些非同寻常的事情。他不在乎别人做什么，只要他认为正确的事情，他就会去做。 金先生答道：“越是把注意力放在疼痛上，我就越会觉得疼。谈论疼痛就像给植物施肥一样。所以我很多年以前就改掉了抱怨的习惯。” 要想过更幸福、更满意的生活，人就得改变自身。这和钱无关，金钱本身既不会使人幸福，也不会带来不幸。金钱是中性的，既不好，也不坏。只有当钱属于某一个人的时候，它才会对这个人产生好的影响或者坏的影响。钱可以被用于好的用途，也可以被用于坏的用途。一个幸福的人有了钱会更幸福；而一个悲观忧虑的人，钱越多，烦恼就越多。 他停顿了片刻，接着又说：“如果你没有做今天这件事情，你就永远不会知道，给自己一些压力之后，你能够做到些什么。一个人觉得最引以为自豪的事情，往往是那些做起来最艰难的事情。这一点你千万不要忘记。”","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%B0%8F%E7%8B%97%E9%92%B1%E9%92%B1%E3%80%8B/"},{"title":"布隆过滤器","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-bloon-filter.html 什么是布隆过滤器布隆过滤器（Bloom Filter）是 1970 年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。 哈希函数布隆过滤器离不开哈希函数，所以在这里有必要介绍下哈希函数的概念，哈希函数的性质: 经典的哈希函数都有无限大的输入值域(无穷大)。 经典的哈希函数的输出域都是固定的范围(有穷大，假设输出域为 S)。 当给哈希函数传入相同的值时，返回值必一样。 当给哈希函数传入不同的输入值时，返回值可能一样，也可能不一样。 输入值会尽可能均匀的分布在 S 上。 前三点都是哈希函数的基础，第四点描述了哈希函数存在哈希碰撞的现象，因为输入域无限大，输出域有穷大，这是必然的，输入域中会有不同的值对应到输入域 S 中。第五点事评价一个哈希函数优劣的关键，哈希函数越优秀，分布就越均匀且与输入值出现的规律无关。比如存在 “hash1”,“hash2”,“hash3” 三个输入值比较类似，经过哈希函数计算后的结果应该相差非常大，可以通过常见的 MD5 和 SHA1 算法来验证这些特性。如果一个优秀的函数能够做到不同的输入值所得到的返回值可以均匀的分布在 S 中，将其返回值对 m 取余(%m)，得到的返回值可以认为也会均匀的分布在 0~m-1 位置上。 布隆过滤器原理布隆过滤器是一个 bit 向量或者说 bit 数组，如下图所示： 如果我们要映射一个值到布隆过滤器中，我们需要使用多个不同的哈希函数生成多个哈希值，并对每个生成的哈希值指向的 bit 位置 1，例如针对值 “baidu” 和三个不同的哈希函数分别生成了哈希值 1、4、7，则上图转变为： Ok，我们现在再存一个值 “ali”，如果哈希函数返回 3、4、8 的话，图继续变为： 值得注意的是，4 这个 bit 位由于两个值的哈希函数都返回了这个 bit 位，因此它被覆盖了。现在我们如果想查询 “dianping” 这个值是否存在，哈希函数返回了 1、5、8 三个值，结果我们发现 5 这个 bit 位上的值为 0，说明没有任何一个值映射到这个 bit 位上，因此我们可以很确定地说 “dianping” 这个值不存在。而当我们需要查询 “baidu” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1，那么我们可以说 “baidu” 存在了么？答案是不可以，只能是 “baidu” 这个值可能存在。 这是为什么呢？答案跟简单，因为随着增加的值越来越多，被置为 1 的 bit 位也会越来越多，这样某个值 “taobao” 即使没有被存储过，但是万一哈希函数返回的三个 bit 位都被其他值置位了 1 ，那么程序还是会判断 “taobao” 这个值存在。 布隆过滤器应用比如一个网站有 20 亿 url 存在一个黑名单中，这个黑名单 要怎么存？若此时随便输入一个 url，你如何快速判断该 url 是否在这个黑名单中？并且需在给定内存空间（比如：500M）内快速判断出。 可能很多人首先想到的会是使用 HashSet，因为 HashSet 基于 HashMap，理论上时间复杂度为：O(1)。达到了快速的目的，但是空间复杂度呢？URL 字符串通过 Hash 得到一个 Integer 的值，Integer 占 4 个字节，那 20 亿个 URL 理论上需要： 20亿*4/1024/1024/1024=7.45G 的内存，不满足空间复杂度的要求。这里就引出本文要介绍的 “布隆过滤器”。 如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。链表、树、散列表（又叫哈希表，Hash table）等等数据结构都是这种思路，存储位置要么是磁盘，要么是内存。很多时候要么是以时间换空间，要么是以空间换时间。 在响应时间要求比较严格的情况下，如果我们存在内里，那么随着集合中元素的增加，我们需要的存储空间越来越大，以及检索的时间越来越长，导致内存开销太大、时间效率变低。 此时需要考虑解决的问题就是，在数据量比较大的情况下，既满足时间要求，又满足空间的要求。即我们需要一个时间和空间消耗都比较小的数据结构和算法。Bloom Filter 就是一种解决方案。 布隆过滤器特点 因使用哈希判断，时间效率很高。空间效率也是其一大优势。 有误判的可能，需针对具体场景使用。 因为无法分辨哈希碰撞，所以不是很好做删除操作。 使用场景布隆过滤器的巨大用处就是，能够迅速判断一个元素是否在一个集合中。它的常用使用场景如下： 黑名单 : 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信） URL去重 : 网页爬虫对 URL 的去重，避免爬取相同的 URL 地址 单词拼写检查 Key-Value 缓存系统的 Key 校验 (缓存穿透) : 缓存穿透，将所有可能存在的数据缓存放到布隆过滤器中，当黑客访问不存在的缓存时迅速返回避免缓存及 DB 挂掉。 ID 校验，比如订单系统查询某个订单 ID 是否存在，如果不存在就直接返回。 最佳实践常见的适用常见有，利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。 另外，既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。 大Value拆分Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。 拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"},{"title":"各种开源协议介绍","text":"世界上的开源许可证（Open Source License）大概有上百种，今天我们来介绍下几种我们常见的开源协议。大致有GPL、BSD、MIT、Mozilla、Apache和LGPL等。 Apache LicenseApache License（Apache许可证），是Apache软件基金会发布的一个自由软件许可证。 Apache Licence是著名的非盈利开源组织Apache采用的协议。该协议和BSD类似，同样鼓励代码共享和最终原作者的著作权，同样允许源代码修改和再发布。但是也需要遵循以下条件： 需要给代码的用户一份Apache Licence。 如果修改了代码，需要再被修改的文件中说明。 在衍生的代码中（修改和有源代码衍生的代码中）需要带有原来代码中的协议，商标，专利声明和其他原来作者规定需要包含的说明。 如果再发布的产品中包含一个Notice文件，则在Notice文件中需要带有Apache Licence。你可以再Notice中增加自己的许可，但是不可以表现为对Apache Licence构成更改。 Apache Licence也是对商业应用友好的许可。使用者也可以再需要的时候修改代码来满足并作为开源或商业产品发布/销售。 使用这个协议的好处是: 永久权利 一旦被授权，永久拥有。 全球范围的权利 在一个国家获得授权，适用于所有国家。假如你在美国，许可是从印度授权的，也没有问题。 授权免费 无版税， 前期、后期均无任何费用。 授权无排他性 任何人都可以获得授权 授权不可撤消 一旦获得授权，没有任何人可以取消。比如，你基于该产品代码开发了衍生产品，你不用担心会在某一天被禁止使用该代码 BSDBSD是”Berkeley Software Distribution”的缩写，意思是”伯克利软件发行版”。 BSD开源协议：是一个给于使用者很大自由的协议。可以自由的使用，修改源代码，也可以将修改后的代码作为开源或者专有软件再发布。 当你发布使用了BSD协议的代码，或则以BSD协议代码为基础做二次开发自己的产品时，需要满足三个条件： 1． 如果再发布的产品中包含源代码，则在源代码中必须带有原来代码中的BSD协议。 2． 如果再发布的只是二进制类库/软件，则需要在类库/软件的文档和版权声明中包含原来代码中的BSD协议。 3． 不可以用开源代码的作者/机构名字和原来产品的名字做市场推广。 BSD代码鼓励代码共享，但需要尊重代码作者的著作权。BSD由于允许使用者修改和重新发布代码，也允许使用或在BSD代码上开发商业软件发布和销售，因此是对商业集成很友好的协议。而很多的公司企业在选用开源产品的时候都首选BSD协议，因为可以完全控制这些第三方的代码，在必要的时候可以修改或者二次开发。 GPLGPL （GNU General Public License） ：GNU通用公共许可协议。 Linux 采用了 GPL。 GPL协议和BSD, Apache Licence等鼓励代码重用的许可很不一样。GPL的出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但不允许修改后和衍生的代码做为闭源的商业软件发布和销售。这也就是为什么我们能用免费的各种linux，包括商业公司的linux和linux上各种各样的由个人，组织，以及商业软件公司开发的免费软件了。 LGPLLGPL是GPL的一个为主要为类库使用设计的开源协议。和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同。LGPL允许商业软件通过类库引用(link)方式使用LGPL类库而不需要开源商业软件的代码。这使得采用LGPL协议的开源代码可以被商业软件作为类库引用并发布和销售。 但是如果修改LGPL协议的代码或者衍生，则所有修改的代码，涉及修改部分的额外代码和衍生的代码都必须采用LGPL协议。因此LGPL协议的开源代码很适合作为第三方类库被商业软件引用，但不适合希望以LGPL协议代码为基础，通过修改和衍生的方式做二次开发的商业软件采用。 GPL/LGPL都保障原作者的知识产权，避免有人利用开源代码复制并开发类似的产品。 MITMIT是和BSD一样宽范的许可协议,源自麻省理工学院（Massachusetts Institute of Technology, MIT），又称X11协议。作者只想保留版权,而无任何其他了限制。MIT与BSD类似，但是比BSD协议更加宽松，是目前最少限制的协议。这个协议唯一的条件就是在修改后的代码或者发行包包含原作者的许可信息。适用商业软件。使用MIT的软件项目有：jquery、Node.js。 MIT与BSD类似，但是比BSD协议更加宽松，是目前最少限制的协议。这个协议唯一的条件就是在修改后的代码或者发行包包含原作者的许可信息。适用商业软件。使用MIT的软件项目有：jquery、Node.js。 MPL (Mozilla Public License 1.1)MPL协议允许免费重发布、免费修改，但要求修改后的代码版权归软件的发起者 。这种授权维护了商业软件的利益，它要求基于这种软件的修改无偿贡献版权给该软件。这样，围绕该软件的所有代码的版权都集中在发起开发人的手中。但MPL是允许修改，无偿使用得。MPL软件对链接没有要求。 EPL (Eclipse Public License 1.0)EPL允许Recipients任意使用、复制、分发、传播、展示、修改以及改后闭源的二次商业发布。 使用EPL协议，需要遵守以下规则： 当一个Contributors将源码的整体或部分再次开源发布的时候,必须继续遵循EPL开源协议来发布,而不能改用其他协议发布.除非你得到了原”源码”Owner 的授权； EPL协议下,你可以将源码不做任何修改来商业发布.但如果你要发布修改后的源码,或者当你再发布的是Object Code的时候,你必须声明它的Source Code是可以获取的,而且要告知获取方法； 当你需要将EPL下的源码作为一部分跟其他私有的源码混和着成为一个Project发布的时候,你可以将整个Project/Product以私人的协议发布,但要声明哪一部分代码是EPL下的,而且声明那部分代码继续遵循EPL； 独立的模块(Separate Module),不需要开源。 Creative Commons 知识共享协议Creative Commons (CC) 许可协议并不能说是真正的开源协议，它们大多是被使用于设计类的工程上。 CC 协议种类繁多，每一种都授权特定的权利。 一个 CC 许可协议具有四个基本部分，这几个部分可以单独起作用，也可以组合起来。下面是这几部分的简介： 1、署名 作品上必须附有作品的归属。如此之后，作品可以被修改，分发，复制和其它用途。 2、相同方式共享 作品可以被修改、分发或其它操作，但所有的衍生品都要置于CC许可协议下。 3、非商业用途 作品可以被修改、分发等等，但不能用于商业目的。但语言上对什么是”商业”的说明十分含糊不清 (没有提供精确的定义)，所以你可以在你的工程里对其进行说明。例如，有些人简单的解释”非商业”为不能出售这个作品。而另外一些人认为你甚至不能在有广告的网站上使用它们。 还有些人认为”商业”仅仅指你用它获取利益。 4、禁止衍生作品 CC 许可协议的这些条款可以自由组合使用。大多数的比较严格的CC协议会声明 “署名权，非商业用途，禁止衍生”条款，这意味着你可以自由的分享这个作品，但你不能改变它和对其收费，而且必须声明作品的归属。这个许可协议非常的有用，它可以让你的作品传播出去，但又可以对作品的使用保留部分或完全的控制。最少限制的CC协议类型当属 “署名”协议，这意味着只要人们能维护你的名誉，他们对你的作品怎么使用都行。 CC 许可协议更多的是在设计类工程中使用，而不是开发类，但没有人或妨碍你将之使用与后者。只是你必须要清楚各部分条款能覆盖到的和不能覆盖到的权利。 图解分析","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E5%90%84%E7%A7%8D%E5%BC%80%E6%BA%90%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D/"},{"title":"查看Redis内存使用","text":"原文： https://haicoder.net/note/redis-interview/redis-interview-redis-memory.html 查看Redis内存使用在 Redis 使用过程中，如果我们需要查看 Redis 的内存使用情况，我们可以使用 INFO 命令，具体命令如下： 1INFO 执行完毕后，如下图所示： 我们可以看到，此时输出了所有的 Redis 的使用信息，如果我们仅仅需要查看内存的使用，我们还可以使用如下命令： 1INFO Memory 执行完毕后，如下图所示： 其中，具体每项解释如下： | 字段 | 说明 | | ————————- | ———————————————————— | | used_memory | 由 redis 分配器分配的内存总量，以字节为单位 | | used_memory_human | 易读方式 | | used_memory_rss | 从操作系统的角度，返回 redis 已分配的内存总量(俗称常驻集大小) | | used_memory_rss_human | 易读方式 | | used_memory_peak | redis 的内存消耗峰值(以字节为单位) | | used_memory_peak_human | 易读方式 | | total_system_memory | 系统内存总量 | | total_system_memory_human | 易读方式 | | used_memory_lua | Lua 引擎使用的字节量 | | used_memory_lua_human | 易读方式 | | maxmemory | 配置设置的最大可使用内存值 | | maxmemory_human | 易读方式 | | maxmemory_policy | 内存淘汰策略 | | mem_fragmentation_ratio | used_memory_rss 和 used_memory 之间的比率 | | mem_allocator | 在编译时指定的， Redis 所使用的内存分配器。可以是 libc 、 jemalloc 或者 tcmalloc | 在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。 当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。当 Redis 释放内存时，分配器可能会，也可能不会，将内存返还给操作系统。 如果 Redis 释放了内存，却没有将内存返还给操作系统，那么 used_memory 的值可能和操作系统显示的 Redis 内存占用并不一致。查看 used_memory_peak 的值可以验证这种情况是否发生。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E6%9F%A5%E7%9C%8Bredis%E5%86%85%E5%AD%98%E4%BD%BF%E7%94%A8/"},{"title":"《快速阅读术》","text":"从“复制100%”到“邂逅1%”，读一本书，只为遇见一行文字。 **像听音乐那样读书**。 “流水式阅读”指的是这样一种读书方法：让书籍内容从心中“流过”，只要“流过”便有意义。 流水式阅读是信息大爆炸时代最合理并且可以“避免堆积”的阅读方式。 在“每天同一时间”读书。 固定“时间段以及情境”，让大脑产生“习惯的错觉” 可以快速阅读的书的特点就在于，贯穿全书的线索较少，相对独立的章节较多，无论选择从哪里开始阅读都能有所收获。 为写而读 每次推选一本书，并从中摘出令人印象深刻的一句话。 提高阅读速度的四个步骤：步骤一：仔细阅读序言和目录。 步骤二：仅读开头和结尾的5行。 步骤三：确定了关键词之后再阅读。 步骤四：使用多种阅读节奏阅读。 人类的大脑拥有不可思议的能力，能够自动补全遗漏的片断。在读到“A→C”这样的字幕序列时，我们的大脑就会自动推断“其间是B”。 一周6本，一个月25本，一年300本，进入一种“多读生活”的状态。听到“一年读300本书”的阅读目标，恐怕很多人都会感到吃惊，认为这是绝对不可能的事。 美国的人气作家迪恩·雷·孔茨在《畅销小说的写作方法》中曾经说：“要让主人公陷入绝境走投无路，最终皆大欢喜，否则难以让读者感到心满意足。”大意如此。此话一语中的。途中要起伏跌宕，扣人心弦，而最后一定要云开见日，完美收官。这种如释重负的感觉最引人入胜。 随着人生阅历的增加和年龄的增长，以及知识面的扩大，每个人最后必然都会找到自己专注执着的那一部分。 10年之后，我们还能够以13岁时的心境去读书。 如果能够保持这样的心境，那么，无论年龄或阅历如何，我们一生都能遇见令自己感动的书籍。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB%E6%9C%AF%E3%80%8B/"},{"title":"《终身成长》","text":"当你有时间提升自己的时候，为什么要浪费时间一遍又一遍地去证明自己的杰出？ 即使是（或特别是）事情发展不顺利时也能拥有这种想要提升自己并坚持不懈的激情，这就是拥有成长型思维模式的人身上的标志。这种思维模式，让人们在人生遭遇重大挑战的时刻，依然可以茁壮成长。 更新鲜的是，人们对风险和努力的看法是从他们基本的思维模式中衍生出来的，并不是说，一些人碰巧认识到了挑战自我的价值以及努力的重要性。我们通过研究发现，这些想法直接来源于成长型思维模式。当我们教给人们成长型思维模式，告诉他们要重视个人发展时，他们关于挑战和努力的看法自然就会变成我们之前说的那样。同样，当我们（暂时）将人们放入固定型思维模式，告诉他们个人能力是不会改变的，他们会很快对挑战感到恐惧，并对努力感到不屑。 我思维模式的改变源于我的工作。一天，我的一个博士生玛丽·班杜拉和我想要弄明白，为什么有些学生如此专注于证明他们的能力，而有些学生却不在乎这一点，仅仅是热衷于学习。突然间，我们发现人们对能力拥有两种不同的理解：一种认为能力是固定的，需要被证明；另一种则认为能力是可以改变的，是可以通过学习来培养的。 杰出的社会学家本杰明·巴伯曾经说：“我不会将世界两分成弱和强，或者成功和失败—–我会将世界分成好学者和不好学者。” 很多成长型思维模式者甚至没有想过要攀上顶峰。他们能达到这个高度，是因为他们在做自己喜欢的事。讽刺的是：顶峰是很多固定型思维模式者渴望到达的地方，却是很多成长型思维模式者的工作激情带来的副产品。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E7%BB%88%E8%BA%AB%E6%88%90%E9%95%BF%E3%80%8B/"},{"title":"经济机器是怎样运行的","text":"桥水基金创始人 瑞·达利欧 发布的经济科普视频中所得。 短期债务周期 长期债务周期 人们因为离波动太近，无法感知波动。 央行通过调整利率控制短期债务周期内的经济运行。 长期债务周期下行时，也叫去杠杆化时期，因为利率已经为 0 不能再降，手段失效。 降低支出 削减债务 财富再分配 央行发行更多货币 经济增长率需要大于债务增长率，否则永远无法脱离下行周期。 三条经验法则： 不要让债务的增长速度超过收入，因为债务负担最终将把你压垮 不要让收入的增长速度超过生产率，因为这最终将使你失去竞争力 尽一切努力提高生产率，因为生产率在长期内起着最关键的作用","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E7%BB%8F%E6%B5%8E%E6%9C%BA%E5%99%A8%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%90%E8%A1%8C%E7%9A%84/"},{"title":"缓存穿透击穿与雪崩","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-cache-collapse.html 缓存穿透概念缓存和数据库中都没有的数据，可用户还是源源不断的发起请求，导致每次请求都会到数据库，从而压垮数据库。 流程 说明比如客户查询一个根本不存在的东西，首先从 Redis 中查不到，然后会去数据库中查询，数据库中也查询不到，那么就不会将数据放入到缓存中，后面如果还有类似源源不断的请求，最后都会压到数据库来处理，从而给数据库造成巨大的压力。 解决办法业务层校验用户发过来的请求，根据请求参数进行校验，对于明显错误的参数，直接拦截返回。比如，请求参数为主键自增id，那么对于请求小于 0 的 id 参数，明显不符合，可以直接返回错误请求。 不存在数据设置短过期时间对于某个查询为空的数据，可以将这个空结果进行 Redis 缓存，但是设置很短的过期时间，比如 30s，可以根据实际业务设定。注意一定不要影响正常业务。 布隆过滤器布隆过滤器 是一种数据结构，利用极小的内存，可以判断大量的数据“一定不存在或者可能存在。 对于缓存穿透，我们可以将查询的数据条件都哈希到一个足够大的布隆过滤器中，用户发送的请求会先被布隆过滤器拦截，一定不存在的数据就直接拦截返回了，从而避免下一步对数据库的压力。 缓存击穿概念Redis 中一个热点 key 在失效的同时，大量的请求过来，从而会全部到达数据库，压垮数据库。 流程 说明这里要注意的是这是某一个热点 key 过期失效，和后面介绍缓存雪崩是有区别的。比如淘宝双十一，对于某个特价热门的商品信息，缓存在 Redis 中，刚好 0 点，这个商品信息在 Redis 中过期查不到了，这时候大量的用户又同时正好访问这个商品，就会造成大量的请求同时到达数据库。 解决办法设置热点数据永不过期对于某个需要频繁获取的信息，缓存在 Redis 中，并设置其永不过期。当然这种方式比较粗暴，对于某些业务场景是不适合的。 定时更新比如这个热点数据的过期时间是 1h，那么每到 59 minutes 时，通过定时任务去更新这个热点 key，并重新设置其过期时间。 互斥锁这是解决缓存击穿比较常用的方法。 互斥锁简单来说就是在 Redis 中根据 key 获得的 value 值为空时，先锁上，然后从数据库加载，加载完毕，释放锁。若其他线程也在请求该 key 时，发现获取锁失败，则睡眠一段时间（比如 100 ms）后重试。 缓存雪崩概念Redis 中缓存的数据大面积同时失效，或者 Redis 宕机，从而会导致大量请求直接到数据库，压垮数据库。 流程 说明对于一个业务系统，如果 Redis 宕机或大面积的 key 同时过期，会导致大量请求同时打到数据库，这是灾难性的问题。 解决办法设置有效期均匀分布避免缓存设置相近的有效期，我们可以在设置有效期时增加随机值；或者统一规划有效期，使得过期时间均匀分布。 数据预热对于即将来临的大量请求，我们可以提前走一遍系统，将数据提前缓存在 Redis 中，并设置不同的过期时间。 保证Redis服务高可用为防止 Redis 集群单节点故障，可以通过 Redis 的哨兵模式和集群模式实现高可用。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E5%87%BB%E7%A9%BF%E4%B8%8E%E9%9B%AA%E5%B4%A9/"},{"title":"《自律力》","text":"畅销书。 误区：自律不是强迫自己做事情 自由平等的灵魂才能在漫长的生命中互相欣赏，结伴同行。 你的外表是你最直观的名片。有一段话说：“以貌取人，绝对科学。性格写在唇边，幸福露在眼角。理性感性寄于声线，真诚虚伪映在瞳仁。站姿看出才华气度，步态可见自我认知。表情里有近来心境，眉宇间是过往岁月。衣着显审美，发型表个性。职业看手，修养看脚。”","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E8%87%AA%E5%BE%8B%E5%8A%9B%E3%80%8B/"},{"title":"《财务自由之路》","text":"美国佐治亚大学的托马斯·史丹利博士历时12年之久，致力于研究富人的生活。他得出了这样一个结论：这些人都属于世界上自身满意度最高的人，因为他们的梦想、目标、价值观和策略是协调一致的。 只有当你清晰地确定知道自己的价值观之后，你才能掌控自己的生活。 成功意味着得到你想要的东西，而幸福意味着热爱你所拥有的一切。 承担责任，拓宽你的可控领域。 从舒适的环境中脱离出来 解决问题 正确的提问方式 扩大你的个人范畴 我们充分利用自己的潜能时，会获得最大的满足感。我所理解的成功就是成为最好的自己。我全力以赴时，会感受到前所未有的活力。 持续不断地学习和成长 成长就是生命。持续不断地学习和成长意味着，感受到自身源源不断的活力，也意味着你能成为最好的自己。 你阅读的第一本书，应该是一本关于快速阅读的书，因为时间是无价的，只需要花3个小时来进行练习，你的阅读速度就会不断得到提升。 如果有机会结识有趣的人，一定要好好利用，不要将时间浪费在“闲聊”上。让Ta给你推荐两到三本Ta都铎的最好的书。接下来，问Ta为什么觉得这些书好，这样你就免费获得了一位优秀读者做出的总结。你在短短几分钟内就会知道，自己是否也应该读一读这本书。在这种方式的帮助下，我最终以书籍的形势接触到了许多宝藏。 同成功相比，我们更轻易地记住错误和失败，它们在我们大脑中留存的时间是成功的11倍。 将自己看作一个足够重要的人物，开始记录关于自己的日记。 大目标提升我们对机会的感知能力。许多人在某种程度上都倾向于对于自己有益的事物予以关注，而大目标对我们而言就是有益处的，让我们对更多的事物感兴趣，去发现更多的机会，结识更多新的朋友。 比赛是消极防御还是主动进攻，两者之间有着天壤之别 针对一项非必要的金钱支出，最愚蠢的辩解便是：“我需要它。我一定要买下它。”我们真正需要的东西其实是少之又少的。我们只是为了对自己的消费行为进行辩解，所以这样声称而已。 你应该付钱给自己，而且应该首先付钱给自己！我的建议是：自己给自己发薪水。将每月收入的10％存入一个独立账户中。这10％会让你变得安乐富足。余下的90％用于支付其他开支。 月初首先支付自己，自己比其他人更重要。 孩子应该在什么时候开始储蓄？从第一笔零花钱开始。你应该尽早将“支付自己”的理念告诉孩子。请让孩子接受有关储蓄和富裕的有用的信仰。我的一个朋友决定给他8岁的女儿10欧元零花钱，并让她在车上坐好。他对她说，他现在必须向她解释一些非常重要的事。他开车带着她去了城市中的贫民区。那里的一切，看起来黯淡无光。没有绿色，只有脏脏的泥土和混凝土。他问她，想住在这里，还是想住在他们那环境宜人的独栋宅院。他向她解释，她在未来10～15年还会和父母住在一起，但是之后就由她自己负责了。那时，她要么居住在这样一个可怕的环境中，要么住在一栋像他们家那样漂亮的房子里。并且，他告诉女儿，她现在就可以自己决定。他花了半天的时间来向他的女儿解释储蓄和“支付自己”的概念。他和她一起下车，穿过贫民区。他们一起在一家邋遢的饭馆里吃了午饭。当孩子感觉不舒服时，他说：“这里住的就是那些有10欧元就花10欧元的人。”回家以后，他们一起做了一个储蓄计划：女儿想将10欧元中的5欧元存下来。因为她每存1欧元，她的爸爸就会为她存50欧元，也就是说每月能存下250欧元。假设，我这位朋友和他的女儿坚持7年，然后他停止每月存250欧元的投资。即便如此，他的女儿在32岁之前也会获得超过200000欧元的金额。而我的朋友只需要投入21000欧元。更为重要的是：我朋友的女儿在很小的时候就轻松地学会了金钱的概念。也许她再也不需要从她父亲手上拿钱了。 我们真正需要的东西其实少之又少。我们只是为了对自己的消费行为进行辩解，所以这样声称而已。 影响复利的，只有三个重要因素：时间、利润率和投入 用72除以利率，你就能得到投入资本翻倍的年限。 我们的制度在很多方面就是使强者更强，弱者更弱。这看起来就是人类进化中的固有规律。 金钱只留给哪些了解并遵守资本法则的人。 一般情况下，只有当一个人有了一笔存款之后，他才会开始对高利润率感兴趣。在这之前，复利的力量只能与你擦肩而过。 资本主义使富人更加强大，会拿走那些无视其法则的人手上现有的东西。 想把某件事物变成必需品，我们就需要应用杠杆作用。这意味着我们要像使用杠杆那样施压。杠杆作用往往产生于：如果你不去做某件事情，你就会感受到巨大的痛苦；但是如果你做了，你就会感受到极大的快乐。 要使你的愿望变成绝对必需品，你的需求便是绝佳的理由。你为什么想要做，必须做某件事的理由。在需要做出决定的场合下，你应该经常使用”为什么“而不是”怎么做“来自我叩问。每一个达成过远大目标的人，都是将90%的精力放在”为什么“上，只将10%的精力放在”怎么做“上。 我们想要的东西（此处需要理解为消费品）并不等同于我们需要的东西； 消费债根本没有优点。更确切地说：消费债是愚蠢的行为，对人产生破坏性的效果，打击人的积极性，消磨人的精力，使人最终陷入一种恶性循环。 我们的大脑是如何运作的：我们可以为了避免痛苦、感受快乐去做任何事情。 对每一笔支出，都要问自己：这笔支出真的有必要吗？我必须花这笔钱吗？ 帮助并不会主动来到那些需要帮助的人面前，而是会来到那些值得获得帮助的人面前。 你的努力要以能够激发你动力的目标为导向：你在积累财富的同时也清除了你的债务。 以前我将自由定义为：能够去做自己想做的事情。而现在，我对自由的新定义是：自由意味着，自律地去执行我计划好的事情。 一天，我和我的教练一起去厨房取咖啡。他拿起一壶咖啡，直接就把咖啡往地上倒。我跳到一边，深怕咖啡溅到自己身上，同时喊道：“等等，等等，您还没拿杯子呢！”他无动于衷地继续倒咖啡。在我不知所措地望着地面的一摊咖啡时，我的教练缓慢而又有力地对我说道：“你看到了吗，舍费尔先生？咖啡就好像是你的才能，它们一文不值地躺在地上。没有倒进杯子的咖啡一文不值，再多也无用。没有自律，你的才能也是一文不值。”我的教练的做法有没有引起你的注意？他极为深刻地改变了我关于自律的信仰。在擦拭厨房地面的咖啡时，我第一次将自律看作我的才能的杠杆。自律就是力量，它决定了我们体内无尽的潜力的发挥程度。没有自律，任何一种才能都只能白白浪费。 知足常乐的人也是主动放弃的人。 专业人士是就算自己不认为自己是专业人士，也能够做到最好的人。 整天工作的人，没有时间来挣钱。 永远不要将你对自己的怀疑告知任何人，要展示自己的强项。人们不会追随一个自我怀疑的人，只会追随那些坚强不屈的、对目标坚定不移的人。 长时间用小火煮饭的人，他的火最终会完全熄灭。 刻不容缓的去处理事情 所有值得你去做的事情都值得你好好地去做。 一位投资者会在买入的时候获得利润，而非在卖出的时候。 投资应该使金钱流入你的口袋，而债务是金钱流出你的口袋。资金流动的方向就表明了这是一笔投资还是一笔债务。 我们所有人做的事情。往往并不正确。 如果每个人都集中全力做自己擅长的事情，就能使自己的生活质量得到巨大提升，一直以来都是如此。别的领域则委托其他擅长的人来做。在我认识到这一点之后，我便为自己找了一位优秀的值得信任的顾问。这是一个十分正确的决定。 他说：“有疑虑是很正常的，其实这就是对未来存在的消极想法。有两件事很重要：第一，除了我之外，你不能告诉任何人你对未来的疑虑；第二，每当你内心产生怀疑时，最好马上给我打电话。这样我们就可以马上谈论一些关于未来的美好愿景。” 你必须为自己创造出一种能促使你成功的环境。 你站上桌子，然后请一位比你瘦弱的朋友站到桌子前面，和你一起进行力量较量。你试着将他拽上桌子，而他试着将你拉下桌子。谁会赢呢？物理学原理是：将某人向下拉比将他往上拽会更容易。长时间比下去，你肯定赢不了。对手只需要“保持不动”，一直等到你筋疲力尽，他就赢了。与此同理的是：如果你身边都是比你贫穷的人，那么你就会停滞不前。如果你身边都是比你富有的人，那么你也会变得富有。 那些没有亲身经历过的人没有权利给建议，你也绝对没有理由去听从他们的建议。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E8%B4%A2%E5%8A%A1%E8%87%AA%E7%94%B1%E4%B9%8B%E8%B7%AF%E3%80%8B/"},{"title":"《超级记忆-宫殿记忆法》","text":"学会记忆术、思维导图、快速阅读。 无意识无能，有意识无能，有意识有能，无意识有能 纯声音记忆，即我们常说的机械记忆模式。《大悲咒》《楞严咒》 我们人类的大脑一共有三种记忆模式，其中最根本也是最基础的就是声音记忆。我们平常管这种记忆方法叫死记硬背。我们之所以拿这种完全听不懂的咒语来测试，就是为了排除其他记忆方法对记忆效果的影响。在记忆这些咒语的时候，没法理解，没有文字，而且只能靠耳朵来听，所以是纯粹的声音记忆模式。 有13个外表一模一样的小球产品，其中有一个是次品，其质量与其他12个略有差别，但不知道是重还是轻。假定这13个球上都有标号，现在给你一架天秤，只能使用三次，把这个次品小球找出来。注：必须要考虑到所有的可能。 这是一个利用催眠技术进行的简单的意向对话的过程。公路上出现的石头就是自己前进道路上的困难。如果总是试图绕过或者躲避困难，困难就还会以不同的方式来阻碍自己前进。只有彻底地把困难解决掉，才能让自己行进得更顺畅。房子里的箱子实际就是自己的目标，也可以理解为自己想要的东西。我们在定位目标的时候，会有很多很多的诱惑来干扰自己，让自己迷失方向。只有坚定自己的目标，让它更清晰、更明确，才有可能通过自己的努力去实现这个目标。 图像记忆 在记忆的时候多加细节描述词。 串联联想：所谓串联联想，就是把需要记忆的单词逐个转换成图像，然后通过一定的相互关系串联在一起。 下面的几条口诀希望你能牢记在心。 每一个词语必须有完全独立的清晰图像。 每个图像只能而且必须与前后的图像发生关系。 尽量不要出现没有关系的图像。 想象要夸张甚至脱离现实。 最好加入一些感觉。 “这种快速阅读又叫潜意识阅读，就是你在看书的时候大脑都可以神游出去，只要眼睛能看到书本上的东西就可以。” 波动阅读术 三遍阅读法：影像速读、波动速读、结构化速读 快速记忆法1：联想编故事。对于顺序记忆的词模式，可以使用。例如黄河流经的省份： 青海 四川 甘肃 宁夏 内蒙古 陕西 山西 河南 山东。技巧：1.串联联想的图像越具体，图像就会越牢固； 2.串联联想的时候，不相邻的词语不要有图像上的联结； 3.不要出现没有关系的图像；4.调动全身的视、听、味、触、体等多个感觉器官参与联想； 5.想象的世界不存在不合理，什么事情都可以发生。 快速记忆法 2：打桩链接。适合顺序记忆 人体桩 虚拟桩 实景桩 数字桩","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E8%B6%85%E7%BA%A7%E8%AE%B0%E5%BF%86-%E5%AE%AB%E6%AE%BF%E8%AE%B0%E5%BF%86%E6%B3%95%E3%80%8B/"},{"title":"路在脚下","text":"大学毕业之后，我来到北京工作，到今天已经三年了。这三年的时间里，经历了许多，想明白了很多事情。写下来，为我自己，也给正在读这篇文章的你一些启发。 感谢自己没有放弃追求真实我是一个一直在问为什么的人。 初中高中除了填鸭式的教育，看了不少网络小说、日本动漫。网络小说里的题材，一般是主角从零到无敌的爽文套路；火影、海贼、死神、妖尾，每一部都在阐释不同的世界观、价值观。这些让我对于人生有了一些宏观的概念。 现实的生活总是充满疑问，“听话”可以说是这部分的总结。有些事情可以暂时想不明白，但是可以先按照有经验的人提供的建议来做。这期间我发现了，有“做法”并不能填补内心的空缺，只有找到为什么，我才会满意。 高二的时候，我开始思考人生的意义，一直到现在，得出的答案有几个方向。 第一个是，活着就是为了快乐。看起来是最佳选择。 第二个是，为了给别人提供帮助，让社会变得更好。排除社会主义教育的熏陶这个因素，这真的是一个选项，因为帮助别人确实给自己带来快乐。双赢。 第三，活着是责任。这个选项是一次聚餐的时候，我向在座的各位“大人”提问得到的一个结果。无疑现实了很多。 第四，因为爱情。不做赘述。 第五，人生是没有意义的。 我一直在这五个选项里面徘徊，求证，希望自己能选对一个。不过从高中，大学，直到毕业工作了，我发现我骗不了自己，这些都不是能让我满意的答案。 我陷进去了。 所幸这些没有影响到我的生活，有些事情尽管不知道为什么，但是有一些做法是没有错的。就像是现在的神经网络，目前的做法是通过大量的数据集训练模型，然后用成熟的模型预测出样本的结果。模型里并没有 1+1=2 这种解释，只是用充足的数据告诉你，哪个结果是符合预期的。 我的每一天都会冒出这个问题。学习、工作、娱乐、谈恋爱，甚至每天早上为什么要醒过来，总会有那么一瞬间这个问题在脑海里出现。 如果没有找到答案的话，我应该会按照“正确的做法”度过一生吧。 先谈世界观2020 年疫情肆虐，过年回到北京，各种防疫措施，我过上了两点一线的生活。年初的时候美股熔断，这个时间我在读尤瓦尔赫拉利写的《人类简史》。 这本标着“简史”的名字，看起来是讲历史的书，读下来感觉是在讲人性。人在漫长的历史中为何变成了今天这个样子。 书里关于宗教、进化论以及感觉的观点让我印象深刻。 书里讲，佛教所说的禁欲其实并不是去抑制自己的欲望，而是观察自己的欲望，让欲望像水一样流过去。我头一次清晰的认识到，人和人的欲望是可以分开来看待的。 关于快乐的观点，打破了我的认知。作者说，快乐只是人体内激素的反应而已，机制是基于自然选择的生存进化。 我们接受的教育，在生物这个学科里，对于自然选择强调的是，选择了拥有能适应自然的生理特征的个体，存活至今。但是这里忽略了一个很重要的事实：自然选择不止选择了生理特征，还有人性的部分。 总结几个例子： 人都是八卦的。这是因为在组建部落的时候，个体需要记忆周围人的一些特征、发生的事情，依靠集体的力量提高生存概率。 人非常不喜欢思考，很乐于接受别人的观点。我们对于一些概念比如国家、公司、孙悟空的认知，是基于想象力的。人类的认知形成基于两步，第一步是想象力构建，第二步是判断。想象力是一个被动的过程，而判断是一个主动的过程。外部信息通过想象力自动在脑海里形成初步认知，而判断这个第二个过程很多时候都是缺失的，这就造成了认知的盲目性。 人的感觉很多时候都在误导自己。这个称之为进化的惯性。感觉基于激素的分泌，身体感觉的产生逻辑，是基于进化过程中的生存规则，目的是通过这种机制降低死亡的概率。 自从工业革命之后，人类的生产力得到了飞跃式的提升。到今天，在中国，说的通俗点，只是想活到 60 岁的话不是难事。人的生存风险被极大程度的降低了。 从人类文明发展的角度看，自然选择的比重已经下降到了很低的水平，取而代之的是人为选择的过程。 人为选择规则是什么呢，显而易见的是金钱、权利等等。整个社会构成是个金字塔，下层的人向上输送资源，为上层的人提供更好的条件。这是人性的必然结果。 对人性理解的越深刻，越能理解一些社会现象、经济规律等等。 再说未来。工业革命、信息革命推动了 20 世纪的文明进程，21 世纪的这一百年，我认为有四种可能性： 文明倒退。目前已知的能威胁到人类的，像没有对策的病毒、全球变暖、板块运动、小行星撞击、核战争等等，如果发生，文明停滞是不可避免的，甚至可能出现倒退。又回到了自然选择的时代。 物理学的突破。四种基本力转换、量子力学，物理学上的突破带来的变革，会把人类带向一个新的时代，比如星际旅行等。 人工智能的变革。 人类自身的进化。举例，长生不老，超人。 四个方向并不互斥，可能会交叉进行。 接着是方法论对于人性、社会、未来的更深入的认识，让我的世界观变得更完整了。接下来就是方法论的部分，引子是一些理财的书籍。 《小狗钱钱》，理财启蒙书籍，用故事的形式讲解了一些基本的理财手段和金融概念。让我受到启发的，是小女孩从开头到结尾的成长过程，先找到一个目标，然后制定策略，之后获得正面反馈，再尝试更大的目标。 我找到了灵感。这不就是一条路么。后续我又读了《财务自由之路》《穷爸爸富爸爸》《苏世民-我的经验与教训》，这些标着理财标签的书，读下来感觉实际上讲的是人生。 总结下来，我找到了我的方法论： 找到你的目标，用一生的时间要做的事情。感性的你和理性的你都想实现的事情。 形成正反馈。 半年时间，我做到了规律作息、每天早起看书、有节奏的锻炼身体、计划和复盘等等。 未来变得可期了。 后边的一段时间，跟朋友们分享我的所得。 我发现，这个方法有很多的不适用人群。有些人不能接受世界观，有些人找不到合适的目标，有些人的目标在跟现实生活重叠时出现了严重的冲突。每个人都有不一样的现实。 有缘人得之我把找到路的方法记录下来，希望能帮到这个时代迷茫的人。 每个人的身体里，有两个“自己”在影响决策。这两个自己有不同的思考逻辑，我们的决策就是两个思考逻辑共同输出的结果。 其中一个是低层次的、依靠感觉的，这个“自己”的思考速度很快，是自然选择留下来的有利于生存的决策。从这个层面理解快乐、悲伤，以及成瘾等等，这是接下来的基础。 另一个是高层次的、依靠逻辑判断的部分，它的思考需要基于已知来判断未知。我们学习、生活等等学到的逻辑慢慢的都在转化成这部分。现代社会人类的进化主要体现在脑能力的进化，这是真实的趋势。 我的这个办法最关键的地方就在于找到属于你的目标。这个目标有几个要求： 要足够长远，有一生这么长。这意味着不能是歪门邪道，不能是短期快感，对自己、对别人都要是一件好事才行。 符合“两个自己”的利益。在感性和理性的层面上都要渴望这个目标。 形成正反馈。需要感觉上的正反馈和逻辑上的正反馈，并且可以反馈到每一天。 我来说明一下为什么这个方法是可行的。 首先举个小例子，量化我们想做一件事的程度，我把这个程度成为快乐值。把无聊这种状态标为 0，然后把刷个短视频标为 1 。人最根本的思考逻辑是避免痛苦，追求快乐。在一个确定的时间点，没有其他因素影响的情况下，人会选择做快乐值更高的事情。 长期的成就更能提高这个快乐值，比如长期目标的实现标为 100 。通俗举例：努力学习靠本事通过考试。 关键就在于，如何分解这个长期的快乐值，分解到每一天，让它大于，比如短视频的这个 1 。 做到了，感性和理性都会满足，两个自己都是更快乐的。这种快乐可以每天被重复下去，并且最终实现 100 。 基本的原理就是以上这部分。","link":"/%E6%84%9F%E6%82%9F/%E8%B7%AF%E5%9C%A8%E8%84%9A%E4%B8%8B/"},{"title":"Redis变慢定位","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-slow.html Redis变慢定位Redis 作为内存数据库，拥有非常高的性能，单个实例的 QPS 能够达到 10W 左右。但我们在使用 Redis 时，经常时不时会出现访问延迟很大的情况，如果你不知道 Redis 的内部实现原理，在排查问题时就会一头雾水。 很多时候，Redis 出现访问延迟变大，都与我们的使用不当或运维不合理导致的。 Redis变慢常见原因使用复杂度高的命令如果在使用 Redis 时，发现访问延迟突然增大，如何进行排查？首先，第一步，建议你去查看一下 Redis 的慢日志。Redis 提供了慢日志命令的统计功能，我们通过以下设置，就可以查看有哪些命令在执行时延迟比较大。 首先设置 Redis 的慢日志阈值，只有超过阈值的命令才会被记录，这里的单位是微妙，例如设置慢日志的阈值为 5 毫秒，同时设置只保留最近 1000 条慢日志记录： 12345# 命令执行超过5毫秒记录慢日志CONFIG SET slowlog-log-slower-than 5000# 只保留最近1000条慢日志CONFIG SET slowlog-max-len 1000 设置完成之后，所有执行的命令如果延迟大于 5 毫秒，都会被 Redis 记录下来，我们执行 SLOWLOG get 5 查询最近5条慢日志： 12345678910111213127.0.0.1:6379&gt; SLOWLOG get 51) 1) (integer) 32693 # 慢日志ID 2) (integer) 1593763337 # 执行时间 3) (integer) 5299 # 执行耗时(微妙) 4) 1) &quot;LRANGE&quot; # 具体执行的命令和参数 2) &quot;user_list_2000&quot; 3) &quot;0&quot; 4) &quot;-1&quot;2) 1) (integer) 32692 2) (integer) 1593763337 3) (integer) 5044 4) 1) &quot;GET&quot; 2) &quot;book_price_1000&quot; 通过查看慢日志记录，我们就可以知道在什么时间执行哪些命令比较耗时，如果你的业务经常使用 O(N) 以上复杂度的命令，例如 sort、sunion、zunionstore，或者在执行 O(N) 命令时操作的数据量比较大，这些情况下 Redis 处理数据时就会很耗时。 如果你的服务请求量并不大，但 Redis 实例的 CPU 使用率很高，很有可能是使用了复杂度高的命令导致的。 解决方案就是，不使用这些复杂度较高的命令，并且一次不要获取太多的数据，每次尽量操作少量的数据，让 Redis 可以及时处理返回。 存储bigkey如果查询慢日志发现，并不是复杂度较高的命令导致的，例如都是 **SET**、 DELETE 操作出现在慢日志记录中，那么你就要怀疑是否存在 Redis 写入了 bigkey 的情况。 Redis 在写入数据时，需要为新的数据分配内存，当从 Redis 中删除数据时，它会释放对应的内存空间。如果一个 key 写入的数据非常大，Redis 在分配内存时也会比较耗时。同样的，当删除这个 key 的数据时，释放内存也会耗时比较久。 你需要检查你的业务代码，是否存在写入 bigkey 的情况，需要评估写入数据量的大小，业务层应该避免一个 key 存入过大的数据量。那么有没有什么办法可以扫描现在 Redis 中是否存在 bigkey 的数据吗？Redis 也提供了扫描 bigkey 的方法： 1redis-cli -h $host -p $port --bigkeys -i 0.01 使用上面的命令就可以扫描出整个实例 key 大小的分布情况，它是以类型维度来展示的。 需要注意的是当我们在线上实例进行 bigkey 扫描时，Redis 的 QPS 会突增，为了降低扫描过程中对 Redis 的影响，我们需要控制扫描的频率，使用 -i 参数控制即可，它表示扫描过程中每次扫描的时间间隔，单位是秒。 使用这个命令的原理，其实就是 Redis 在内部执行 scan 命令，遍历所有 key，然后针对不同类型的 key 执行 strlen、llen、hlen、scard、zcard 来获取字符串的长度以及容器类型(list/dict/set/zset)的元素个数。 而对于容器类型的 key，只能扫描出元素最多的 key，但元素最多的 key 不一定占用内存最多，这一点需要我们注意下。不过使用这个命令一般我们是可以对整个实例中 key 的分布情况有比较清晰的了解。 针对 bigkey 的问题，Redis 官方在 4.0 版本推出了 lazy-free 的机制，用于异步释放 bigkey 的内存，降低对 Redis 性能的影响。即使这样，我们也不建议使用 bigkey，bigkey 在集群的迁移过程中，也会影响到迁移的性能。 集中过期有时你会发现，平时在使用 Redis 时没有延时比较大的情况，但在某个时间点突然出现一波延时，而且报慢的时间点很有规律，例如某个整点，或者间隔多久就会发生一次。 如果出现这种情况，就需要考虑是否存在大量 key 集中过期的情况。如果有大量的 key 在某个固定时间点集中过期，在这个时间点访问 Redis 时，就有可能导致延迟增加。 Redis 的过期策略采用主动过期+懒惰过期两种策略： 主动过期：Redis 内部维护一个定时任务，默认每隔 100 毫秒会从过期字典中随机取出 20 个 key，删除过期的 key，如果过期 key 的比例超过了 25%，则继续获取 20 个 key，删除过期的 key，循环往复，直到过期 key 的比例下降到 25% 或者这次任务的执行耗时超过了 25 毫秒，才会退出循环。 懒惰过期：只有当访问某个 key 时，才判断这个 key 是否已过期，如果已经过期，则从实例中删除。 注意，Redis 的主动过期的定时任务，也是在 Redis 主线程中执行的，也就是说如果在执行主动过期的过程中，出现了需要大量删除过期 key 的情况，那么在业务访问时，必须等这个过期任务执行结束，才可以处理业务请求。此时就会出现，业务访问延时增大的问题，最大延迟为 25 毫秒。 而且这个访问延迟的情况，不会记录在慢日志里。慢日志中只记录真正执行某个命令的耗时，Redis 主动过期策略执行在操作命令之前，如果操作命令耗时达不到慢日志阈值，它是不会计算在慢日志统计中的，但我们的业务却感到了延迟增大。 此时你需要检查你的业务，是否真的存在集中过期的代码，一般集中过期使用的命令是 expireat 或 pexpireat 命令，在代码中搜索这个关键字就可以了。 如果你的业务确实需要集中过期掉某些 key，又不想导致 Redis 发生抖动，有什么优化方案？解决方案是，在集中过期时增加一个随机时间，把这些需要过期的 key 的时间打散即可。伪代码可以这么写： 12# 在过期时间点之后的5分钟内随机过期掉redis.expireat(key, expire_time + random(300)) 这样 Redis 在处理过期时，不会因为集中删除 key 导致压力过大，阻塞主线程。另外，除了业务使用需要注意此问题之外，还可以通过运维手段来及时发现这种情况。 做法是我们需要把 Redis 的各项运行数据监控起来，执行 info 可以拿到所有的运行数据，在这里我们需要重点关注 expired_keys 这一项，它代表整个实例到目前为止，累计删除过期 key 的数量。 我们需要对这个指标监控，当在很短时间内这个指标出现突增时，需要及时报警出来，然后与业务报慢的时间点对比分析，确认时间是否一致，如果一致，则可以认为确实是因为这个原因导致的延迟增大。 实例内存达到上限有时我们把 Redis 当做纯缓存使用，就会给实例设置一个内存上限 maxmemory，然后开启 LRU 淘汰策略。当实例的内存达到了 maxmemory 后，你会发现之后的每次写入新的数据，有可能变慢了。 导致变慢的原因是，当 Redis 内存达到 maxmemory 后，每次写入新的数据之前，必须先踢出一部分数据，让内存维持在 maxmemory 之下。这个踢出旧数据的逻辑也是需要消耗时间的，而具体耗时的长短，要取决于配置的淘汰策略： allkeys-lru：不管 key 是否设置了过期，淘汰最近最少访问的 key volatile-lru：只淘汰最近最少访问并设置过期的 key allkeys-random：不管 key 是否设置了过期，随机淘汰 volatile-random：只随机淘汰有设置过期的 key allkeys-ttl：不管 key 是否设置了过期，淘汰即将过期的 key noeviction：不淘汰任何 key，满容后再写入直接报错 allkeys-lfu：不管 key 是否设置了过期，淘汰访问频率最低的 key（4.0+支持） volatile-lfu：只淘汰访问频率最低的过期 key（4.0+支持） 具体使用哪种策略，需要根据业务场景来决定。 我们最常使用的一般是 allkeys-lru 或 volatile-lru 策略，它们的处理逻辑是，每次从实例中随机取出一批 key（可配置），然后淘汰一个最少访问的 key，之后把剩下的 key 暂存到一个池子中，继续随机取出一批 key，并与之前池子中的 key 比较，再淘汰一个最少访问的 key。以此循环，直到内存降到 maxmemory 之下。 如果使用的是 allkeys-random 或 volatile-random 策略，那么就会快很多，因为是随机淘汰，那么就少了比较 key 访问频率时间的消耗了，随机拿出一批 key 后直接淘汰即可，因此这个策略要比上面的 LRU 策略执行快一些。 但以上这些逻辑都是在访问 Redis 时，真正命令执行之前执行的，也就是它会影响我们访问 Redis 时执行的命令。另外，如果此时 Redis 实例中有存储 bigkey，那么在淘汰 bigkey 释放内存时，这个耗时会更加久，延迟更大，这需要我们格外注意。 如果你的业务访问量非常大，并且必须设置 maxmemory 限制实例的内存上限，同时面临淘汰 key 导致延迟增大的的情况，要想缓解这种情况，除了上面说的避免存储 bigkey、使用随机淘汰策略之外，也可以考虑拆分实例的方法来缓解，拆分实例可以把一个实例淘汰 key 的压力分摊到多个实例上，可以在一定程度降低延迟。 fork耗时严重如果你的 Redis 开启了自动生成 RDB 和 AOF 重写功能，那么有可能在后台生成 RDB 和 AOF 重写时导致 Redis 的访问延迟增大，而等这些任务执行完毕后，延迟情况消失。 遇到这种情况，一般就是执行生成 RDB 和 AOF 重写任务导致的。 生成 RDB 和 AOF 都需要父进程 fork 出一个子进程进行数据的持久化，在 fork 执行过程中，父进程需要拷贝内存页表给子进程，如果整个实例内存占用很大，那么需要拷贝的内存页表会比较耗时，此过程会消耗大量的 CPU 资源，在完成 fork 之前，整个实例会被阻塞住，无法处理任何请求，如果此时 CPU 资源紧张，那么 fork 的时间会更长，甚至达到秒级。这会严重影响 Redis 的性能。 我们可以执行 info 命令，查看最后一次 fork 执行的耗时 latest_fork_usec，单位微妙。这个时间就是整个实例阻塞无法处理请求的时间。 除了因为备份的原因生成 RDB 之外，在主从节点第一次建立数据同步时，主节点也会生成RDB文件给从节点进行一次全量同步，这时也会对 Redis 产生性能影响。 要想避免这种情况，我们需要规划好数据备份的周期，建议在从节点上执行备份，而且最好放在低峰期执行。如果对于丢失数据不敏感的业务，那么不建议开启 AOF 和 AOF 重写功能。 另外，fork 的耗时也与系统有关，如果把 Redis 部署在虚拟机上，那么这个时间也会增大。所以使用 Redis 时建议部署在物理机上，降低 fork 的影响。 绑定CPU很多时候，我们在部署服务时，为了提高性能，降低程序在使用多个 CPU 时上下文切换的性能损耗，一般会采用进程绑定 CPU 的操作。 但在使用 Redis 时，我们不建议这么干，原因如下。 绑定 CPU 的 Redis，在进行数据持久化时，fork 出的子进程，子进程会继承父进程的 CPU 使用偏好，而此时子进程会消耗大量的 CPU 资源进行数据持久化，子进程会与主进程发生 CPU 争抢，这也会导致主进程的 CPU 资源不足访问延迟增大。 所以在部署 Redis 进程时，如果需要开启 RDB 和 AOF 重写机制，一定不能进行 CPU 绑定操作！ AOF配合不合理上面提到了，当执行 AOF 文件重写时会因为 fork 执行耗时导致 Redis 延迟增大，除了这个之外，如果开启 AOF 机制，设置的策略不合理，也会导致性能问题。 开启 AOF 后，Redis 会把写入的命令实时写入到文件中，但写入文件的过程是先写入内存，等内存中的数据超过一定阈值或达到一定时间后，内存中的内容才会被真正写入到磁盘中。 AOF 为了保证文件写入磁盘的安全性，提供了 3 种刷盘机制： appendfsync always：每次写入都刷盘，对性能影响最大，占用磁盘 IO 比较高，数据安全性最高。 appendfsync everysec：1 秒刷一次盘，对性能影响相对较小，节点宕机时最多丢失 1 秒的数据。 appendfsync no：按照操作系统的机制刷盘，对性能影响最小，数据安全性低，节点宕机丢失数据取决于操作系统刷盘机制。 当使用第一种机制 appendfsync always 时，Redis 每处理一次写命令，都会把这个命令写入磁盘，而且这个操作是在主线程中执行的。 内存中的的数据写入磁盘，这个会加重磁盘的 IO 负担，操作磁盘成本要比操作内存的代价大得多。如果写入量很大，那么每次更新都会写入磁盘，此时机器的磁盘 IO 就会非常高，拖慢 Redis 的性能，因此我们不建议使用这种机制。 与第一种机制对比，appendfsync everysec 会每隔 1 秒刷盘，而 appendfsync no 取决于操作系统的刷盘时间，安全性不高。因此我们推荐使用 appendfsync everysec 这种方式，在最坏的情况下，只会丢失 1 秒的数据，但它能保持较好的访问性能。 当然，对于有些业务场景，对丢失数据并不敏感，也可以不开启 AOF。 使用Swap如果你发现 Redis 突然变得非常慢，每次访问的耗时都达到了几百毫秒甚至秒级，那此时就检查 Redis 是否使用到了 Swap，这种情况下 Redis 基本上已经无法提供高性能的服务。 我们知道，操作系统提供了 Swap 机制，目的是为了当内存不足时，可以把一部分内存中的数据换到磁盘上，以达到对内存使用的缓冲。 但当内存中的数据被换到磁盘上后，访问这些数据就需要从磁盘中读取，这个速度要比内存慢太多！ 尤其是针对 Redis 这种高性能的内存数据库来说，如果 Redis 中的内存被换到磁盘上，对于 Redis 这种性能极其敏感的数据库，这个操作时间是无法接受的。 我们需要检查机器的内存使用情况，确认是否确实是因为内存不足导致使用到了 Swap。 如果确实使用到了 Swap，要及时整理内存空间，释放出足够的内存供 Redis 使用，然后释放 Redis 的 Swap，让 Redis 重新使用内存。 释放 Redis 的 Swap 过程通常要重启实例，为了避免重启实例对业务的影响，一般先进行主从切换，然后释放旧主节点的 Swap，重新启动服务，待数据同步完成后，再切换回主节点即可。 可见，当 Redis 使用到 Swap 后，此时的 Redis 的高性能基本被废掉，所以我们需要提前预防这种情况。 我们需要对 Redis 机器的内存和 Swap 使用情况进行监控，在内存不足和使用到 Swap 时及时报警出来，及时进行相应的处理。 网卡负载过高如果以上产生性能问题的场景，你都规避掉了，而且 Redis 也稳定运行了很长时间，但在某个时间点之后开始，访问 Redis 开始变慢了，而且一直持续到现在，这种情况是什么原因导致的？ 之前我们就遇到这种问题，特点就是从某个时间点之后就开始变慢，并且一直持续。这时你需要检查一下机器的网卡流量，是否存在网卡流量被跑满的情况。 网卡负载过高，在网络层和 TCP 层就会出现数据发送延迟、数据丢包等情况。Redis 的高性能除了内存之外，就在于网络 IO，请求量突增会导致网卡负载变高。 如果出现这种情况，你需要排查这个机器上的哪个 Redis 实例的流量过大占满了网络带宽，然后确认流量突增是否属于业务正常情况，如果属于那就需要及时扩容或迁移实例，避免这个机器的其他实例受到影响。 运维层面，我们需要对机器的各项指标增加监控，包括网络流量，在达到阈值时提前报警，及时与业务确认并扩容。 总结定位 Redis 变慢问题，需要我们从各个方面综合考虑，除了以上常见的方法之外，我们还可以使用 info 命令，查看 Redis 的各方面的性能指标，尤其是 memory 和 stats。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E5%8F%98%E6%85%A2%E5%AE%9A%E4%BD%8D/"},{"title":"Redis数据持久化RDB与AOF","text":"原文：https://haicoder.net/note/redis-interview/redis-interview-redis-rdb-aof.html Redis数据持久化Redis 作为一个内存数据库，数据是以内存为载体存储的，那么一旦 Redis 服务器进程退出，服务器中的数据也会消失。为了解决这个问题，Redis 提供了持久化机制，也就是把内存中的数据保存到磁盘当中，避免数据意外丢失。 Redis 提供了两种持久化方案：RDB 持久化和 AOF 持久化，一个是快照的方式，一个是类似日志追加的方式。 RDB快照持久化概念RDB 持久化是通过快照的方式，即在指定的时间间隔内将内存中的数据集快照写入磁盘。在创建快照之后，用户可以备份该快照，可以将快照复制到其他服务器以创建相同数据的服务器副本，或者在重启服务器后恢复数据。RDB 是 Redis 默认的持久化方式。 快照持久化RDB 持久化会生成 RDB 文件，该文件是一个压缩过的二进制文件，可以通过该文件还原快照时的数据库状态，即生成该 RDB 文件时的服务器数据。RDB 文件默认为当前工作目录下的 dump.rdb，可以根据配置文件中的 dbfilename 和 dir 设置 RDB 的文件名和文件位置，具体配置如下： 123456# 设置dump的文件名dbfilename dump.rdb# 工作目录# 例如上面的dbfilename只指定了文件名，但是它会写入到这个目录下。这个配置项一定是个目录，而不能是文件名。dir ./ 相关配置12345678910111213141516171819202122# RDB自动持久化规则# 当 900 秒内有至少有 1 个键被改动时，自动进行数据集保存操作save 900 1# 当 300 秒内有至少有 10 个键被改动时，自动进行数据集保存操作save 300 10# 当 60 秒内有至少有 10000 个键被改动时，自动进行数据集保存操作save 60 10000# RDB持久化文件名dbfilename dump-&lt;port&gt;.rdb# 数据持久化文件存储目录dir /var/lib/redis# bgsave发生错误时是否停止写入，通常为yesstop-writes-on-bgsave-error yes# rdb文件是否使用压缩格式rdbcompression yes# 是否对rdb文件进行校验和检验，通常为yesrdbchecksum yes 触发快照的时机 执行 save 和 bgsave 命令 配置文件设置 save &lt;seconds&gt; &lt;changes&gt; 规则，自动间隔性执行 bgsave 命令 主从复制时，从库全量复制同步主库数据，主库会执行 bgsave 执行 flushall 命令清空服务器数据 执行 shutdown 命令关闭 Redis 时，会执行 save 命令 save和bgsave命令区别执行 save 和 bgsave 命令，可以手动触发快照，生成 RDB 文件，两者的区别为使用 save 命令会阻塞 Redis 服务器进程，服务器进程在 RDB 文件创建完成之前是不能处理任何的命令请求： 12127.0.0.1:6379&gt; saveOK 而使用 bgsave 命令不同的是，bgsave 命令会 fork 一个子进程，然后该子进程会负责创建 RDB 文件，而服务器进程会继续处理命令请求： 12127.0.0.1:6379&gt; bgsaveBackground saving started 其中，fork() 是由操作系统提供的函数，作用是创建当前进程的一个副本作为子进程，具体流程如下： fork 一个子进程，子进程会把数据集先写入临时文件，写入成功之后，再替换之前的 RDB 文件，用二进制压缩存储，这样可以保证 RDB 文件始终存储的是完整的持久化内容。 自动间隔触发在配置文件中设置 save &lt;seconds&gt; &lt;changes&gt; 规则，可以自动间隔性执行 bgsave 命令，具体配置如下： 123456789101112131415161718192021222324################################ SNAPSHOTTING ################################## Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## In the example below the behaviour will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## Note: you can disable saving completely by commenting out all &quot;save&quot; lines.## It is also possible to remove all the previously configured save# points by adding a save directive with a single empty string argument# like in the following example:## save &quot;&quot;save 900 1save 300 10save 60 10000 save &lt;seconds&gt; &lt;changes&gt; 表示在 seconds 秒内，至少有 changes 次变化，就会自动触发 bgsave 命令，具体配置解释如下： | 配置 | 描述 | | ————- | ———————————————————— | | save 900 1 | 当时间到900秒时，如果至少有1个key发生变化，就会自动触发bgsave命令创建快照 | | save 300 10 | 当时间到300秒时，如果至少有10个key发生变化，就会自动触发bgsave命令创建快照 | | save 60 10000 | 当时间到60秒时，如果至少有10000个key发生变化，就会自动触发bgsave命令创建快照 | save与bgsave| 命令 | save | bgsave | | —— | —————— | ———————————- | | IO类型 | 同步 | 异步 | | 阻塞？ | 是 | 是（阻塞发生在fock()，通常非常快） | | 复杂度 | O(n) | O(n) | | 优点 | 不会消耗额外的内存 | 不阻塞客户端命令 | | 缺点 | 阻塞客户端命令 | 需要fock子进程，消耗内存 | AOF持久化概念除了 RDB 持久化，Redis 还提供了 AOF（Append Only File）持久化功能，AOF 持久化会把被执行的写命令写到 AOF 文件的末尾，记录数据的变化。默认情况下，Redis 是没有开启 AOF 持久化的，开启后，每执行一条更改 Redis 数据的命令，都会把该命令追加到 AOF 文件中，这是会降低 Redis 的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高 AOF 的性能。 配置可以通过配置 redis.conf 文件开启 AOF 持久化，关于 AOF 的配置如下： 1234567891011121314151617181920212223242526# appendonly参数开启AOF持久化appendonly no# AOF持久化的文件名，默认是appendonly.aofappendfilename &quot;appendonly.aof&quot;# AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的dir ./# 同步策略# appendfsync alwaysappendfsync everysec# appendfsync no# aof重写期间是否同步no-appendfsync-on-rewrite no# 重写触发配置auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb# 加载aof出错如何处理aof-load-truncated yes# 文件重写策略aof-rewrite-incremental-fsync yes AOF的实现AOF 需要记录 Redis 的每个写命令，步骤为：命令追加（append）、文件写入（write）和文件同步（sync）。 命令追加开启 AOF 持久化功能后，服务器每执行一个写命令，都会把该命令以协议格式先追加到 aof_buf 缓存区的末尾，而不是直接写入文件，避免每次有命令都直接写入硬盘，减少硬盘 IO 次数。 文件写入和同步对于何时把 aof_buf 缓冲区的内容写入保存在 AOF 文件中，Redis 提供了多种策略： | 配置 | 描述 | | ——————– | ———————————————————— | | appendfsync always | 将 aof_buf 缓冲区的所有内容写入并同步到 AOF 文件，每个写命令同步写入磁盘 | | appendfsync everysec | 将 aof_buf 缓存区的内容写入 AOF 文件，每秒同步一次，该操作由一个线程专门负责 | | appendfsync no | 将 aof_buf 缓存区的内容写入 AOF 文件，什么时候同步由操作系统来决定 | appendfsync 选项的默认配置为 everysec，即每秒执行一次同步，关于 AOF 的同步策略是涉及到操作系统的 write 函数和 fsync 函数的，在 《Redis设计与实现》 中是这样说明的： 为了提高文件写入效率，在现代操作系统中，当用户调用 write 函数，将一些数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区的空间被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里。 这样的操作虽然提高了效率，但也为数据写入带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了 fsync、fdatasync 同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性。 从上面的介绍我们知道，我们写入的数据，操作系统并不一定会马上同步到磁盘，所以 Redis 才提供了 appendfsync 的选项配置。当该选项时为 always 时，数据安全性是最高的，但是会对磁盘进行大量的写入，Redis 处理命令的速度会受到磁盘性能的限制；appendfsync everysec 选项则兼顾了数据安全和写入性能，以每秒一次的频率同步 AOF 文件，即便出现系统崩溃，最多只会丢失一秒内产生的数据；如果是 appendfsync no 选项，Redis 不会对 AOF 文件执行同步操作，而是有操作系统决定何时同步，不会对 Redis 的性能带来影响，但假如系统崩溃，可能会丢失不定数量的数据。 always、everysec、no对比| 命令 | 优点 | 缺点 | | ——– | ——————————– | ——————————— | | always | 不丢失数据 | IO开销大，一般SATA磁盘只有几百TPS | | everysec | 每秒进行与fsync，最多丢失1秒数据 | 可能丢失1秒数据 | | no | 不用管 | 不可控 | AOF重写(rewrite)在了解 AOF 重写之前，我们先来看看 AOF 文件中存储的内容是啥，先执行两个写操作： 1234127.0.0.1:6379&gt; set s1 helloOK127.0.0.1:6379&gt; set s2 worldOK 然后我们打开 appendonly.aof 文件，可以看到如下内容： 1234567891011121314*3$3set$2s1$5hello*3$3set$2s2$5world 该命令格式为 Redis 的序列化协议（RESP）。*3 代表这个命令有三个参数，$3 表示该参数长度为 3，看了上面的 AOP 文件的内容，我们应该能想象，随着时间的推移，Redis 执行的写命令会越来越多，AOF 文件也会越来越大，过大的 AOF 文件可能会对 Redis 服务器造成影响，如果使用 AOF 文件来进行数据还原所需时间也会越长。 时间长了，AOF 文件中通常会有一些冗余命令，比如：过期数据的命令、无效的命令（重复设置、删除）、多个命令可合并为一个命令（批处理命令）。所以 AOF 文件是有精简压缩的空间的。 AOF 重写的目的就是减小 AOF 文件的体积，不过值得注意的是：AOF 文件重写并不需要对现有的 AOF 文件进行任何读取、分享和写入操作，而是通过读取服务器当前的数据库状态来实现的，文件重写可分为手动触发和自动触发，手动触发执行 bgrewriteaof 命令，该命令的执行跟 bgsave 触发快照时类似的，都是先 fork 一个子进程做具体的工作： 12127.0.0.1:6379&gt; bgrewriteaofBackground append only file rewriting started 自动触发会根据 auto-aof-rewrite-percentage 和 auto-aof-rewrite-min-size 64mb 配置来自动执行 bgrewriteaof 命令： 123# 表示当AOF文件的体积大于64MB，且AOF文件的体积比上一次重写后的体积大了一倍（100%）时，会执行`bgrewriteaof`命令auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 下面看一下执行 bgrewriteaof 命令，重写的流程： 说明如下： 重写会有大量的写入操作，所以服务器进程会 fork 一个子进程来创建一个新的 AOF 文件 在重写期间，服务器进程继续处理命令请求，如果有写入的命令，追加到 aof_buf 的同时，还会追加到 aof_rewrite_buf AOF 重写缓冲区 当子进程完成重写之后，会给父进程一个信号，然后父进程会把 AOF 重写缓冲区的内容写进新的 AOF 临时文件中，再对新的 AOF 文件改名完成替换，这样可以保证新的 AOF 文件与当前数据库数据的一致性 AOF重写配置| 配置名 | 含义 | | ————————— | —————————– | | auto-aof-rewrite-min-size | 触发AOF文件执行重写的最小尺寸 | | auto-aof-rewrite-percentage | 触发AOF文件执行重写的增长率 | | 统计名 | 含义 | | —————- | ————————————- | | aof_current_size | AOF文件当前尺寸（字节） | | aof_base_size | AOF文件上次启动和重写时的尺寸（字节） | AOF重写自动触发机制，需要同时满足下面两个条件： 12aof_current_size &gt; auto-aof-rewrite-min-size(aof_current_size - aof_base_size) * 100 / aof_base_size &gt; auto-aof-rewrite-percentage 假设 Redis 的配置项为： 12auto-aof-rewrite-min-size 64mbauto-aof-rewrite-percentage 100 当 AOF 文件的体积大于 64Mb，并且 AOF 文件的体积比上一次重写之久的体积大了至少一倍（100%）时，Redis 将执行 bgrewriteaof 命令进行重写。 AOF重写原理当 AOF 文件的大小超过所设定的阈值时，redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。假如我们调用了 100 次 INCR 指令，在 AOF 文件中就要存储 100 条指令，但这明显是很低效的，完全可以把这 100 条指令合并成一条 SET 指令，这就是重写机制的原理。 在进行 AOF 重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响 AOF 文件的可用性。 AOF 方式的另一个好处，我们通过一个 “场景再现” 来说明。某同学在操作 redis 时，不小心执行了 flushall，导致 redis 内存中的数据全部被清空了，只要 redis 配置了 AOF 持久化方式，且 AOF 文件还没有被重写（rewrite），我们就可以用最快的速度暂停 redis 并编辑 AOF 文件，将最后一行的 FLUSHALL 命令删除，然后重启 redis，就可以恢复 redis 的所有数据到 FLUSHALL 之前的状态了。但是如果 AOF 文件已经被重写了，那就无法通过这种方法来恢复数据了。 数据恢复Redis4.0 开始支持 RDB 和 AOF 的混合持久化（可以通过配置项 aof-use-rdb-preamble 开启） 如果是 redis 进程挂掉，那么重启 redis 进程即可，直接基于 AOF 日志文件恢复数据 如果是 redis 进程所在机器挂掉，那么重启机器后，尝试重启 redis 进程，尝试直接基于 AOF 日志文件进行数据恢复，如果 AOF 文件破损，那么用 redis-check-aof fix 命令修复 如果没有 AOF 文件，会去加载 RDB 文件 如果 redis 当前最新的 AOF 和 RDB 文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的 RDB 数据副本进行数据恢复 RDB优缺点优点 RDB 快照是一个压缩过的非常紧凑的文件，保存着某个时间点的数据集，适合做数据的备份，灾难恢复 可以最大化 Redis 的性能，在保存 RDB 文件，服务器进程只需 fork 一个子进程来完成 RDB 文件的创建，父进程不需要做 IO 操作 与 AOF 相比，恢复大数据集的时候会更快 缺点 RDB 的数据安全性是不如 AOF 的，保存整个数据集的过程是比繁重的，根据配置可能要几分钟才快照一次，如果服务器宕机，那么就可能丢失几分钟的数据 Redis 数据集较大时，fork 的子进程要完成快照会比较耗CPU、耗时 AOF优缺点优点 数据更完整，安全性更高，秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失1秒的数据） AOF 文件是一个只进行追加的日志文件，且写入操作是以 Redis 协议的格式保存的，内容是可读的，适合误删紧急恢复 缺点 对于相同的数据集，AOF 文件的体积要大于 RDB 文件，数据恢复也会比较慢 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。 不过在一般情况下， 每秒 fsync 的性能依然非常高 RDB和AOF选择 如果是数据不那么敏感，且可以从其他地方重新生成补回的，那么可以关闭持久化 如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用 RDB 如果是用做内存数据库，要使用 Redis 的持久化，建议是 RDB 和 AOF 都开启，或者定期执行 bgsave 做快照备份，RDB 方式更适合做数据的备份，AOF 可以保证数据的不丢失 总结RDB 是将某一时刻的数据持久化到磁盘中，是一种快照的方式。redis 在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，即使 redis 处于运行状态。 生成 RDB 文件有两种方式，即手动触发与自动触发。 AOF 方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍。同样数据集的情况下，AOF 文件要比RDB文件的体积大。而且，AOF 方式的恢复速度也要慢于 RDB 方式。 如果在追加日志时，恰好遇到磁盘空间满、inode 满或断电等情况导致日志写入不完整，redis 提供了 redis-check-aof 工 具，可以用来进行日志修复。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96rdb%E4%B8%8Eaof/"},{"title":"Redis跳跃表","text":"原文: https://haicoder.net/note/redis-interview/redis-interview-redis-skiplist.html 什么是跳跃表Redis 中的跳跃表是一种有序的数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。 为什么使用跳跃表首先，因为 zset 要支持随机的插入和删除，所以它不宜使用数组来实现，关于排序问题，我们也很容易就想到红黑树或者平衡树这样的树形结构，为什么 Redis 不使用这样一些结构呢？ 性能考虑： 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树的操作，相对来说跳跃表的变化只涉及局部； 实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观； 基于以上的一些考虑，Redis 基于 William Pugh 的论文做出一些改进后采用了跳跃表这样的结构。 跳跃表与红黑树skip List 是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为 O(logN)（大多数情况下），因为其性能匹敌红黑树且实现较为简单，因此在很多著名项目都用跳表来代替红黑树，例如 LevelDB、Reddis 的底层存储结构就是用的 SkipList。 目前常用的 key-value 数据结构有三种：Hash 表、红黑树、SkipList，它们各自有着不同的优缺点： Hash 表：插入、查找最快，为 O(1)；如使用链表实现则可实现无锁；数据有序化需要显式的排序操作。 红黑树：插入、查找为 O(logn)，但常数项较小；无锁实现的复杂性很高，一般需要加锁；数据天然有序。 SkipList：插入、查找为 O(logn)，但常数项比红黑树要大；底层结构为链表，可无锁实现；数据天然有序。 SkipList特点一个跳表，应该具有以下特征： 一个跳表应该有几个层（level）组成，通常是 10-20 层，leveldb 中默认为 12 层。 跳表的第 0 层包含所有的元素，且节点值是有序的。 每一层都是一个有序的链表，层数越高应越稀疏，这样在高层次中能 ‘跳过’ 许多的不符合条件的数据。 如果元素 x 出现在第 i 层，则所有比 i 小的层都包含 x。 每个节点包含 key 及其对应的 value 和一个指向该节点第 n 层的下个节点的指针数组 x-&gt;next[level] 表示第 level 层的 x 的下一个节点。 跳跃表实现详解我们先来看一个普通的链表结构： 我们需要这个链表按照 score 值进行排序，这也就意味着，当我们需要添加新的元素时，我们需要定位到插入点，这样才可以继续保证链表是有序的，通常我们会使用二分查找法，但二分查找是有序数组的，链表没办法进行位置定位，我们除了遍历整个找到第一个比给定数据大的节点为止 （时间复杂度 O(n)) 似乎没有更好的办法。 但假如我们每相邻两个节点之间就增加一个指针，让指针指向下一个节点，如下图： 这样所有新增的指针连成了一个新的链表，但它包含的数据却只有原来的一半。 现在假设我们想要查找数据时，可以根据这条新的链表查找，如果碰到比待查找数据大的节点时，再回到原来的链表中进行查找，比如，我们想要查找 7，查找的路径则是沿着下图中标注出的红色指针所指向的方向进行的： 这是一个略微极端的例子，但我们仍然可以看到，通过新增加的指针查找，我们不再需要与链表上的每一个节点逐一进行比较，这样改进之后需要比较的节点数大概只有原来的一半。 利用同样的方式，我们可以在新产生的链表上，继续为每两个相邻的节点增加一个指针，从而产生第三层链表： 在这个新的三层链表结构中，我们试着查找 13，那么沿着最上层链表首先比较的是 11，发现 11 比 13 小，于是我们就知道只需要到 11 后面继续查找，从而一下子跳过了 11 前面的所有节点。 可以想象，当链表足够长，这样的多层链表结构可以帮助我们跳过很多下层节点，从而加快查找的效率。 更进一步的跳跃表跳跃表 skiplist 就是受到这种多层链表结构的启发而设计出来的。按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到 *O(logn)*。 但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的 2:1 的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点 （也包括新插入的节点） 重新进行调整，这会让时间复杂度重新蜕化成 *O(n)*。删除数据也有同样的问题。 skiplist 为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是 3，那么就把它链入到第 1 层到第 3 层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个 skiplist 的过程： 从上面的创建和插入的过程中可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点并不会影响到其他节点的层数，因此，插入操作只需要修改节点前后的指针，而不需要对多个节点都进行调整，这就降低了插入操作的复杂度。 现在我们假设从我们刚才创建的这个结构中查找 23 这个不存在的数，那么查找路径会如下图： Redis跳跃表的实现结构定义Redis 中的跳跃表由 server.h/zskiplistNode 和 server.h/zskiplist 两个结构定义，前者为跳跃表节点，后者则保存了跳跃节点的相关信息，同之前的 集合 list 结构类似，其实只有 zskiplistNode 就可以实现了，但是引入后者是为了更加方便的操作： 123456789101112131415161718192021222324/* ZSETs use a specialized version of Skiplists */typedef struct zskiplistNode { // value sds ele; // 分值 double score; // 后退指针 struct zskiplistNode *backward; // 层 struct zskiplistLevel { // 前进指针 struct zskiplistNode *forward; // 跨度 unsigned long span; } level[];} zskiplistNode;typedef struct zskiplist { // 跳跃表头指针 struct zskiplistNode *header, *tail; // 表中节点的数量 unsigned long length; // 表中层数最大的节点的层数 int level;} zskiplist; 正如文章开头画出来的那张标准的跳跃表那样。 随机层数对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数，源码在 t_zset.c/zslRandomLevel(void) 中被定义： 123456int zslRandomLevel(void) { int level = 1; while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF)) level += 1; return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;} 直观上期望的目标是 50% 的概率被分配到 Level 1，25% 的概率被分配到 Level 2，12.5% 的概率被分配到 Level 3，以此类推…有 2-63 的概率被分配到最顶层，因为这里每一层的晋升率都是 50%。 Redis 跳跃表默认允许最大的层数是 32，被源码中 ZSKIPLIST_MAXLEVEL 定义，当 Level[0] 有 264 个元素时，才能达到 32 层，所以定义 32 完全够用了。 创建跳跃表这个过程比较简单，在源码中的 t_zset.c/zslCreate 中被定义： 123456789101112131415161718192021222324zskiplist *zslCreate(void) { int j; zskiplist *zsl; // 申请内存空间 zsl = zmalloc(sizeof(*zsl)); // 初始化层数为 1 zsl-&gt;level = 1; // 初始化长度为 0 zsl-&gt;length = 0; // 创建一个层数为 32，分数为 0，没有 value 值的跳跃表头节点 zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); // 跳跃表头节点初始化 for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) { // 将跳跃表头节点的所有前进指针 forward 设置为 NULL zsl-&gt;header-&gt;level[j].forward = NULL; // 将跳跃表头节点的所有跨度 span 设置为 0 zsl-&gt;header-&gt;level[j].span = 0; } // 跳跃表头节点的后退指针 backward 置为 NULL zsl-&gt;header-&gt;backward = NULL; // 表头指向跳跃表尾节点的指针置为 NULL zsl-&gt;tail = NULL; return zsl;} 插入节点实现这几乎是最重要的一段代码了，但总体思路也比较清晰简单，如果理解了上面所说的跳跃表的原理，那么很容易理清楚插入节点时发生的几个动作 （几乎跟链表类似）： 找到当前我需要插入的位置 （其中包括相同 score 时的处理）； 创建新节点，调整前后的指针指向，完成插入； 为了方便阅读，我把源码 t_zset.c/zslInsert 定义的插入函数拆成了几个部分 第一部分：声明需要存储的变量 12345// 存储搜索路径zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;// 存储经过的节点跨度unsigned int rank[ZSKIPLIST_MAXLEVEL];int i, level; 第二部分：搜索当前节点插入位置 123456789101112131415161718serverAssert(!isnan(score));x = zsl-&gt;header;// 逐步降级寻找目标节点，得到 &quot;搜索路径&quot;for (i = zsl-&gt;level-1; i &gt;= 0; i--) { /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; // 如果 score 相等，还需要比较 value 值 while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) { rank[i] += x-&gt;level[i].span; x = x-&gt;level[i].forward; } // 记录 &quot;搜索路径&quot; update[i] = x;} 有一种极端的情况，就是跳跃表中的所有 score 值都是一样，zset 的查找性能会不会退化为 O(n) 呢？从上面的源码中我们可以发现 zset 的排序元素不只是看 score 值，也会比较 value 值 （字符串比较）。 第三部分：生成插入节点 12345678910111213141516/* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */level = zslRandomLevel();// 如果随机生成的 level 超过了当前最大 level 需要更新跳跃表的信息if (level &gt; zsl-&gt;level) { for (i = zsl-&gt;level; i &lt; level; i++) { rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; } zsl-&gt;level = level;}// 创建新节点x = zslCreateNode(level,score,ele); 第四部分：重排前向指针 1234567891011for (i = 0; i &lt; level; i++) { x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;}/* increment span for untouched levels */for (i = level; i &lt; zsl-&gt;level; i++) { update[i]-&gt;level[i].span++;} 第五部分：重排后向指针并返回 1234567x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0];if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x;else zsl-&gt;tail = x;zsl-&gt;length++;return x; 节点删除实现删除过程由源码中的 t_zset.c/zslDeleteNode 定义，和插入过程类似，都需要先把这个 “搜索路径” 找出来，然后对于每个层的相关节点重排一下前向后向指针，同时还要注意更新一下最高层数 maxLevel，直接放源码 (如果理解了插入这里还是很容易理解的)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) { int i; for (i = 0; i &lt; zsl-&gt;level; i++) { if (update[i]-&gt;level[i].forward == x) { update[i]-&gt;level[i].span += x-&gt;level[i].span - 1; update[i]-&gt;level[i].forward = x-&gt;level[i].forward; } else { update[i]-&gt;level[i].span -= 1; } } if (x-&gt;level[0].forward) { x-&gt;level[0].forward-&gt;backward = x-&gt;backward; } else { zsl-&gt;tail = x-&gt;backward; } while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL) zsl-&gt;level--; zsl-&gt;length--;}/* Delete an element with matching score/element from the skiplist. * The function returns 1 if the node was found and deleted, otherwise * 0 is returned. * * If 'node' is NULL the deleted node is freed by zslFreeNode(), otherwise * it is not freed (but just unlinked) and *node is set to the node pointer, * so that it is possible for the caller to reuse the node (including the * referenced SDS string at node-&gt;ele). */int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node) { zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) { while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) { x = x-&gt;level[i].forward; } update[i] = x; } /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. */ x = x-&gt;level[0].forward; if (x &amp;&amp; score == x-&gt;score &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) { zslDeleteNode(zsl, x, update); if (!node) zslFreeNode(x); else *node = x; return 1; } return 0; /* not found */} 节点更新实现当我们调用 ZADD 方法时，如果对应的 value 不存在，那就是插入过程，如果这个 value 已经存在，只是调整一下 score 的值，那就需要走一个更新流程。 假设这个新的 score 值并不会带来排序上的变化，那么就不需要调整位置，直接修改元素的 score 值就可以了，但是如果排序位置改变了，那就需要调整位置，该如何调整呢？ 从源码 t_zset.c/zsetAdd 函数 1350 行左右可以看到，Redis 采用了一个非常简单的策略： 123456/* Remove and re-insert when score changed. */if (score != curscore) { zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr); zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score); *flags |= ZADD_UPDATED;} 把这个元素删除再插入这个，需要经过两次路径搜索，从这一点上来看，Redis 的 ZADD 代码似乎还有进一步优化的空间。 元素排名的实现跳跃表本身是有序的，Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 span 属性，用来 表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点中间会跳过多少个节点。在上面的源码中我们也可以看到 Redis 在插入、删除操作时都会小心翼翼地更新 span 值的大小。 所以，沿着 “搜索路径”，把所有经过节点的跨度 span 值进行累加就可以算出当前元素的最终 rank 值了： 12345678910111213141516171819202122232425/* Find the rank for an element by both score and key. * Returns 0 when the element cannot be found, rank otherwise. * Note that the rank is 1-based due to the span of zsl-&gt;header to the * first element. */unsigned long zslGetRank(zskiplist *zsl, double score, sds ele) { zskiplistNode *x; unsigned long rank = 0; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) { while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt;= 0))) { // span 累加 rank += x-&gt;level[i].span; x = x-&gt;level[i].forward; } /* x might be equal to zsl-&gt;header, so test if obj is non-NULL */ if (x-&gt;ele &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) { return rank; } } return 0;} Redis跳跃表常用操作的时间复杂度| 操作 | 时间复杂度 | | ———————————————————— | —————————————- | | 创建一个跳跃表 | O(1) | | 释放给定跳跃表以及其中包含的节点 | O(N) | | 添加给定成员和分值的新节点 | 平均O(logN),最坏O(logN)(N为跳跃表的长度) | | 删除除跳跃表中包含给定成员和分值的节点 | 平均O(logN),最坏O(logN)(N为跳跃表的长度) | | 返回给定成员和分值的节点再表中的排位 | 平均O(logN),最坏O(logN)(N为跳跃表的长度) | | 返回在给定排位上的节点 | 平均O(logN),最坏O(logN)(N为跳跃表的长度) | | 给定一个分值范围,返回跳跃表中第一个符合这个范围的节点 | O(1) | | 给定一个分值范围,返回跳跃表中最后一个符合这个范围的节点 | 平均O(logN),最坏O(logN)(N为跳跃表的长度) | | 给定一个分值范围,除跳跃表中所有在这个范围之内的节点 | 平均O(logN),最坏O(logN)(N为跳跃表的长度) | | 给定一个排位范围,鼎除跳跃表中所有在这个范围之内的节点 | O(N),N为被除节点数量 | | 给定一个分值范固(range),比如0到15,20到28,诸如此类,如果跳氏表中有至少一个节点的分值在这个范間之内,那么返回1,否则返回0 | O(N),N为被除节点数量 | 总结 跳跃表基于单链表加索引的方式实现。 跳跃表以空间换时间的方式提升了查找速度。 Redis 有序集合在节点元素较大或者元素数量较多时使用跳跃表实现。 Redis 的跳跃表实现由 zskiplist 和 zskiplistnode 两个结构组成，其中 zskiplist 用于保存跳跃表信息(比如表头节点、表尾节点、长度)，而 zskiplistnode 则用于表示跳跃表节点。 Redis 每个跳跃表节点的层高都是 1 至 32 之间的随机数。 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的成员对象必须是唯一的跳跃表中的节点按照分值大小进行排序，当分值相同时，节点按照成员对象的大小进行排序。","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/redis%E8%B7%B3%E8%B7%83%E8%A1%A8/"},{"title":"Hexo 搭建个人博客网站","text":"最近想好好整一整个人博客，搜索一番，比较火的有三种方式：Jekyll、Hugo、Hexo 最终选择 Hexo ，官网及参考主题链接如下 【hexo 官方网站】 【icarus 主题】 【next 主题】 搭建步骤【安装】123456789101112131415161718192021222324252627282930# 安装 hexonpm install hexo-cli -g# 新建项目hexo init blogcd blogecho &gt;&gt; .gitignoreecho .vscode &gt;&gt; .gitignoreecho .idea &gt;&gt; .gitignore# 初始化 git 仓库git init# 将 icarus 工程 设置为子模块git submodule add https://github.com/ppoffice/hexo-theme-icarus.git themes/icarushexo config theme icarusyarn installhexo clean# 根据提示安装缺失依赖 !!!# 根据提示安装缺失依赖 !!!# 根据提示安装缺失依赖 !!!# yarn add bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3 hexo-component-inferno@^0.10.5 inferno@^7.3.3 inferno-create-element@^7.3.3hexo servergit add .git commit -m &quot;commit&quot; 【 配置】参考【icarus主题配置】 配置 _config.yml 、 _config.icarus.yml 、 _config.post.yml _config.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103# Hexo Configuration## Docs: http://hexo.io/docs/configuration.html## Source: https://github.com/hexojs/hexo/# Sitetitle: Learn &amp; Recordsubtitle: description: 王东杰的个人博客keywords: blog,wangdongjie,wdjauthor: 王东杰language: zh-CNtimezone: Asia/Shanghai# URL## If your site is put in a subdirectory, set url as 'http://yoursite.com/child' and root as '/child/'url: https://wangdj2020.github.io/root: /permalink: :category/:post_title/permalink_defaults:# Directorysource_dir: sourcepublic_dir: docstag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render:# Writingnew_post_name: :title.md # File name of new postsdefault_layout: posttitlecase: false # Transform title into titlecaseexternal_link: # Open external links in new tab enable: true field: postfilename_case: 0render_drafts: falsepost_asset_folder: falserelative_link: falsefuture: truehighlight: enable: true line_number: true tab_replace:# Category &amp; Tagdefault_category: uncategorizedcategory_map:tag_map:# Date / Time format## Hexo uses Moment.js to parse and display date## You can customize the date format as defined in## http://momentjs.com/docs/#/displaying/format/date_format: YYYY-MM-DDtime_format: HH:mm:ssupdated_option: 'empty'# Pagination## Set per_page to 0 to disable paginationper_page: 10pagination_dir: pageindex_generator: per_page: 10archive_generator: per_page: 20 yearly: true monthly: truecategory_generator: per_page: 10tag_generator: per_page: 10# Extensions## Plugins: https://github.com/hexojs/hexo/wiki/Plugins## Themes: https://github.com/hexojs/hexo/wiki/Themestheme: icarus# Deployment## Docs: http://hexo.io/docs/deployment.html# deploy:# type: git# repository: https://github.com/ppoffice/hexo-theme-icarus.git# branch: gh-pagesmarked: gfm: falsegithubEmojis: className: not-gallery-item# 有空再搞这个搜索# algolia:# applicationID: T0CJF4ZB1O# apiKey: bcbeb94d417749ab5c65b082fce32333# indexName: hexo-icarus _config.icarus.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326# Version of the configuration fileversion: 4.0.0# Icarus theme variant, can be &quot;default&quot; or &quot;cyberpunk&quot;variant: default# Path or URL to the website's logo# logo: /img/logo.svglogo: text: Learn &amp; Record# Page metadata configurationshead: # URL or path to the website's icon favicon: /img/favicon.svg # Open Graph metadata # https://hexo.io/docs/helpers.html#open-graph open_graph: # Page title (og:title) (optional) # You should leave this blank for most of the time title: # Page type (og:type) (optional) # You should leave this blank for most of the time type: blog # Page URL (og:url) (optional) # You should leave this blank for most of the time url: # Page cover (og:image) (optional) Default to the Open Graph image or thumbnail of the page # You should leave this blank for most of the time image: # Site name (og:site_name) (optional) # You should leave this blank for most of the time site_name: # Page author (article:author) (optional) # You should leave this blank for most of the time author: # Page description (og:description) (optional) # You should leave this blank for most of the time description: # Twitter card type (twitter:card) twitter_card: # Twitter ID (twitter:creator) twitter_id: # Twitter ID (twitter:creator) twitter_site: # Google+ profile link (deprecated) google_plus: # Facebook admin ID fb_admins: # Facebook App ID fb_app_id: # Structured data of the page # https://developers.google.com/search/docs/guides/intro-structured-data structured_data: # Page title (optional) # You should leave this blank for most of the time title: # Page description (optional) # You should leave this blank for most of the time description: # Page URL (optional) # You should leave this blank for most of the time url: # Page author (article:author) (optional) # You should leave this blank for most of the time author: # Page images (optional) Default to the Open Graph image or thumbnail of the page # You should leave this blank for most of the time image: # Additional HTML meta tags in an array meta: # Meta tag specified in &lt;attribute&gt;=&lt;value&gt; style # E.g., name=theme-color;content=#123456 =&gt; &lt;meta name=&quot;theme-color&quot; content=&quot;#123456&quot;&gt; # URL or path to the website's RSS atom.xml rss: # Page top navigation bar configurationsnavbar: # Naviagtion menu items menu: 首页: / 归档: /archives 分类: /categories 标签: /tags 关于: /about # # Links to be shown on the right of the navigation bar # links: # Download on GitHub: # icon: fab fa-github # url: 'https://github.com/ppoffice/hexo-theme-icarus'# # Page footer configurations# footer:# # Links to be shown on the right of the footer section# links:# Creative Commons:# icon: fab fa-creative-commons# url: 'https://creativecommons.org/'# Attribution 4.0 International:# icon: fab fa-creative-commons-by# url: 'https://creativecommons.org/licenses/by/4.0/'# Download on GitHub:# icon: fab fa-github# url: 'https://github.com/ppoffice/hexo-theme-icarus'# Article related configurationsarticle: # Code highlight settings highlight: # Code highlight themes # https://github.com/highlightjs/highlight.js/tree/master/src/styles theme: atom-one-light # Show copy code button clipboard: true # Default folding status of the code blocks. Can be &quot;&quot;, &quot;folded&quot;, &quot;unfolded&quot; fold: unfolded # Whether to show estimated article reading time readtime: true # Article licensing block # licenses: # Creative Commons: # icon: fab fa-creative-commons # url: 'https://creativecommons.org/' # Attribution: # icon: fab fa-creative-commons-by # url: 'https://creativecommons.org/licenses/by/4.0/' # Noncommercial: # icon: fab fa-creative-commons-nc # url: 'https://creativecommons.org/licenses/by-nc/4.0/'# Search plugin configurations# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Search/search: type: insight# Comment plugin configurations# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Comment/# comment:# Donate plugin configurations# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Donation/# donates:# # Alipay donate button configurations# -# type: alipay# # Alipay qrcode image URL# qrcode: ''# # &quot;Buy me a coffee&quot; donate button configurations# -# type: buymeacoffee# # URL to the &quot;Buy me a coffee&quot; page# url: ''# # Patreon donate button configurations# -# type: patreon# # URL to the Patreon page# url: ''# # Paypal donate button configurations# -# type: paypal# # Paypal business ID or email address# business: ''# # Currency code# currency_code: USD# # Wechat donate button configurations# -# type: wechat# # Wechat qrcode image URL# qrcode: ''# # Share plugin configurations# # https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Share/# share:# type: sharethis# # URL to the ShareThis share plugin script# install_url: //platform-api.sharethis.com/js/sharethis.js#property=5ab6f60ace89f00013641890&amp;product=inline-share-buttons# Sidebar configurations.# Please be noted that a sidebar is only visible when it has at least one widgetsidebar: # Left sidebar configurations left: # Whether the sidebar sticks to the top when page scrolls sticky: true # Right sidebar configurations right: # Whether the sidebar sticks to the top when page scrolls sticky: false# Sidebar widget configurations# http://ppoffice.github.io/hexo-theme-icarus/categories/Widgets/widgets: # Profile widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: profile # Author name author: 王东杰 # Author title author_title: Stay hungry, Stay foolish # Author's current location location: 中国 北京 # URL or path to the avatar image avatar: https://wdj-1252419878.cos.ap-beijing.myqcloud.com/blog/2021-04-12-011456.jpg # Whether show the rounded avatar image avatar_rounded: true # Email address for the Gravatar gravatar: # URL or path for the follow button follow_link: 'https://github.com/wangdj2020/' # Links to be shown on the bottom of the profile widget social_links: Github: icon: fab fa-github url: 'https://github.com/wangdj2020/' # Facebook: # icon: fab fa-facebook # url: 'https://facebook.com' # Twitter: # icon: fab fa-twitter # url: 'https://twitter.com' # Dribbble: # icon: fab fa-dribbble # url: 'https://dribbble.com' # RSS: # icon: fas fa-rss # url: / # Table of contents widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: toc # Recommendation links widget configurations # - # # Where should the widget be placed, left sidebar or right sidebar # position: left # type: links # # Names and URLs of the sites # links: # Hexo: 'https://hexo.io' # Bulma: 'https://bulma.io' # Categories widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: categories # Recent posts widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: recent_posts # Archives widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: archives # Tags widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: tags # Google FeedBurner email subscription widget configurations # - # # Where should the widget be placed, left sidebar or right sidebar # position: left # type: subscribe_email # # Hint text under the email input # description: # # Feedburner ID # feedburner_id: '' # Google AdSense unit configurations # - # # Where should the widget be placed, left sidebar or right sidebar # position: left # type: adsense # # AdSense client ID # client_id: '' # # AdSense AD unit ID # slot_id: ''# Plugin configurations# https://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/plugins: # Enable page startup animations animejs: true # Show the &quot;back to top&quot; button back_to_top: true # Baidu Analytics plugin settings # https://tongji.baidu.com baidu_analytics: # Baidu Analytics tracking ID tracking_id: # BuSuanZi site/page view counter # https://busuanzi.ibruce.info busuanzi: false # CNZZ statistics # https://www.umeng.com/web cnzz: # CNZZ tracker id id: # CNZZ website id web_id: # Enable the lightGallery and Justified Gallery plugins # https://ppoffice.github.io/hexo-theme-icarus/Plugins/General/gallery-plugin/ gallery: true # Google Analytics plugin settings # https://analytics.google.com # google_analytics: # # Google Analytics tracking ID # tracking_id: UA-72437521-5 # Hotjar user feedback plugin # https://www.hotjar.com/ hotjar: # Hotjar site id site_id: # Enable the KaTeX math typesetting supprot # https://katex.org/ katex: false # Enable the MathJax math typesetting support # https://www.mathjax.org/ mathjax: false # Enable the Outdated Browser plugin # http://outdatedbrowser.com/ outdated_browser: true # Show a progress bar at top of the page on page loading progressbar: true# CDN provider settings# https://ppoffice.github.io/hexo-theme-icarus/Configuration/Theme/speed-up-your-site-with-custom-cdn/providers: # Name or URL template of the JavaScript and/or stylesheet CDN provider cdn: jsdelivr # Name or URL template of the webfont CDN provider fontcdn: google # Name or URL of the fontawesome icon font CDN provider iconcdn: loli _config.post.yml_config.post.yml 文件中的配置是对 博客页面的细分配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100sidebar: # Left sidebar configurations left: # Whether the sidebar sticks to the top when page scrolls sticky: true # Right sidebar configurations right: # Whether the sidebar sticks to the top when page scrolls sticky: false# Sidebar widget configurations# http://ppoffice.github.io/hexo-theme-icarus/categories/Widgets/widgets: # Profile widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: profile # Author name author: 王东杰 # Author title author_title: Stay hungry, Stay foolish # Author's current location location: 中国 北京 # URL or path to the avatar image avatar: https://wdj-1252419878.cos.ap-beijing.myqcloud.com/blog/2021-04-12-011456.jpg # Whether show the rounded avatar image avatar_rounded: true # Email address for the Gravatar gravatar: # URL or path for the follow button follow_link: 'https://github.com/wangdj2020/' # Links to be shown on the bottom of the profile widget social_links: Github: icon: fab fa-github url: 'https://github.com/wangdj2020/' # Facebook: # icon: fab fa-facebook # url: 'https://facebook.com' # Twitter: # icon: fab fa-twitter # url: 'https://twitter.com' # Dribbble: # icon: fab fa-dribbble # url: 'https://dribbble.com' # RSS: # icon: fas fa-rss # url: / # Table of contents widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: toc # Recommendation links widget configurations # - # # Where should the widget be placed, left sidebar or right sidebar # position: left # type: links # # Names and URLs of the sites # links: # Hexo: 'https://hexo.io' # Bulma: 'https://bulma.io' # Categories widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: left type: categories # Recent posts widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: recent_posts # Archives widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: archives # Tags widget configurations - # Where should the widget be placed, left sidebar or right sidebar position: right type: tags # Google FeedBurner email subscription widget configurations # - # # Where should the widget be placed, left sidebar or right sidebar # position: left # type: subscribe_email # # Hint text under the email input # description: # # Feedburner ID # feedburner_id: '' # Google AdSense unit configurations # - # # Where should the widget be placed, left sidebar or right sidebar # position: left # type: adsense # # AdSense client ID # client_id: '' # # AdSense AD unit ID # slot_id: '' 【部署】部署使用 【Github Pages】 策略是，将 master 分支的 /docs 文件夹作为博客根目录。 这样只需要将生成的静态文件输出到 /docs 文件夹，再提交代码就能达到更新的效果。 上面的 _config.yml 配置文件中已经将输出目录变更为 /docs 整个目录结构大致如下： 12345678910111213141516171819202122$ tree.├── README.md├── _config.icarus.yml├── _config.post.yml├── _config.yml├── db.json├── package.json├── push.sh├── node_modules/···├── scaffolds│ ├── draft.md│ ├── page.md│ └── post.md├── scripts│ └── tab.js└── source ├── _posts │ ├── helloworld.md ├── about │ └── index.md └── gallery 最后写一个发布脚本，即 push.sh （加执行权限 chmod +x push.sh） 1234567git pullhexo cleanhexo generategit restore docs/_config.ymlgit add .git commit -m &quot;commit&quot;git push 写作相关说明新建文章（ 默认使用 post.md 模板）1hexo new &quot;hello world&quot; 文章头部123456789101112---title: Hexo 搭建个人博客网站date: 2020-08-30 11:10:21toc: truecover:thumbnail: https://wdj-1252419878.cos.ap-beijing.myqcloud.com/blog/2020-08-30-040528.png!1000pxtags: - hexocategories:- 生命在于学习- Blog--- title：文章标题 date：发布时间 toc：是否显示目录 cover：封面图 thumbnail：缩略图 tags：标签 categories：类别 阅读更多在文章中添加 1&lt;!-- more --&gt;","link":"/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/hexo-%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%BD%91%E7%AB%99/"},{"title":"《人生效率手册》","text":"知易行难，一个人如果能够数十年如一日地践行一种良好的学习和生活习惯，必然是因为在内心深处有着一个十分坚定的人生目标和具体的实施计划。 现实情况是，大部分人都很迷茫，根本不知道自己一生究竟想要成为什么样的人，要做出怎样的事业、构建怎样的人生。好像一切都得按照“本应该的样子”而活，墨守成规，不求突破，到了一定的年龄就要按部就班工作、买房、结婚、生子、养老，最后死亡。有人将这千篇一律的人生轨迹叫作自然规律。可是自然规律并不等于人云亦云，更不是要求我们只能按所谓的“规律”、毫无生气地去生活。 自然规律只是人们从物质固有的、本质的、稳定的联系中总结出来的规律，并不代表人人都要如此，人人都需要遵守自然规律生活下去。有些所谓的“规律”是可以打破的，那些弃之不顾的人就变成了大家眼中的“成功人士”，而那些墨守成规的人，自然变成了大多数的平凡人。 我们之所以最后成为了大多数的平凡人，没有创造理想中的一番天地，就是因为我们并没有领悟人生的奥秘，未能及早觉醒，并在想明白之后发愤图强。通常来说，绝大多数的人会在四五十岁开始悔恨，悔恨自己在年轻时没有想清楚，或者在想明白后没有立即付诸行动。甚至还有一些人，一生都处于糊涂懵懂的状态，他们也就谈不上想没想明白，想没想清楚，更谈不上努力奋斗了。 只有把自己的人生目标先明确出来，精准定位自己的目标和未来走向，才能从茫然的人生状态中解脱出来，才能真正通过切切实实的行动去实现自我价值。就像行驶在马路上的汽车，只有明确自己要走的方向，才是有效的；就像在茫茫大海中航行的轮船，只有在导航和灯塔的帮助下才不会迷失方向，所以在努力之前，你最应该明确自己的目标，不然一切都是无用功。 通过多年的观察分析，我将职场青年大致分为以下五类，我们现在就来定义一下自己到底是哪一类。 第一类朋友——完全没有人生目标，每一天都活得浑浑噩噩，每一天都如行尸走肉一般，完全都不知道自己的人生为了什么，仿佛在这个世界上有他们也行没他们也罢。 第二类朋友——时常找不到目标，别人说什么仿佛都是对的，别人告诉他们应该做什么他们就去做，完全没有自己的想法，更加不知道什么是自己的想法。 第三类朋友——有的时候仿佛能找到目标，这个目标时有时无，就像风筝一样缥缈不定，没有清晰的人生目标，没有明确的奋斗方向。 第四类朋友——也是最常见的一类，他们其实有着明确的人生目标，但就是没有清晰的人生道路规划，差在规划上。 第五类朋友——很少见，但是却非常有代表性，他们一般都拥有明确的人生目标，同时又有着清晰的道路规划，每一步的选择都是围绕目标来进行的，而且能通过踏踏实实的努力来构建。 每个人到年底都会参加各种各样的聚会，有目标的人是不会轻易参加这些聚会的，他们的目的是构建自己的朋友圈，而不是被构建，他们有清晰的人际交往选择。但是没有人生目标的人，一般随叫随到，别人一叫他们去参加聚会，他们就去了，而且他们也不清楚自己为什么参加，感觉就是好玩，或者有空就去了，是完全没有目的性的参与，这就是一种区别。 还有一个很特别的方法，就是去看他们对时间的吝惜程度。有目标的人，往往对时间使用得特别仔细，好像他们做什么事情都是为了争分夺秒地实现自己的梦想，在他们的世界中，拒绝别人不会是一件很困难的事情，他们清楚地知道自己要什么，自己努力是为了什么。没有目标的人仿佛到处都能找到机会，这个聚会去参加，那个聚会也去参加，一会去学习这个技能，一会去学习那个技能，人生处处是目标，目标随时都在变化，没有清晰而坚定的目标。别人喜欢的他们就喜欢，别人倡导的他们就去跟随。 对待学习的态度，有目标的人和没有目标的人也是不一样的。有目标的人一般会有在知识和技能领域获取和提升的诉求，求知若渴，他们能够清晰地划分出什么是精学，什么是泛学，对知识如饥似渴，不知疲倦地去汲取知识的力量。没有目标的人，压根就不会主动去学，就算是学，也是走马观花，他们往往学的是一种快感，在快感消失后，他们对所学到的东西也就渐渐地毫无印象了。 有目标的人，他们生而具有使命感，好像可以预知未来，对人生每一步都能稳健规划，并按照计划实现梦想，人生充满节奏感。但没有目标的人，对未来茫然无知，常把好运气当成能力。 10000 小时定律 在决定要不要做一件事情时，一定要和我们的目标进行密切的结合，如果你没有想清楚一个目标，那么建议你不要做，你甚至可以用那些时间去睡觉。你做的每一件事，都需要树立一个基本的目标，这样在做完这件事，达到自己预期的目标后，你就会特别有成就感，也更愿意投入下一件事、下一个目标中，达到一个良性的循环。 需要注意的是，晚上不适合做10000小时的基础学习，因为这类学习属于精学体系，它需要安静，同时它需要一个绝对的真空环境，以保证自己能够完成一个又一个专注力的训练，所以嘈杂的夜晚不适合做这件事情。你的晚间基本上是用来进行泛学训练和健康锻炼的，尤其是被动式的学习特别合适，收听或收看学习栏目是不错的选择。 7 个人物法。适合大多数人，探究未来的方向不合适。实操性很强。 事实上，大部分人在做一个决定之前，一定是经过了深思熟虑，然后才下定的决心，最后付诸行动。 在我设计的效率手册中，每年要对自我评估，每一个进行评估的人都会被要求计算每日、每周、每月、每年的学习时间，占额外8小时，也就是2920小时（8小时乘以365天）的百分之几。我曾经做过调查，GYL（全球青年领导力）导师的学习时间平均为额外8小时的37.5%，也就是说，他们每天至少花3个小时在业余学习上。很多人看到这里都会诧异，他们都已经那么牛了，为什么还要花那么多的时间去学习？ CEO高鸿鹏老师，都曾分享过他们的读书经历和学习方法，实质是讲你把时间花在什么上面，你就会收获什么。时间的魅力在于，在你不知不觉中给你惊喜，让你变成一个意想不到的自己，一个更好的自己。 你需要把计划、实施、总结、评估以及再次计划做成一个大的循环体系，这才是时间管理。 每年我都会制定一些评价标准，比如我有每年出一本书的习惯，这就是我时间管理能力的重要指标。我是一位创业者，目前是创业的第四年。这期间，我要带领着两个团队同步发展，每年至少进行100场演讲、阅读100本书、训练一项硬本领。那么，我时间管理的重要指标，就是我能否还能拿出时间来出版一本书。如果能够拿出来，一定是在顺利完成其他指标后才可以。这样，我就可以检验出自己的时间管理能力。如果我一年能出版一本书的话，那么我的时间管理能力就基本符合了我对自己的要求。大家也可以用其他方法自测，比如做一次减脂塑身的活动，或者完成一项技能训练，说好一口流利的英文等，这都是可以检验时间管理能力的标准，大家要形成自己的风格来进行时间管理，而不是人云亦云。 问问自己哪些事情是可以坚持10000小时的？很多人觉得除了将吃饭、睡觉、玩手机坚持了10000小时以上，他们的人生还没有什么事情是可以坚持10000小时的。在这里我想让大家知道的是，每一个成功人士的背后，都是坚持。只不过有些人在很年轻的时候就有了这种坚持、训练的意识，也就是俗称的开窍早，但有些人开窍非常晚，所以没有坚持的意识，也没有坚持做下去的习惯。 在人生电池图理论下，我们每个人都要把自己当成一块不能再次蓄电的电池，时间就是这块电池的电量，浪费了就没有了。生命也是这块电池，过完了，过去的日子就一去不复返了。每个人一定要不断地反复问自己：我生命的有效周期到底还有多长时间。这个思考以及自问自答的反思，最好每周进行一次。不要等到每年年底或者年初的时候，临时抱佛脚，才意识到时间不够用。因为你必须知道，自己还可以拿多少时间，或者说多少小时来实现梦想。尤其是如果梦想远大的话，就需要去拥有实现梦想的时间基础。 可人往往就是这样的物种，他的意识发育成熟速度，往往远远落后于身体。也就是说，你现在空有体力和大把空闲时间，却不知道该怎么用，该朝着什么方向努力。等你慢慢步入30岁、40岁、50岁的时候，你开始懂了，想明白奋斗的重要含义了，可是身体、精力以及家庭状况却不允许你去奋斗了，你往往没有时间修炼你的硬本领了。30岁以后，不论是男生、女生，体力、精力都非常有限，动不动就缺觉，而且每天单位有一堆烦心事，家里面时不时还会出状况。 灵魂如果没有确定的目标，就会丧失自己。 可控时间： 每天早上的早起 下班的晚上 周六日的时间 管理学当中，我们用SMART原则来确定目标，即具体的（specific）、可衡量的（measurable）、可实现的（attainable）、合理的（realistic）、有时间限制的（time-targeted）。从第五项标准（time-targeted）一词就能看出，目标性法则是以时间管理为基础的。 我们要明白，一个人越想做卓越的贡献，就越需要整块的时间。我个人非常反对碎片化时间的管理，我认为碎片时间，不能做整体性工作，我们应该放弃无用的碎片化知识的涉猎。——同意 在时间管理中，从人生目标和自我现状两个维度去区分，可以得出对自己的判断，也就是“自我认知”。从人生目标来说，人生目标是一项远期目标，相对应的时间管理方法叫作远期目标的时间管理法；对近期目标来说，我们可以称之为日程管理或者近期时间管理法则。 目标分解法：我们需要将长期的人生目标和短期的人生目标进行一定程度上的区分。漫长的人生是由一天一天组成的，人在时间中慢慢老去。有的人在年轻的时候就找到了人生的正确打开方式，而一直没有找到的人只能庸庸碌碌地度过一生。 真正的时间管理，是从开始计划，到实施计划、总结复盘，再到评估，以及再次计划的过程。 如果你想掌握时间管理，一个非常重要的方法就是用项目管理的方法，来管理好自己的时间，记住四个要素，计划、实施、总结、评估，才能到再次计划。 这些成功的人，都有一些共同的习惯，那就是早起、健身、阅读以及陪伴家人。 早起做什么，有三个方向可以思考。 发展你自己的事业，也就是我说的硬本领； 要给家庭基本需求以外的呵护，比如你每天都会花费 10 分钟的时间跟孩子深度交流、沟通，来聆听他们的内心，或者陪伴他们做手工或者读书，等等； 第三是从事健身锻炼，投身到兴趣爱好中。 时间管理，越早想明白越好；但想明白还不够，越早做到越好；做到还不够，只有每天坚持才重要。 当你陷入负面情绪无法自拔时，你身边要有充满正能量的朋友，他们在你的身边鼓励你、激励你，让你远离负面情绪，进入积极正面的情绪。或者，你可以去寻找比你年轻、比你还拼搏的异类群体。当你偶尔犯懒的时候，就去关注了解他们的生活，要知道他们为了实现自己的梦想，同样很拼搏。 成为企业的 CEO，不仅需要独特的战略眼光，也要能看懂手中的财务报表，不仅要在决策的关键时刻有足够的勇气和魄力，也要会制作漂亮美观又言之有物的 PPT。 早起仪式： 听到闹铃后立即起床。 香气唤醒，咖啡唤醒。 进入高效能的状态。 写下三个目标。 用总结法为昨日的事情进行复盘。 为今天一整天进行日程的安排。 精学训练 努力进入忘我状态，且最少持续一小时。 出状态，吃早餐，调整积极心情，放松。 强健的体魄和敏锐的大脑，是成功的先决条件。 在学习的过程中，一定要有总结与反馈机制。所谓总结，是吸收，也就是只是输入后，与你之前知识体系中的元素互相融合，形成自我反思。总结一定要靠思维逻辑来一步步梳理与理顺。 高效学习的十个秘诀 目标 为目标设置节奏，找短板，找需要修炼的硬本领 精学体系，需要整块时间来处理。 泛学体系，体现的是一个人综合的知识面。往往需要你在每个领域都略知一二才可以。 预习 实时学习 复习，看记录的学习笔记，对自己的专项能力尽心再次训练。 早起法 屏蔽周围的负面信息 自我激励与分享 有人说，这是人的趋利避害性导致的，当你知道一件事是对你有好处的时候，你就会坚持去做，早起就是这样。 曾国藩最大的能力是通过个人努力，将自己从一个笨人，变成了非常高明且有本领的人，这就是坚持早起的力量。 每天早上 6 点半前起来算早起；6 点半以后，只能说是正常起床了。 很多人觉得自己每天最困的时候就是起床1小时以后，有时甚至他们在早起的社群里打完卡后又重新回到了被窝里。我想说，你要了解你的身体，知道它什么时候会懈怠。什么时候是你意识上的懈怠，这点非常重要，因为它将决定你是否能有效地坚持目标、实现目标。所以，咖啡是一项最有效的唤醒方法，如果你对咖啡过敏，也可以饮用红茶等。 如果你觉得自己是异类（轻度暗示了，你不是异类，只不过好学而已），那么在你的工作和生活圈，你一定要努力去找到那些与你相同的异类才可以。努力在你身边找寻，发现他们与你一样有不凡的气质，和他们一起进步和发展，最好可以达成生活同步。 每年聚会都是以头脑风暴会为目标，除了各自复盘一下过去的一年，彼此点评，同时还能商量出一些今年的合作事宜。 其实很多杰出的人在修炼完围绕自己核心竞争力的硬本领之后，仍然坚持每年学习一门及技能。 把硬本领的相关知识点与其他领域的相关内容，一个个先修炼好，并最终把它们结合在一起运用到实践中的不同的场景，这个结合的过程被称为技能整合。 学习是为自己而学，而且只为自己而学。同时，学习不是一个阶段性行为，学无止境！ 人是知识以及行动力的集合载体，在有一定的知识基础后，我们需要向人学习。 自我评价体系的四个能力： 获取信息的能力：感知能力、阅读能力、搜集资料的能力等。 加工、应用、创造信息的能力：包括记忆能力、思维能力、表达能力（口头、文字的）、实践运用能力、创造能力等。 学习的调控能力：包括确定学习目的、制订和调整学习计划、培养学习兴趣、克服学习困难等。 自我意识和自我超越的能力。 练习一个知识点，就启动一项评价。 给身体编程： 屏蔽负面信息（无用信息）； 身体与大脑虽然相连，但不共享一套体系。 养成习惯 呼吸法。用鼻子吸进空气3秒钟，让空气停留3秒钟，呼气6秒钟。这种呼吸法能给大脑提供更多的氧气，刺激副交感神经系统，降低呼吸速度和心脏跳动频率，使肌肉放松、血管膨胀，改善血液流动。从根本上说，它给大脑传达了一个信息：一切都正常，无须抵抗或逃跑。 每一个困难的背后都蕴藏着同等、甚至更大的机遇。 我们平时看书就是一种输入，我们在读书期间，老师上课，我们听课，对于我们学生来说，这就是一种输入；除了看工具书外，我们还会看其他的书籍，它们帮助我们拓宽视野，提升知识储备，这也是一种输入；我们在和其他人沟通交流时，获得新的知识或者是新的观点，这也是一种输入；甚至在外出旅行的过程中，那些所见所闻，所接触到的新鲜事物，也是一种输入。 输出一般指的是将知识传授给他人、指导他人。分享、讲话和写作都属于输出，你把你学到的东西转化成你自己的观点。 通过输出机制来巩固输入的学习成果，让学习成为一个封闭的环，一入一出，学习效果更佳，知识点也就记得更牢固，同时，我们接收到的知识也更加广泛。 每年我都会要求自己拜访一定数量的人生导师，他们有的人是企业老板、商界名人，有的是文化圈的泰斗、大文豪。他们在不同的领域有着不同的成就，通过拜访他们，和他们沟通交流，完成我的自我输入。 一场成功的演讲是基于两个要素为基础的，第一是真诚，第二是换位思考。这是能够真正实现沟通，以及在沟通之下进行表达、演讲，市场工作等最重要的两个基础。 后来他甚至到了这样一个阶段，在大学选课时，尽量选那些不用在人们面前发言的课程，他尽量回避需要进行公开的演讲和谈话的课程。我非常不赞同的这种行为，主动回避你的弱点，要知道敢比会更重要，未来你将需要这些技能。——说法偏激了，应该想我得到这些技能多好啊，引起正向的激励。 90 分钟的演讲，我们需要准备八项。演讲的目的性、服饰与装扮、动作设置、环境、次序、礼仪、手稿、彩蛋。 每晚临睡前需要先思考明天的目标是什么，想明白了再睡觉，然后早起就要把它写下来。 康奈尔笔记法的结构是这样的：康奈尔笔记法将一页纸分成了三部分，右上最大的空间用来做笔记，左边四分之一左右用来写提纲，下方五分之一左右的空间用于写总结。 第一步，记录（Record）。在右上方的笔记栏内记下课程要点。 第二步，简化（Reduce）。记录以后，尽早将笔记栏的重点以关键词、简短标题、概念等方式写在随手笔记的侧栏大纲中。 第三步，背诵（Recite）。 第四步，思考（Reflect）。这是康奈尔笔记法中最“精髓”的一步，随手笔记下方的总结区域是你的思想结晶。 第五步，复习（Review）。短期记忆很容易遗忘，间隔复习有助于加深记忆。每周花10分钟左右时间快速复习笔记。 我们的阅读，可以转化成思想，成为思想的核心价值。 计划、实施、总结、评估、再计划 人际关系的价值在于，每个人的时间具有稀缺性，在时间上的投入，需要我们有明确的目标性原则。你需要为值得的人投资更多，同时减少不必要的社交浪费。 情商公式=真诚+换位思考； 人际关系分类管理原则需要遵循 10/20/150原则。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E4%BA%BA%E7%94%9F%E6%95%88%E7%8E%87%E6%89%8B%E5%86%8C%E3%80%8B/"},{"title":"《博恩崔西的时间管理课》","text":"我对成功和成功者了解得越多，就越觉得成功者都有一个明显的共同特征：重视时间的价值，并能持续高效地利用时间。 因此，我得出这样一个结论：没有超群的时间管理技能就不可能成功。我们甚至无法想象一个快乐、有成就的人会过着一种杂乱无章的生活。我的另一个重大发现是，如果你接受了时间管理训练，就相当于培养了自己获得成就、财富和成功的习惯。 培养时间管理技能的首要一点就是要认识到，对时间的管理就是对生活的管理，这就是好好珍惜时间这份最珍贵的礼物的方法。正如本杰明·富兰克林所说：“你热爱生活吗？那就请不要挥霍时间，因为生活正是由时间组成的。” 在你学习管理时间的同时，你也在掌握着人生，掌控着未来。 多年来，心理学家在“心理控制点”领域做过大量研究，发现人们对自己和生活的积极态度取决于他们能在多大程度上掌控自己的生活。如果你有一个“内在”控制点，便可以感到生活掌握在自己的手里。你能够自己做决定，为你自己的行为和结果负责。你是自己生活的首要创造者。 心理学家还发现，如果你拥有的是“外在”控制点，也就是生活的决定权在于外部的人和事，比如你的老板、账单、家庭、健康或其他任何因素，你将感到消极、愤怒和沮丧。挫败感将使你丧失改变的力量。你将产生“习得性无助”，将自己视为“环境的产物”而非“环境的创造者”。当你的控制点是外在的，你会感到自己沦为外在力量的囚犯和受害者。 如果你在明天的彩票中赢得100万美元，你将会如何改变你的生活？如果你瞬间成为一个百万富翁，你所做的事会与今天有什么不同？你将会着手做哪些现在无法做的事？你将停止做哪些现在正在做的事？你将更多的或更少的做什么？你想要去哪里？你想要见到谁？如果此刻你的手上有100万美元的现金，你想做的第一个改变是什么。 如果有机会为自己写自传，你希望在自传里写什么？设想你就要走到生命的尽头，你想为自己写一本自传。如果你可以提前设计好自己的生活，写自己的故事，你会希望你的生命中发生什么？你希望自己成为一个怎样的人？你想要获得哪些成就？想象着你将为自己编写生活的脚本，如果你对这个脚本不满意，你可以把它撕毁，再重新来写。 要培养他人的能力、信心，一个最有效的方法就是让他们全权负责完成一项重要的任务。当人们知道自己要负全部责任时，就会感受到更强的个人力量和掌控感。这有利于建立人的主动性和决心，也有助于培养意志力和决断力。 所有的时间管理技能都要建立在一个清晰、明确的目标和目的基础之上。确认什么是你想要实现的最重要的目标和愿意全身心投入的工作，是进行高效时间管理的第一步。 成功必备的品质是：明确的目标、扎实的知识和强烈的愿望。 1.明确的目标是基础！列一张清单，写出未来一年内你打算在生活和工作中的各个领域实现的十个目标。用现在时态来描述，就如同你已经实现了这些目标。 2.重读你的清单，自问：“如果有一个目标可以对我的生活产生最积极的影响，会是哪一个目标？”把它写在一张新纸的最顶端。 3.为自己设定一个实现目标的具体时间。如果必要的话，可以设定目标完成过程中每个阶段的时间表。 4.列出你能想到的每一件可以帮助你完成这个目标的事。如果想到新的，再加上去。不断更新你的行动列表，直到最终完成。 5.把你的列表整理成一个计划。确定哪个是最重要的，哪个是最首要的。 6.找出你需要克服的障碍，你需要掌握的新知识、新技能，以及可以提供帮助的人。要详细。 7.从最重要的目标开始着手，下决心每天都向你的目标迈进一步。永不放弃！ 你越多地计划一件事，你就越深地把你的目标印在潜意识中，而潜意识正是为其提供动力的工具。 2.以一个旁观者的视角来评价自己。一个很好的训练方法是：站到你的办公桌或办公室旁，问问自己：“什么样的人会在这样的地方工作？” 打开你的皮夹或公文包看看，问问自己：“什么样的人会有这样的皮夹或公文包？”看看你的车里车外、你的橱柜、你的家、你的院子还有车库，问问自己：“什么样的人像这样生活？” 你是否会对这个人委以重任？为什么？通过一个中立的第三方视角来诚实地评价自己，你会看到一个怎样的自我？ 整洁的桌面是效率的提升。 一项任务的完成会使人产生极大地心理满足感。你的大脑就以这种方式构造，当你完后一项工作时，不论大小，都会引起内啡肽的分泌。对你而言一项任务越是艰巨、重要，你就会越多地在完成时体验到快乐、愉悦的感觉。每次完成一项任务，你就希望继续去完成接下来的任务。 当你提前一晚制定工作计划时，在你睡觉的时候你的潜意识就已经开始致力于你的计划和目标了。这样，当你从睡梦中醒来是，就已经迸发出一些对工作的思考和想法。 个人条理的 7 个工具 前夜的准备 规划你的时间 早起的鸟儿有虫吃 利用有序的归档系统 利用黄金时间做最重要的工作 利用听写机或录音机来做记录 使你的航空旅行也能创造财富。—带本书看，不困的话 自我暗示：我在做每件事时都是有序高效的。 人的自然倾向是优先处理“占多数的小事”。遵循这种自然倾向，我们很多时候都是在努力地解决那些根本不需要处理的事情。 只有在你的行动与价值观相一致时，你才能达到最佳状态，你才会充满自信。只有你的信念与你的行动像手和手套一样契合，你才能真正地感觉到幸福。 无论如何，当你发现自己的外在表现与内在信念不一致时，你就会体验到压力和冲突。 人们单身的时候的价值观会与他们结了婚和有了孩子之后差别非常大。单身的人不需要对其他人承担责任，此时工作、社交、旅行、娱乐、运动及其他活动更有价值。可是人一旦结婚、生了孩子，价值观会发生极大的改变。几乎每个夜晚，你的配偶和孩子都是最为重要的。当你的价值观发生了变化，你也就变成了与之前不同的人。 如果你所做的事情与自己的价值观完全相符，你会感受到由衷的幸福。 要想实现一个之前从未实现过的目标，你就需要培养并掌握一种之前没有的新技能。 对时间最糟糕的利用就是把不需要做的事做得完美无缺。 如果一件事根本不值得做，那就更不值得把它做对。 你的时间掌控力取决于你能在多大程度上放弃低价值或无意义的事情。你越多地放弃、取消不必要的任务你就为“A”类任务的完成腾出越多的时间，而这类事情才是决定你事业成败的关键。 时间就是你的生命。当你投入精力去做最高优先级的任务时，你就是在为生活创造最大的财富。相对的，去做非优先级的事情就是对时间的浪费。当你全身心处理最高优先级的任务时，你就能获得最大回报，你会体验到源源不断的力量、热情和自尊感。你会感到更有力量、更自信，你自己和你的整个人生都呈现着最佳状态。 人的潜意识无法分辨真实经验和生动想象之间的区别，如果你想象自己表现得高效，你的潜意识就会完全按照你在哪个时候的表现高效来做出反应。每一次你都想象自己表现出最佳状态，你的潜意识就会把这种想象当做真发生过记录下来。 你可以通过想自己灌输积极的形象来推动自己走向成功，这种积极的形象可以是自己想象出来的，也可以是回味自己之前有过的高峰体验。 如果你想更加自信，那就表现得自信。如果你想更勇敢，那就表现得勇敢。如果你想更高效，那就像你已经是高工作效率的人那样来表现自己。你的行为表现会改变你的感情和信念，就像你的感情和信念能够决定你的行为表现一样。 天才的三个特质：第一种特质是所有的天才看起来都会采取系统和有序的方法去解决问题；第二种特质是好奇心；第三种特质是他们注意力的集中程度要比普通人更加深入和强烈。 托马斯·杰弗逊说过：“太阳从未照到过躺在床上的我。” 在别人回家后再在办公室待 1 个小时。对于工作繁忙的人而言，这是保证完成工作的最好办法。 每当你满足了大脑对于完成任务的需要时，大脑就会把内啡肽释放到血液里。这些内啡肽会让你感觉快乐和幸福，可以提高你的动力和创造力，能改善你的个性，让你对自己更加满意。所以要训练自己完成重要任务，这样既可以改善整体生活质量，又可以显著提高自己的工作效率。 奖励对于高水平表现具有非常的激励作用。你应该尽量多给自己一些奖励，即便是完成报告就出去散步这种简单的奖励预期都能推动你前进和帮助你集中精力完成任务。 无论工作类型如何，一旦开始工作就要下定决心坚持到工作完全结束。 “一次只做一件事”是成功的销售人员、主管人员和企业家的共同特征。他们只专注于处理眼前最重要的工作，直到该工作完成为止。他们为工作设定优先级，一次只做一件事。 美国是一个特殊的地方，它在经济上提供你一个向上攀登的阶梯。令人兴奋的是：只是在梯子的底部拥挤不堪，顶端并非如此。 生活就是一系列的项目，而每一个项目又是一个复杂的任务，我们称之为“多任务工作”。这种工作类型要求多人的合作，每个人负责这项工作的一部分，而每一部分都是最终成功的必要基石。计划和组织类型是时间管理的核心技能之一。 组织团队完成任务的能力是管理者事业成功的最重要的品质。 你在前期花越多的时间与团队成员制定计划，他们在执行的时候就越是能够富有创造力的投入。 你越是能把一个大项目分解成每个人的工作，你就越容易来计划、组织、监督、任命和协调，最终按时交工。 在生活中，只有当你的选择是自由的，你才是自由的；只有当你有了准备充分的备用方案时，你才是自由的。如果没有预备好的其他选择，你会发现自己被限制在一个行动程式中。一旦这个计划或行动出错，你就会有大麻烦。 在任务管理中需要掌握的最后一点就是安排时间定期检查工作进展，解决问题及重新安排任务。不管你在一开始计划的多么完美，在过程中都会收到大量的反馈，你要根据这些反馈定期修改原计划，保证工作顺利完成。 成为一个好的领导者要求你拥有或建立最出色的领导和管理能力。但出现问题是你必须保持冷静。你必须不断地提醒自己如果你不站在制高点掌控全局，他就无法成功。如果这个项目非常重要，你就必须承担起检查目标完成进站的责任。除非你亲自花时间去检查、确认，否则不要妄想每一件事都能忠于计划。 把你所有的精力集中到人生最大的梦想上。 如何花费你的时间？根据时间管理专家迈克尔·弗蒂诺的统计，平均在一生中，你将花7年沐浴，6年进餐，5年排队，4年打扫房子，3年开会，1年找东西，8个月处理垃圾邮件，6个月等红灯，120天刷牙。最让人惊讶的是，你每天只花4分钟与配偶交谈，30秒与孩子说话。 要想朝着积极地方向改变这个比例，你就要学会如何切断这些时间的浪费源。 纵观历史，伟大的领导者都有一个共同的特点，就是具有前瞻性，并能发掘所有可能出现问题的事情。他们会提前为偶然时间制定计划。如果真的遇到了麻烦，也已经做好了快速解决的准备，因为他们已经完全考虑过这种情况的出现了。 快速决策，迅速行动 能分辨最重要的工作并尽快完成它的能力比你的其他习惯更能帮你进入事业进步的快车道。 Do it now. 如果你能把引起你内心最大的担忧和痛苦的那件事先完成，你就会变得更高效。 仔细地规划你的生活、工作和节奏，你就可以不时地引起“心流”体验，它也是你成功的关键。所有真正高效的人都会经常性的体验这些神奇的能量流。它可以通过有意识的加快工作节奏来激活，就像飞机清空跑道（加速直到起飞）一样。 如今，任何领域的知识量每 5~7 年就翻一翻，有的甚至只需两三年。这意味着你必须经常地翻新知识才能保持同步。你所有的收入都来源于你的所知。 通过打开思路，不断地从各个不同的来源阅读、收集新信息，科学家们找到了能把其他知识贯穿起来的那一条信息，从而实现了一个伟大的目标。 生活中的每一个改变都源于你的思想和新观点发生的碰撞，就像台球桌上一个球去撞击另一个球。 在这个信息时代，你越多地接触、汲取新观点和新知识，你就越有可能在恰当的时间发现你所需要的那个想法和见解。 阅读之于大脑的意义就如同锻炼之于身体。当你每天都阅读自己专业的知识、书籍时，你就会变得更聪慧、敏锐，也会变得更积极、专注和富有创造性。缺乏阅读，你会眼睁睁地看着成功的机遇从身边溜走。 你所接触的观点越多，你就越有可能在恰当的时间遇到那个对的想法。 对你所挣的钱最好的投资就是自己，成为比挣到这笔钱时的自己更优秀的人。 成熟的大脑是精心设计的，因此你只学习和记忆那些对目前的情况有关和实用的东西。不管这件事多么有趣，如果你无法将它与你目前的工作生活建立起任何联系，或想到如何应用，它就会从你的大脑中溜走，就像流水过筛，你事后很难记住。 做一件事意味着不做另一件事，如果你阅读一些无直接关联或无法应用到你的工作中的东西，你就同时失去了对于能给你带来帮助的东西的阅读机会。 在阅读阶段，你要坐下来，开始快速地阅读，概览和预览的过程已经勾起了你的兴趣和好奇。在阅读中，你就会去寻找这些能填补你知识空缺的信息。这时，你实际上是进入一种“预期学习”中。你会努力寻找书中所包含的信息和观点。 重复是学习之母，一条新信息需要重复 3~6 遍才能被你内化并进入长时记忆。 你学的越多，你就越会学习。 你越是不求回报的付出，回报越是会从意想不到的地方不期而至。 没有什么比对人性的洞察更有力量。人的行为受何种动力驱使，被什么本能控制？如果你了解了人的这些方面，你就能触碰到他存在的本质。 不要假设他人能够理解你们所讨论的内容，直到他能用自己的话把意思反馈给你。同样，不要认为自己理解了一件事情，而是应达到能用自己的话复述，并得到他人的肯定。 你需要把所有能交给别人的事都委派出去为自己获得更多的时间来处理最重要的一些事。 有一个有趣的发现。你越多地思考和讨论问题可能的解决方法，你越是聪明，越是有更多的想法。你会变得越来越有创造性。你的思维也会更加敏捷。你越多地去寻找解决办法，他们就会越多地出现在你的大脑中。最终，你就像吃豆子游戏中的黄色小精灵一样在遇到问题时尽快地把它们消灭掉。 思考备用方案的过程是一个很好的思维训练。它促使你以更发散的思维看待问题的所有可能性。通常，在思考如何留出退路的同时，你实际上也在完善最初确定的解决方案。有时，你在做全面的调整。 在以情动人前，你自己要先被打动。在催人泪下前，你自己要热泪盈眶。在你以理服人前，你自己要坚信不疑。 对于那些生活在社会底层的人而言，时间的概念不过几分钟，他们根本不考虑此刻以外的事情。小时工的时间观是两个支付周期，工薪阶层的时间观大约是两个月。当你在社会经济的阶梯上不断向上攀登时，你的时间观就不断加长。 当你为时间和资源的分配做决定时，你考虑了多久以后的未来？有一条规律是：长久的时间观会提高短期的决策能力。在思考当下的决定时，你向前看得越远，你的决定就越正确。长期的成功取决于现在所做的每一个决定的质量。好的决策积累是你未来目标得以顺利实现的保证。 你要尽可能地去雇用他人来做较低价值的工作，而为你自己、你的工作和加人赢得更多的时间。 感情的目的是什么？最简单的答案就是你会比现在更快乐。可是很显然，很多人都没有意识到这一点。人的每一个行为都是为了以某种方式改善自己的生活，提升自己的幸福感。因此，你对一段感情的选择是你一生中所做的最重要的决定。在感情上做出一个正确的选择会比你所做的其他所有选择对你幸福的影响都要大。而对感情的错误选择也会比其他所有决定都能使你的希望和梦想破灭。 一个成熟的、发展健全的成年人会考虑他人的好恶和观点，但是仍然坚持以自己的方式做出自己的决定。 大多数人都忙着处理自己的事情，根本没有时间去顾及别人的生活和行为。 把精力投入到高价值的工作中去——那些让你获得你所预期的报酬的事情。如果你希望每小时挣100元，就一直问自己：“我现在做的事情是否能够支付我100元/小时或者更多的薪水？”如果不是，就告诉自己不要再做下去。只做那些能够支付你预期报酬的事情。 要想让生活保持均衡，你需要不断地回顾自己的价值观，什么对你而言是最重要的。如果你的目标和每天的工作与你的价值观相一致，你会感到无比快乐，并享有最高的自尊感。当你的外在行为表现和内在的心理期望完全吻合时，就是你感到最满足的时候。 为自己理想的生活方式下个定义。如果你有足够的钱，能以任何你想要的方式规划你的生活，你希望它与今天有什么不同？试想为自己制定每个月、每一周最完美的生活计划。如果你能够设计从 1 月 1 日到 12 月 31 日的每一天，你希望自己如何度过？你有哪些想去的地方？你会带着自己的家人去哪里旅行？在最理想的生活转台中，你的作息如何安排？如果你完全有选择的自由，从今天起你会在生活方式上做出什么改变？ 你对自己理想的生活方式越是清晰，你就越能在短时间内做出能确保未来用友这种生活方式的决定。清晰的目标是一切。 通过进行身体锻炼来使你的生活保持平衡，走路、跑步、游泳或者打高尔夫都可以。你要确保每天自己身上的每个关节都得到活动，每块肌肉都得到拉伸。每周进行三次有氧运动才能维持能够保证最佳状态的健康水平。 如果你感到自己太忙了，没有时间进行运动，那就意味着你的生活已经开始失衡。如果你感到自己因为太多的任务而停不下来时，它暗示你已经到了极限。不管何时，当你觉得自己无法停下来时，就是身体在告诉你必须尽快停止的时候。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E5%8D%9A%E6%81%A9%E5%B4%94%E8%A5%BF%E7%9A%84%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E8%AF%BE%E3%80%8B/"},{"title":"读后感 —— 《苏世民：我的经验与教训》","text":"今年疫情严重，全球股市在触底之后出现了很大的反弹，各路股民见势进场。 作为一个金融小白，在周围大佬们都在讨论股票的氛围下，终于开始接触理财。 前前后后读了《小狗钱钱》《富爸爸穷爸爸》《财务自由之路》，加上网上各种资料，终于算是入了个门。 前些日子朋友推荐了这本《苏世民：我的经验与教训》，强推。读下来感触颇深。 理财书，也是人生之道同一本书，不同的人读下来，感悟差别会很大。 从我的角度出发，我是抱着要实现财务自由的想法读下来的。 总体感受，这本书也好，前面几本甚至说《小狗钱钱》这种理财启蒙书籍也好，没有读之前会觉得，里面会是满满的理财相关知识，读下来发现，这些书标着理财的标签，实际上大部分内容是在讲述，如何成为一个更好的自己。 讲理财，更是讲人生之道。 笔记结合感受 Stephen Schwarzman ，史蒂芬·施瓦茨曼 ，苏世民 作者是美国人，我猜 苏世民 这个中文名是 Schwarzman 的音译，shi was man，第一个音作苏，was man 作世民，没太去查是谁起的这个名字，猜测是清华前校长陈吉宁，在谈清华苏世民学者计划的时候特意起的。 给你敬佩的人写信或打电话，请他们提供建议或与其会面的机会。你永远不知道谁愿意跟你见面。最后你会从这些人身上学到很多重要的东西，建立你在余生都可以享用的人际关系。在生命早期结交的人，会与你缔结非同寻常的感情纽带。 这句出自 25 条工作和生活原则之三。之所以记下来，是因为我觉得这条对于我的挑战是最大的，从没有试过，但是绝对是一个很棒的做法。第一，你敬佩的人，说明你是有目标的，而且明确；第二，站的比你高的人看的一定比你要远，能交流是莫大的财富。 我相信教育是一门学科。这门学科的目标是学习如何思考。一旦掌握了这一点，就可以将其应用于学习投身一项事业、学习欣赏艺术、学习阅读书籍。教育赋予我们能力，让我们欣赏上帝之手写就的千回百折的剧情——生活本身。在我们离开教室后，教育仍在继续。与朋友联系、参加俱乐部，这些都能增加我们的知识储备。事实上，学习伴随我们的终生。我和我的干事们只是希望在座的各位能够正确认识教育的目的，并在你们的余生中遵循教育的基本原则，不断质疑，持续思考。 人生是一个不断学习的过程，现代社会更是如此。拥抱变化，持续思考，积极的面对未来。 那年夏天，我在一个夏令营担任顾问。在开车接我回家的路上，父亲告诉我，我即将进入一个他一无所知的世界。不管是在耶鲁的人，还是上过耶鲁的人，他一个都不认识。在这个新的世界里，他能给予我的唯一帮助就是爱我，让我知道我总有家可归。除此之外，我只能依靠自己。 开明的教育，没有隐瞒。我不清楚是苏世民的总结能力好，还是他的父亲原话就是这样，把我放到这个场景这个位置，我是说不出这样的话的。 “施瓦茨曼先生，我想跟你谈谈你论文的事。” “真的没什么好说的。”我说。 “为什么？” “我没什么见解，表达也不好。” “天哪，你真不傻。你比我总结的还好。所以我必须先教你如何写作，然后再教你如何思考。因为两者不能同时学习，我会给你接下来几篇文章的题目，我们先专注于写作技巧，然后我们再专注于思考方式。” 他看到我的潜力，并且着手系统地为我配置我需要的东西。我永远不会忘记他的耐心和善良。我开始相信，教学不仅仅是分享知识。为人师，就必须消除他人学习的障碍。就我而言，障碍是我所接受的教育与同班同学之间的差距。就在那一年，我入选院长嘉许名单，从一名差等生一跃成为班里的尖子生。 教育的力量，别人的帮助，和自己的成长。 在海上待了三个月，再次回到单调的纽黑文，我感到非常不适应，满脑子都是弗洛伊德、港口、沙滩、酒吧，还有沿途接触的姑娘。整个夏天，在同学忙着打网球、在办公室工作时，我则在发动机房汗如雨下，在哥伦比亚的酒吧与人大打出手。我的暑期经历十分刺激又极具挑战性，并且每次都能幸免于难、死里逃生。相比之下，纽黑文的生活越发显得单调乏味，令人倍感压抑、苦闷。在《耶鲁每日新闻》的头版，我看到一则广告，说如果感到沮丧，那么建议去大学健康系看精神科医生。我决定试一试。精神科医生的装扮中规中矩，拿着烟斗，戴着领结。我跟医生诉说了我的那个夏天，那些航线、那些姑娘、那些港口，还诉说了我有多么不想再回学校。 “你当然不想回来，”他说，“为什么想回来呢？你不需要治疗，这只是戒断症状。坚持一下，把心收一收，过几个月就没事了。” 事实证明，他说的对，时间是最好的解药，渐渐地，我的心归于平静，我准备以自己独特的方式度过在耶鲁的时光。 戒断反应这种东西，之前都理解偏了。在某种愉悦感受之后归于平淡，这段时间非常想再去获得那种愉悦，得不到就沮丧甚至出现身体上的症状，这都是戒断反应。这是人类的本能。 尽量接受好的 愉悦感受，比如看书获得知识的满足感。 做大事和做小事的难度是一样的。两者都会消耗你的时间和精力，所以如果决心做事，就要做大事，要确保你的梦想值得追求，未来的收获可以配得上你的努力。 时间和精力是有限的，首先要保证的就是不要浪费时间精力，接着是做应该做的事，下一步是做大事。 我从第一次孤独无助地在大食堂吃饭，一路走到现在，这真是一段值得回忆的充满喜剧色彩的旅程。 这段上下文是，苏世民第一天到耶鲁大学，一个人在食堂吃饭，没有认识的同伴很孤独。 接着几年的学习，期间学习、加入骷髅会、组织芭蕾演出等等，到毕业时，已经是明星学生了。 很出彩的大学经历 从他家离开以后，我跑去公共电话亭给爸妈打电话。我告诉他们，我去找哈里曼了，他给了我一些人生建议。他告诉我，我可以做任何我想到的事情。他说，在人生的某些阶段，我们必须弄清楚自己是谁。越早认清自我越好，只有这样，我们才能找到适合自己的机会，而不是活在他人创造的梦幻中。但如果我要把自己有价值的理想变为现实，成为一个有信息大量流入的如电话交换机一般的人，那么我需要去赚钱。 此段非常重要，建议多读几遍。 认清自己，认清自己的欲望，知道自己的目标，活的要有方向。 此为人生之路 在面试了上千人以后，我已经形成了自己的面试风格。我会捕捉一系列语言和非语言的线索，我会尝试与候选人深入交流，然后观察他们的反应。我没有什么固定的套路，但在每次面试的时候，我的目标都是调动我的洞察力直入候选人的大脑，以评判他们的思维模式，了解他们真实的自我，判断他们是否适合黑石。 深入理解人的思想，评判他们的思维模式，了解他们真实的自我。 我们每天最好的 8 小时是在工作时间，工作和生活，是真实的我们。 对待工作和生活都应该认真积极。 至少，这个人得通过机场测试：如果我么能乘坐的航班延误，我是否愿意跟这个人一期在机场等候？ 机场测试，你能通过么。 当杰克开始跟我学习金融知识时，我只花了一分钟时间，就发现雷金纳德·琼斯的判断完全正确：杰克正是最佳人选。和杰克·韦尔奇一起工作，大脑就好像被接上了一个吸尘器，他会吸走你知道的一切。我再也没有见过像他这样的人，他对学习充满渴望，孜孜以求，总是无休无止地提出这样那样的问题；他善于思考，思维敏捷，能立刻理解一个想法与另一个想法之间的联系，即使这两个想法对他来说都是全新的知识。他就像人猿泰山似的以极快的速度抓着藤蔓穿梭于树木之间，从不失手，学的比我教的还快。 通过了解杰克，观察他的行动，我更为确信，商业中最重要的资产就是信息。你知道得越多，你拥有的视角越多，可以建立的连接就越多，进行预测的能力就越强。 杰克于1981年成为通用电气的首席执行官，开始主持公司的运营，成为美国历史上最伟大的首席执行官之一。由于彼得的引荐，我和杰克也建立了长久的友谊。几十年后，杰克依然令我惊讶不已。我在职业生涯早期就加入了一家大公司，遇到杰克是这一决策最大的收获之一。华尔街和商业都是很小的世界。如果你以一所优秀的学校或一家大公司为起点，与你们这一代最优秀的人交往，你将来就会不断地再次遇到他们。我在耶鲁大学、哈佛商学院、陆军预备队和华尔街早期结识的许多朋友现在都还是我的朋友。我在生命早期交到的朋友，用他们的信任和理解，以我无法预测的方式极大丰富了我的生活。 细品，真正优秀的人一定比你更努力，然后这些人组成了一个圈子，哦我的天，世界就是这么运转的。 刚进入金融行业时，我对工作压力没有足够的思想准备。其实，每次谈判中的每一节点都是一场战斗，有人赢，也有人输。这个行业的人对瓜分蛋糕、给每人都分一点儿不感兴趣，他们想要的是整个蛋糕。我留意到，当周围人的音量飙升、脾气爆发，而此时又需要我做决策时，我就会心跳变快，呼吸变浅，工作效率变缓，自我认知能力和应变能力的把控也随之下降。 他们想要的是整个蛋糕 我找到的缓解压力的方法是专注于自己的呼吸，减缓呼吸速度，放松自己的肩膀，直到呼吸变得深长。这一做法效果惊人，我的思路渐渐变得清晰，对眼前形势的认识变得更为客观和理性，也更加清楚自己如何才能获得胜利。 面对压力，调整状态，专注呼吸，冥想 冥想真的是一个调整的好办法。躺在床上，随着呼吸放松每一块肌肉，包括眼睛。 休息也是技能。 这篇文章准确地描述了当时的我。对我而言，倾听他人的看法是理所应当的做法，这却让我在华尔街独树一帜。在与他人交往过程中，我从不急于表达自己的观点，极力推销自己手里的东西，而总是选择倾听。我会静静等待，关注对方要什么、想什么，然后着手满足对方的需求。我很少在会议上做笔记。我只是非常关注对方说话的内容和表达的方式。如果可以的话，我会尝试找到一些可以与对方产生联系的触点，一些一致之处，或一些共同的兴趣或经历，让公对公的交流变得更富有人情味。这种做法听上去是常识，但在实践中，显然很少有人能够做到。我会全神贯注地倾听对方，由此带来的一个结果就是，我可以回想起事件和对话的细节，好像这些细节已经印在了我的大脑里。许多人失败是因为他们从自身利益的立场出发，只选择性地听取与自己有关的话题，至于其他的话题他们总觉得“这对我有什么用”，他们永远无法从事最有意思和最有价值的工作。仔细聆听对方谈话的内容、认真观察别人表达的方式，这种做法能极为有效地帮我找到“我能提供什么帮助”这一问题的答案，这也是我一直以来在问自己的一个问题。如果我可以帮助别人，并成为解决其问题的朋友，那么其他的一切都会随之而来。 我能为别人提供什么帮助。 人们最感兴趣的话题永远是”自己的问题“。如果你能发现对方的问题所在，并提出解决方案，那么他们一定愿意跟你沟通，无论他们的等级或地位如何。问题越困难，解决方案越少，你的建议就越有价值。为人人避之不及的问题提供解决方案，才是竞争最小、机会最大的领域。 重点，这段绝了 解决别人的问题，是机会；为人人避之不及的问题提供解决方案，是竞争最小、机会最大的领域。 那时，我已经非常了解自己了。从高中到耶鲁大学、哈佛商学院，以及在雷曼兄弟一次又一次的经历，事实证明，几乎任何困难都压不倒我。我可以构思出有价值的伟大设想，并把设想变为现实。阿姆斯特朗教练让我理解了坚持的价值，他教导我，额外的付出一定会换来意外的收获，每次都要让我多跑几英里，让我付出额外的努力。日久天长，日积月累，这些付出逐渐变成了一种志在必得的信念，一种锲而不舍的精神。这就是我无形的资产，当我需要的时候它就会在那里供我撷取，取之不尽，用之不竭。此时此刻，我已经想好利用这些无形的资产进行怎样的投资，以此推进我的职业生涯。 坚持的力量 纯果乐的交易让我了解到，在压力面前，我的能力远远超过我的想象。彼得·彼得森向我展示了伟大导师和合伙人的价值。我与一些优秀人才建立了宝贵的关系，包括公司的同事和像杰克·韦尔奇这样的高管（杰克·韦尔奇后来不断出现在我的职业生涯里）。我曾经历过最好的华尔街，享有过执行复杂交易的巅峰，体验过处于宇宙中心的感觉，也有幸与世界上一些最有趣的人交流信息，沟通思想。 压力激发潜能 追求卓越的人往往对学习充满热情，孜孜以求，他们善于提问、勤于思考，能够敏锐地捕捉到想法之间的联系，从不失手。 追求卓越 创业6个月以来，我们已经拜访了每一个愿意见我们的潜在客户，但除了纽约人寿和大都会人寿最初的投资承诺外，我们还没有募集到1美元。在拜访保诚的时候，我们几乎跑遍了选择的18家目标公司。保诚是杠杆收购的头号金融家，是金本位。在这家公司里我们没有熟人，所以我们选择最后拜访这家公司，而且那个时候，我们的推介材料应该已经完善得差不多了。保诚集团副董事长兼首席执行官加内特·基思邀请我们在新泽西州纽瓦克共进午餐。 加内特吃的是金枪鱼白面包三明治，他把三明治切成了4块。我开始介绍的时候，加内特咬了第一口。在我说话的时候，他会咬掉一些面包，咀嚼，吞咽，一言不发。他的下巴会动，喉结也上下移动。在他吃了3/4的时候，我的推介做完了。加内特把最后一块三明治放下，嘴巴不嚼了。他说：“这很有意思，我出1个亿。” 他的语调如此随意，完全出乎我的意料。为了这1亿美元，我愿意在法律允许的范围内做任何事。这是一个伟大的范例，如果保诚认为在我们公司投资是个好主意，那么其他公司也会纷纷效仿。我想伸手抓住最后一块三明治，以确保加内特不会噎到。 吃三明治的细节记忆的如此清晰，可见这件事对其影响之大 另说，此人长期记忆力极好 人生中重要的一点是始终对新体验持开放态度，及时这些体验并非完全在自己的规划内。 拥抱变化，拥抱变化，拥抱变化 当第一次想到增加黑石的业务线时，我们的宗旨就是要有选择性地进入新领域。新业务不仅本身要表现出色，还能让整个公司获得更多信息、知识和技能。我们相信，我们从不同的业务领域学到的东西越多，公司的发展就会越好。这是哈佛商学院传授的一个理念：在商界，一切都是相互联系的。与竞争对手相比，我们寻求机会、分析市场的角度和方法会有所不同。我们的视角会更加多样、分析会更为深入。我们公司的信息来源越多，我们知道的就越多。知道的越多，我们就越聪明，想要与我们合作的人就越多。 信息就是能力 我可以从他人的音调中听出细微差别，通过他们的肢体语言进行判断，这些信息跟他们汇报的内容本身一样重要。如果我们与分布在全球各地的办公室只是通过电话交流，那么我想我们很难保持公司投资流程所需的严谨性。视频会议技术的发展改变了我的想法。2001年，你可以实时与千里之外的人进行互动。那一年，我们在伦敦开设了办事处。 从他人的音调中听出细微差别，通过他们的肢体语言进行判断，这些信息跟他们汇报的内容本身一样重要。 全都是信息 他告诉这些新人，他们非常幸运，在职业生涯开始时，就能从这场历史性的经济危机中得到磨砺，如果他们够聪明，就会从中学到很多经验教训，并把学到的东西应用于自己的整个职业生涯。他说，成功会令人骄傲自满，不思进取。你只能从失败中学习，在逆境中成长。 成功会令人骄傲自满，不思进取。你只能从失败中学习，在逆境中成长。 我现在很确定中国不再是子孙后代的选修课程，相反，这将是一门核心课程，而我们设计的苏世民学者项目就是学习这一核心课程的最好课堂。 李光耀 世界领袖与其他任何人都没有什么不同。如果你谈论困扰他们的问题，并提出一些有用的建议，他们就会倾听，无论这个人是民主党人还是共和党人、王子还是总理。 解决别人的问题，不仅能获得收益，还能获得友谊 最后，我提醒凯瑟琳：“你之所以晋升，是因为你的工作完成得极为出色。你拥有成功的天赋，无论是个人资质，还是专业技能，都能取得长足的进步，我对你有百分之百的信心。”下属需要知道你非常欣赏他们，你也需要让他们自我感觉良好，这一点非常重要，因为自信是出色表现的基础。 无论你的职业生涯如何开启，都要知道，你的生活不一定会直线前进，这一点非常重要。你必须认识到，这个世界是不可预测的。有时，甚至像你们这样有天赋的人也会遇到意料之外的磨难。在人的一生中，会难以避免地出现诸多困难和艰辛。面临挫折时，你必须要想方设法继续前进。能够定义你个人品质的，永远是你在逆境中展现的百折不回的精神和永不言弃的态度，而不是逆境本身。 把时间和精力投入自己热爱的事物上。热情所至，卓越必成，单纯为了他人的敬仰和尊重而做事，则很少能带来成功。如果你对追求梦想充满热情，如果你能勇往直前，如果你以帮助他人为己任，你的人生就会充实而有意义，你也永远有机会建功立业、成就不凡。你为他人付出的善意和努力，最终会给你自己、你所爱的人以及整个社会带来福报。 这两段是 苏世民在 清华苏世民书院 毕业典礼上的讲话，细品","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E8%AF%BB%E5%90%8E%E6%84%9F-%E2%80%94%E2%80%94-%E3%80%8A%E8%8B%8F%E4%B8%96%E6%B0%91%EF%BC%9A%E6%88%91%E7%9A%84%E7%BB%8F%E9%AA%8C%E4%B8%8E%E6%95%99%E8%AE%AD%E3%80%8B/"},{"title":"《超级快速阅读》","text":"在调用信息的阶段，大脑的任务就是按照实际需要重新整理已保存的信息，然后将其输出，用来解决具体的问题。 比如，如果我们在学习的时候压力过大，或是感觉到竞争威胁，我们的脑干就会本能地活跃起来。我们的大脑一旦切换到这种应激状态，血液会从大脑外部的其他分区流出，逐渐向内部聚集，最终集中于脑干部分。这时，这个毫无学习功能的脑部分区就会成为主导，我们会感到自己无法思考，也学不进新的东西，轻则学习效率下降，重则根本无法进入工作或学习状态。对于现代人来说，这种情况大多出现在考试前或是在工作上遇到新挑战时。 每当人脑接收到一条新信息时，缘脑就会首先被激活。如前文所述，这部分主要负责人体的生理及心理平衡，而人脑所有分区从本质上来说只有一个功能，那就是确保生命安全。 因此，缘脑必须充当信息过滤器，将新的信息与既有经验进行分析比较。如果得出的结论是正面的，也就是说同类的信息曾经给我们带来积极的影响，那么缘脑就会开绿灯，允许这条信息传递到大脑皮层，等待进一步深度处理，我们也会从主观上感到愉悦，产生处理这条信息的动力。 人脑在预先知道时间有限的情况下会自动提高工作效率，以便更好地利用有限的时间。 逐字阅读仍然不失为一种毫无副作用的健康催眠法。 女人的视线要比男人宽得多。女人整天待在家里，负责保护族群居住的山洞免受野兽的侵袭。她们必须时刻留意洞穴入口以及外围区域的大小动静，视线范围就得到了很好的锻炼。在采集野果和照看孩子时，较高的视野拓展能力也是不可忽视的优势之一。人类进化至今，这种能力依然深深地扎根在每个女人的基因里。 与女人相反，男人总是外出狩猎。 他们必须把视线聚焦在距离较远、范围较小的区域内才能找到猎物，并且还要一直紧紧地盯住目标不放。 长此以往，男人的视线就一直处于紧张的远距离聚焦状态。不难想象，如果一个猎人老是因为路边草丛里的野果分心，那全家人迟早都得饿死。 思维导图就是大脑的工作模式 只要个人的能力符合客观挑战的程度，任何一个人在从事任何一项活动时都有可能进入理想的心流状态。 一直以来，肾上腺素这种人体自然分泌的激索都有另外一个十分贴切的名称——应激荷尔蒙，因为这种激素能够加速心跳，加快血液循环，提高肌肉的反应速度。此外，肾上腺素还能加快分解体内的脂肪和糖类，在紧急情况下为身体提供更多的能量。 从生物遗传学的角度来看，肾上腺素绝对是人类生存繁衍的一大功臣。想象一个原始人正在森林里采集野果，突然树丛中跳出来一只剑齿虎。这个可怜人肯定会觉得不知所措。可就在他还没来得及开始理性思考之前，人体就已经像我们上面描述的那样，在几秒钟的时间里分泌出了大量的肾上腺素，为下一步的打斗或者逃跑做好了准备。 只可惜，现代人的压力来源远远不止一只剑齿虎那么简单。考试压力，工作压力，家庭责任，今天被上司批评了，明又要交论文……根本数都数不清。然而我们的身体可分不清哪些压力是老虎惹的祸，哪些压力是因为考试不及格，不管三七二十一都会释放出大量的肾上腺素。 这些荷尔蒙会麻痹脑神经之间的神经树突，阻碍大脑中的信息传递，某些负责促进思维的神经递质也会立即停止分泌。 也就是说，人体内的肾上腺素水平越高，人的思维能力和接受新信息的能力就越低。 此外，我们还得了解肾上腺素的另外一种表现。 在压力越来越大的情况下，我们对自身情况的主观感受往往会越来越偏离客观事实我们越是坐在那里胡思乱想，越会觉得时间不够，要学的东西太多，要看的书看不懂……这种现象其实也是人体生存机制的表现。 一个人遇到的情况越紧急，他的大脑越会刻意屏蔽相关的信息。举个例子来看容易理解**这种逃避现实的效应**了。大家肯定都有过类似的经历：我们读到课本的某个段落，觉得这部分内容简直如天书一般、于是就在潜意识里试图说服自己，这部分内容太多啦，我就算能看玩也肯定看不懂。 可是一觉醒来，等我们清醒了，重新回过头来阅读这篇文章，就会恍然大悟，发现一切问题都迎刃而解了。与此同时，我们也会觉得昨天的自己那么紧张，简直太可笑了。 运动减压，足够运动量的人的肾上腺素一般都会处于稳定的较低水平。运动不但是一种预防压力的有效措施，还可以让你的心态更加平和，情绪更加稳定。 越是无知的人，就越喜欢对那些自己一无所知的事情评头论足。 呼吸放松法 吸气和呼气的节奏越慢，你就会越放松。请你连续练习2~3分钟。在练习的同时，你也可以想象自己正躺在一片宁静的沙滩上，海浪和自己的呼吸同步，正在缓慢的拍打着沙滩。 这里我有必要解释一下α波。在脑电图上，人脑会产生四种不同的脑电波。其中振动频率最高的一种叫做β波，代表人在清醒状态下较为紧张的脑部活动状况。当我们处于较为放忪的状态时，脑电波就会进人α波的区间。如果振动频率更为缓慢，脑电波就变成θ波，人会感觉睡意朦胧。最后一种δ波代表大脑已经进入深沉睡眠或无意识的状态了。 当脑电波振动领率处干α波区间时，我们的大脑能轻松地接受新知识 。 音乐放松：几乎所有巴洛克时期的慢板或柔板乐曲的速度和节奏都至少能够在一段时间里引导我们的大脑进入α波状态。图 2-10：科雷利：12首大协作曲(作品编号6)中的所有慢节奏乐章。 亨德尔：D大调第三好吉他协奏曲，柔板乐章《皇家烟火》。 泰勒曼：g小调第十七号大键琴幻想曲，柔板乐章；G大调中提琴，柔板乐章。 巴赫：《哥德堡变奏曲》，咏叹调；f小调第五号钢琴协奏曲，柔板乐章；F大调大键琴协奏曲，柔板乐章；D大调第三号管弦了组曲。 维瓦尔第：小提琴协奏曲《四季。冬》，柔板乐章； D大调吉他协奏曲，柔板乐章；e小调长笛协奏曲（作品编号44），柔板乐章。 兴趣减压法：除了听音乐，还有一种舒适的减压方法，就是借助人体自然分泌的一种促进神经传导的物质——内啡肽。这种激素堪称“人体的天然鸦片”，能够有效中和血液中的肾上腺素，从而起到减压的效果。 科学证明，每个人在做自己喜欢做的事情时，体内都会自动分泌内啡肽，所以不要一遇到困难就只会做在那里干着急，不妨先放下手头的工作，做些让自己高兴的事情。不管是动手给自己做上一顿美餐，跟朋友聚会谈心，还是去看一场有趣的话剧，只要是你自己打心底里喜欢的活动，都可以起到相同的作用。 阅读高手在阅读的时候会尽觉少地移动自己的视觉聚焦中心。 正确、深刻理解文章内容是长期记忆的基础。 在关干记忆技巧的书里，我们经常会读到这样的内容： 通过阅读得来的信息，大脑大约能记住10% ； 听来的信息，大约能记往20% ； 从图片或表格中获取的信息，大约能记住30% ； 边听边看的话，大约能记住50% ； 如果在被动接收以后，又向其他人主动讲述过一遍，大约可以记住70% ； 如果经过实际应用，大约能记住90% 。 可是如果这位营销员察觉到了你的心不在焉，他就可以有意地作出一些抬手的动作。正如我们在前文提到的那样，人的视线总是会跟随着移动的物体。那么，只要他随意地抬一抬手，就能将你的眼球引导到左上方或右上方这两个与视觉渠道相连的方向上去，这样一來，你会不知不觉地进入视觉模式，跟随他的描述去想象那辆汽车的各种画面。 尽管我们在接受或表达信息时总会用到这几种不同的感官渠道，但每个人或多或少总会表现出一定的倾向。 所谓自律，就是一种反复完成同一任务的能力。 自律分成三部分：明确目标、坚持不懈和自我控制。 根据波迪安的理论，所谓自制力是指一个人的精神或心理有足够强大的力量，不会被自己的任何一种冲动或肤浅的愿望牵着鼻子走。 他的惊人记忆力主要源于他在阅读和交谈的过程中会自然而然地在脑海里生成相应的图像。 而且，这些图像都极为清晰细致，就像一张张高清照片，他还会给这些照片加上其他的感官刺激，例如周围环境中的声响、自己当时的心理感受、鼻子闻到的气味、嘴巴尝到的味道等。 此外，鲁利亚还发现，谢雷谢夫斯基这种处理信息的方式完全是在潜意识下进行的。他并没有接受过任何系统的训练，只是小时候意外发现了这种做法能让自己记得更淸楚一些，从此便养成了习惯，只要接触到外界信息，他就会自然而然地使用这种方式来处理并且记忆信息。 如果你感觉疲惫不堪，甚至出现腰酸背痛或是头痛的症状，那就说明你的学习方式确实出了问题，你的身体已经不堪重负，表示抗议了。长此以往，你很可能再也找不回那种正常的健康的学习状态了。 请大家想象自己正在热带的某个岛屿上度假，你身穿鲜艳的比基尼，浸在清凉的湖水中，现在，请你朝着湖边的小瀑布游去。—-瀑布练习 其实，我们可以随时随地训练自己的视觉渠道，尤其是在等车或是等人的时候，我们更应该充分利用这些零散的时间，仔细观察一下周围的事物。车站的大幅海报、街对面的某栋大厦都是很好的练习素材。 你可以给自己限定一两分钟的观察时间，看后闭上眼睛，在脑海里尽可能细致地回忆刚才看到的毎一个细节。然后睁开眼睛，稍微比较一下，再闭上眼睛，补充第一次回忆时遗漏的细节，循环往复，直到几分钟后真实的图像与自己的想象完全一致。当脑海中头一次出现一幅清晰的画面时，你一定会感觉到由衷的快乐和满足。 针对阅读时的默念，也是同样的道理，我们既不能完全压抑下意识的默念，也不能从头到尾在心里絮叨个不停。我们可以把默念当成一支无形的荧光笔，只在遇到关键词和重点内容的时候拿出来画上几笔，这样才能在不影响速度的前提下，起到辅助理解和加深记忆的积极作用。 可以说，超短时记忆既负责接收有用的信息，也负责有意识、有目的地将其转化记忆。 完成这个步骤以后，我们的大脑中就形成了一份原始电脉冲的备份，这种临时储存的物质叫做RNA基质蛋白，是短时记忆的物质基础。 由此看来，短时记忆实际上是将信息变为大脑事件储存的内容的一个转化步骤。在这个步骤，信息被第一次过滤，只有有意义的一部分信息才能够通过筛选，变成短时记忆。 这说明，真正的学习理解并非与阅读同步，而是在我们休息的时候完成的。在阅读的同时，我们的大脑不断地接收新的信息，这些信息在脑子里打转，却没有机会与既有的知识网络结合在一起。因此在接收了一定量的信息以后稍作休息，反而能够给大脑留出处理信息的足够时间。 一般来说，连续学习45分钟以后应该站起身来，休息一下。每次休息的时间不必太长，5分钟左右就足够了。 这种劳逸结合的学习节奏还能帮助我们调整自己的心态和精神状态，有效地避免过度疲劳。此外，大家完全不必担心这么频繁的休息会影响注意力，因为如果你没有及时休息，你的大脑也会在潜意识里给自己放假，你的注意力反而集中不起来。 因此，我建议大家在遇到上述情况时不要急着拿起话筒，先稍微回想一下自己手头的工作做到哪一步了，然后再开始处理电话里的事情。 硏究指出，毫无计划的人最多只能完成30%—40%的工作。尤其是那些成天坐在图书馆里的学生，往往一天只有两三个小时的高效学习时间。尽管他们看上去十分勤奋，每天的学习时间高达8个小时，但其中不知道有多少时间是在做白日梦、处理零碎的小事、无所事事地乱看网页和玩电脑。 所谓的时间管理，并不是要一分一秒地计划好你的全部生活，剥夺你的所有自由。时间管理的真正目的在于规划好用于学习和工作的时间，好让你有更多的空闲时间来陪伴家人，享受人生。 那么，现在就让我们一起来看一下设定目标时需要注意的原则： SMART原则： 这5个字母分別代表以下这5个德语单词： Spezifisch（具体specific），Messbar（可衡量Measurable），Anspornend（积极），Realistisch（现实）和Terminierbar（有时间限制）。 而在时间管理这个领域，我们会发现在投入的所有时间中，仅有20%的时间能够带來80%的效益，这是因为我们把80%的时间花在鸡毛蒜皮的小事和无关紧要的问题上。 如果你同时接到许多任务，需要在短时间内整理出头绪，找到工作的切入点，那就先把所有任务都列出来，一一分析其重要性和紧急程度。这个法则被后人统称为“艾森豪威尔法则” 。 A 任务——既重要又紧急的任务；B 任务——重要但不紧急的任务；C任务——紧急但不重要的任务；垃圾任务——既不重要又不紧急的任务。 其实，我们的大脑最擅长根据预先的指令来充分利用时间。 要知道，越是这种一门心思扑在工作上的人，往往越没有工作效率，整个人的情绪也会变得消极，近年来常见的“身心耗竭综合症”（Burn-Out Syndrom）就是过于偏重工作而忽咯了其他两个方面的平衡导致的。 人的睡眠过程是十分奇妙的，尽管我们的身体已经进入休息状态，但潜意识仍然能够继续保存存我们睡觉前接收的信息，自动加以处理，从而在我们不知不觉中加深了对信息的理解和记忆，大大提高了复习效率。 休息质量的关键是睡眠的深浅，而不是具体时间的长短。 当涉及某个具体的学科领域时，由于其中的知识点间存在严密的逻辑关系，所以就不能单纯地死记硬背知识点出现的先后顺序了。但在浏览其他关于学习技巧的书籍时，我发现了作者混淆了这两种信息类型，试图将这种记忆方法应用到学习当中，这是绝对不可取的。—-是这样的。 结果发现，我们在学习知识事的记忆始终建立在两个基本原则之上： 其一是将新信息与既有的知识网络联系在一起，这种思维过程我们称为“联想”； 其二是我们必须充分调动五大感官，完成共感这一步骤。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E8%B6%85%E7%BA%A7%E5%BF%AB%E9%80%9F%E9%98%85%E8%AF%BB%E3%80%8B/"},{"title":"陆奇-数字化未来-摘录","text":"陆奇身上的亮点一、不断学习二、搭建系统： 身体系统 设计一个“马拉松快步跑”的时间管理方法和心态。 第一：要意识到这是一场马拉松，不是一场短跑。 第二：这场马拉松的速度需要很快，因为现实世界中，任何高价值的东西——创业公司、大企业的好岗位等——都会有非常激烈的竞争，你需要保持速度并持续领先。 设计这样一个工作节奏和时间管理方式，很类似在高速公路开车。 陆奇说：“你需要保持一个均匀的高速，然后时不时的加速一下，再回到之前均匀的高速。你要避免过度频繁的加速、减速。就像一辆车，如果一直都是高速前进，只是偶尔减速一下，这对与一辆车的损耗是很低的。但如果一辆车过度频繁的突然加速、减速，会对这辆车带来巨大损耗，不用多久车就可能垮掉。 因此，你需要设计属于你自己的一个工作和生活节奏，这种节奏是你可以保持住的高速，而这个高速可以给你带来最大的效率。同时，你也需要设计这个日程节奏，让它可以应对突发变化，可以时不时的冲刺一下，比如偶尔过度加班让工作在截止日期前完成，然后迅速回归之前的速度。必须避免经常性的透支，经常性的拼命追赶截止日期，经常性的处于疲累状态。身体和精神上偶尔透支可以补回，不可长期透支。” 跑一个高效率、可持续、并且可以应对临时突发状况的马拉松才是关键。 我理解就是做好身体的可持续发展。 家庭系统 找到对的人，互相支持。 人脉系统 双赢思维。双赢是最好的选择 文章摘录陆奇：在未来，究竟哪种职业创造财富的机会最大？ 美国物理学家理查德·费曼说：“如果我没能把某件事建立起来，我就没法理解。”这句话十分重要，它揭示了一种认识世界、观察研究对象的方法：针对任何一个复杂的问题，可以把它进一步拆解为子问题，针对每一个子问题，又继续拆解为子问题的子问题，如此穷尽问题到不能再拆解为止。然后，针对每一个子问题的答案都想好方法测试验证，直至把所有子问题的答案都验证清楚正确了，才能说真正弄明白、搞清楚了最初的问题。这是一种线性思考的方法，可以帮助你把所有问题都探究到本质。这种思考方法已成为我的一种习惯。研究数字化，我也采用这种方法。 数字化是什么？其本质到底是什么？我认为数字化包括六个核心步骤，缺一不可。 第一，获取（Capture）信息。搜集获取某现象的相关信息是数字化的第一步。 第二，表达（Represent）信息。搜集信息后必须把特定信息表达出来，可以用各种形式表达，比如二进制、符号和向量等。 第三，存储（Store）信息。必须把现有信息存储在某个有效的媒体上，纸就是存储信息的一种媒体。 第四，传送（Transmit）信息。在使用信息时，需要对信息进行传递。 第五，处理（Process）信息。这是数字化过程中最为核心的部分，对信息进行处理，通常是利用数学知识或模型通过计算对信息进行处理。 第六，递送（Deliver）信息。这是把处理好的信息传送给某个特定终端，该终端能够达到我们人类所需的目标。 我的这一思考角度深受大卫·克里斯蒂安教授的影响，其实盖茨很早就给我推荐大卫的书籍以及40多个小时的视频，他对盖茨也有很大影响，可惜我一直没有看。他提出了一个简单却视角独特的概念——“大历史”，他认为如果不从物理世界的宇宙起源开始是无法研究人类历史的，我对此深表赞同。他认为，历史的起点在物理世界、化学世界、生物世界。在物理世界里，只有两样东西恒久不变：能量和信息。能量比较容易理解，而信息可以转化为知识。一种有效的可以解决多种任务的表达方法，就是知识，而知识是一种潜在的能量。 举例来说知识为什么是潜在的能量。假定有两个人，他们的任务是搬动一块很大的石头，一个人懂杠杆原理，另一个人不懂。懂得杠杆原理的人用一根木棒很快就可以搬动石头，不懂杠杆原理的这个人就永远搬不动，所以说知识是潜在的能量，这是很重要的一个概念。 宇宙起源理论认为，复杂系统是智能的，它能针对环境的变化而做调整。其智能之处就在于，用能量加信息来减熵。人类是一个复杂系统，人类所做的一切都是减熵行为，基于这一宏大的理论背景，不变的不变就是能源加信息。人类社会就是一个超级复杂的系统，而人类社会的长期驱动力，第一是追求权力，第二是追求财富，第三是追求知识。人类的历史证明，人类永远在追求这三样东西，无论是个人、组织还是国家。 人类社会是由通用技术的发展推进经济的发展，基本上可以划分为三个阶段：农业时代、工业时代，以及我们现在进入的信息和知识经济时代。 农业时代基本上由太阳能驱动，太阳能是人类可以使用的免费能量，基本上只要用劳力就可以，不需要大规模的其他技能。因此，农业时代这条曲线很扁。 工业时代持续发展了300多年，最大的核心驱动其实是化石能源，一开始是煤、汽油，后来变成电，可以输送到任何需要的地方。工业社会主要是化石能源加上人的技能（技能也是一种知识），工业社会有大学，大规模训练培养厨师、裁缝、工程师、律师等具有各种专业技能的人员。因此，工业时代这条曲线开始上扬。 接着人类进入了这条增长最快、最陡峭的曲线，它是由大规模的信息、数字化来驱动的。计算机的发明，使得获取信息、处理信息的能力以惊人的速度高速发展。第三条曲线仍然是以化石能源为主。人们已经知道，化石能源是有时限的，我认为假以时日新的能源结构必然会出现。 可见，当前的数字化大浪潮之所以来势凶猛，会对人类社会产生重大影响，原因正在于此。从宇宙起源开始的大历史发展演化说明，当前的数字化浪潮是历史的必然，势不可当，不可逆转。 过去60多年的历史上，数字化进程一直是由计算平台来驱动的。由于高科技一次又一次突破，平均12年左右会产生出新一代的计算平台。图10.2就充分展现了计算平台演化的发展路径。 第一代是IBM（国际商业机器公司）单板的个人电脑；第二代是微软、苹果的个人电脑，这时的个人电脑有了显示器，同时有局域网；第三代是PC互联网；第四代是移动和云；而我们刚刚进入第五代AI/5G +边缘计算的早期。 在技术方面，“Mobile/Cloud”计算平台也有很多提高。 一方面，硅晶片不一样了，原来是英特尔主导的硅晶片X86，但在移动时代它彻底丧失了机会，现在是ARM（处理器）+ SOC（芯片），加以深度学习为主的计算，相应的操作系统也变了，在此再不赘述，可以参见表10.3。 在此，我想重申构建一个全新聚合信息体系的重要性。纵览欧洲历史，在印刷术发明之前，是教廷掌控一切，信息传送只在教堂之间，也只有教堂才能获得信息。印刷术发明之后，除了教堂，国王、贵族和精英也加入传输信息和获取信息的行业中，信息被贵族控制。从某种意义上说，现代美国依然与此相差不远，信息被精英控制。随着数字化的深入与扩展，精英对信息的控制被彻底打破了，搜索引擎是打破精英控制信息的第一步，随之而来的社交平台比搜索引擎走得更远。 在这个信息聚合体系底层的是“数字化基底”（Digital Substrate），这是一个集成的数据系统，无论是某个搜索引擎，还是某个社交平台，其信息架构都是这样的。重点在于这是一个公开的信息架构，它清楚地勾勒出某个社会现象的数字化流程和闭环结构。只有形成闭环的社会现象，才能具备自动自我迭代、进化演变的智能能力。其内在一定有以下几个子系统。 第一个子系统是观察系统，观察世界或人的行为，获得信息。第二个子系统是智能系统，把获取的数据进行表达、存储、做模型计算（处理），最后进行传输。第三个子系统是动作系统，负责与用户或环境（物理世界）进行互动。第四个子系统是运营系统，由人，也就是这个系统的作者通过运营系统来维护、更新这样一个数字化的生态体系。 图10.3是对这一信息体系结构的形象化的展现，勾勒出数字世界与物理世界的系统性融合，彼此交织，密不可分。其中有四个子系统，第一是动作系统，用户在体验终端上使用App获得信息，用户行为被数字化了，这些数字化行为信息到系统后，进行数据处理，传送到智能子系统，在这个智能子系统中，这些接收到的信息被表达出来，接着用机器学习的算法来建模，同时记忆和存储。有了这些模型（就是知识）之后，再把这些知识传送给客户，与此同时，用户也可以跟其所处的世界进行互动。最终还有一个运营系统，以搜索引擎为例，这个系统就是谷歌，谷歌里面有开发人员、销售人员、市场人员、客服人员，谷歌持续不断地去更改搜索引擎的代码。 图10.3中的虚线矩阵框围住的上半部分是物理世界，实线矩阵框围住的下半部分是数字世界，数字世界和物理世界越来越重叠，无法完全分开。特别要强调的是，“流入”是把原子变成二进制的数字，也就是把物理世界变成数字，“流出”是把数字变成物理世界的看得到、摸得到的原子，建立了一个反馈闭环来产出数字世界里关于该社会现象的知识，进而帮助到物理世界里的人。 最重要的是，这是一个通用的结构，任何一个社会现象的大规模数字化都永远适用于这个信息聚合体系，它是物理世界和数字化世界融为一体的核心界面和核心信息架构。有了这样的架构之后，人类可以更好地理解并管理数字化的进程，让数字化真正服务于人类。 在此，简单分析几个案例，说明这一信息架构是如何运转的。 第一个案例是互联网与搜索引擎。 搜索引擎的世界就是万维网，通过爬虫抓取很多关键信息，用户输入关键词、点击搜索页面结果，这些行为被数字化。在智能系统部分，核心是要做搜索结果的排序、一系列的建模等，形成一个反馈的闭环。图10.4是搜索引擎的数字基底结构图。 重点讲解搜索引擎的几个核心计算。第一，要核心计算信息主题性。它要计算出每个网页是关于什么内容的。第二，要计算信息的质量。第三，要计算信息的可信度。信息有文字、图片甚至视频等多种类别，需要不同的计算模型。 除了对信息（搜索对象）进行计算，还要对用户意图进行计算。用户输入某个关键词究竟代表的需求是什么，想要做什么？那搜索引擎知道什么呢？它知道的东西太多了，知道世界上人的需求、兴趣，知道信息的供给、信息的获取。我曾经是一名搜索引擎工程师，当时就觉得世界上无数的人，每天在向你倾诉他想要什么、需要什么。其实，每个人在生活里都有一些所谓不可说的秘密，不会跟任何人说，即使对最亲密的妻子、爱人、亲人也都不会说，但是你会跟搜索引擎讲，因为你想找信息。搜索引擎开启了一个非常神奇的数字化世界，它无所不知，它所累积的大数据，可以说描绘了社会的全貌。 第二个案例是以优步、滴滴、Grab5（租车服务供应商）和Lyft6（来福车）为代表的城市交通。 这也是典型的数字世界和物理世界融合的案例，其核心要做的是获取乘客、司机的位置，然后计算每段行程需要多长时间，再用经济学和计算机科学综合测算定价，当然现在也把评判行程安全系数纳入计算范围，总之这些都是通过数字化的方法来进行预估的。个中细节我不再赘述，详情可以参考图10.5。 特别想指出的是，从长期来看，这样打通数字世界和物理世界的公司十分有前景。原因何在？优步和滴滴这样的企业拥有太多信息数据，知道什么时候、什么日期有这样的人会从这里到这些商店、那些医院，全面掌握了非常多的社会经济行为信息，据此可以做很多推理，衍生出很多业务，它们完全可以做大生态的生意。 之所以会提出这个构想，也与我自己在微软的工作经历分不开，我曾花了几年时间主导设计了微软的Office 365（办公软件），它的核心后端其实就是这样一个体系。在评判任何一个企业前景的时候，都要洞悉其本质数字化了什么，了解其核心是如何把物理世界和数字世界连接融合在一起的。 正如此前所说，这是一个通用的结构，诸如信息推荐、社交平台、零售、教育、医疗、人的身体，抑或微生物世界里的客体，微小到纳米级，或是更大的物体，都可以被数字化，每个城市、每个国家、天气甚至整个地球也都可以被数字化，用上述的体系来数字化。 数字化未来谈到数字化未来，我有以下几点看法。 第一，人工智能早期和近期主要落地的应用是在工业垂直领域。其数字化的趋势是往下沉的，通过传感器可以把纺织业、农业、鱼塘、医院、工厂都数字化，高概率都是往垂直的方向发展的。而人工智能贯通多个行业领域的横向应用则还需要时间。无人驾驶有望建立一个新的社会基础，是人工智能横向发展的典型应用。另一个横向发展的机会，则是把每个空间、每个场所都智能化（数字化）。 第二，前端数字化也还有一些机会，诸如AR（增强现实）和VR（虚拟现实）。从长期看，脑机接口是一个比较重要的机会。如果可以通过植入的方法在人脑的皮层后植入观察体系，那数据的获取和交互会完全不一样，所以从数字化的能力角度来讲，这也很有机会。 第三，计算的基石是算法。人类历史上所有的科学，包括传统的物理学或狭义相对论，基本上都有商业的应用。只有量子是尚未被商用的科学，前面提到的理查德·费曼教授在50多年前提出的理论，奠定了量子计算的基础。在算法领域，量子计算有很大的突破机会。而Crypto（加密模块）是一种不同的计算方法，把信任用数字化的形式表达出来。同时还有生物形态的算法，用DNA的方法或者用合成生物学的方法来测算。 第四，我个人非常关注的是能源。一如最初讲到人类社会发展的核心驱动力就是能源和信息，如果能源结构发生改变，其引发的变革效果也必将是划时代的。在能源领域，也有不少机会。 第五，空间的探索与扩展，仅仅在地球上远远不够，要走得远一些。YC（美国著名创业孵化器）就投资了不少致力于拓展地球之外空间的企业。 从信息化的角度来看，一位人人可得的数字化个人助理会逐步被创建，微软特别有可能实现这一点。这很重要，世界将因此变得更公平。现在只有富人、有钱人才可以有助理，将来每个人都可以有一个万能的助理，这也意味着有很多前景。 采访问答Q：对人工智能，这个世界上有两大阵营在争论。一方认为现在的人工智能是专用人工智能，如果它走向通用人工智能，会有一个奇点，一旦走到奇点的话机器会超过人，人变成什么就不知道了。而另一方认为世界上没有通用人工智能，而奇点不会出现，是因为到现在为止，人工智能只能做关联分析推理，还不能做因果推理，也就是说，目前的人工智能只是模拟人的右脑，还不能够模拟左脑。 A：人工智能目前以深度学习为主，而通用人工智能发展的难点主要指的就是推理。 Q：如果没有推理，怎样能够让机器比人厉害？您觉得这是有可能的吗？ A：我觉得从技术开发上来讲，有一个蛮长的过程，但我认为机器超越人类是有可能的。今天的深度学习基本上是向量，向量是表达人的大脑神经元激活的最简单的数据化方式，人的思想就是大脑神经元不断激活的结果，数学上就是用向量来表达。但人脑是可以处理符号的（有实验证据证明），但在这些向量上无法直接做符号处理，因此机器不能做逻辑推理。 在离开微软之前，我花了不少精力为微软从约翰·霍普金斯大学挖了一个人叫Paul Smolensky（保罗·斯莫伦斯基），他花了30年时间研究发声学。这与发声学有什么关系呢？“发声”很核心的一点就是把思想讲给对方听，其实思想是一大堆神经在激活，但表达出来的是符号，只不过是用声音振荡的频率将符号传送给对方。 所以，思想从向量变成符号的过程可以在“发声”过程中被观察到。他做了一整套数学理论，基本上是张量的乘积，真正要工程化非常难，但数学上已经可以成立了。 Q：这从根本上就是看我们对人脑认识的深刻程度，实现通用人工智能显然差距还很远，但是您讲到了一系列有趣的概念，您看好脑机接口，那脑机接口之后是机器管人，还是人管机器，人变成了什么？ A：首先人还是人。 Q：人还是人的定义是什么，是因为他有智慧，有人的道德、善良，还是什么？比如机器在哪些方面可以超过人，人还是人这句话怎么讲？请您定义一下人是什么？ A：我尝试回答一下。“人”这个命题，可以从哲学角度讨论，从人为学的角度讨论，我可能是纯粹从认知科学、系统角度定义的，这样的话，人是“生物表达形态的一个系统”，人的系统里有三个组成部分［感知体系、思考体系、行动体系（如手臂和腿）］。 人有一个信息框架，这是认知科学要做的，就是人是如何处理信息的，基于这样的定义，脑机接口比较简单，就是增加一个交互接口。今天的脑机接口第一个应用是让彻底瘫痪的人，虽然手和脚都不能用了，但可以用思想来控制指挥。 还有一个应用就是做广告预测，今天脑机接口有两种（植入方法、戴的设备）。 戴的设备也可以测试到不少信号，比如你要做一个电视广告，其实很难衡量看了这个电视广告后用户有什么样的反应，于是让20个人戴上脑机接口的设备，然后再给他们看广告，就会很方便地获得他们对这个广告的真实反应。这些感受，甚至观众本人都未必能讲清楚。所以，穿戴的脑机接口早期应用已经找到了，比如广告的选择与优化。因为植入的脑机接口还不成熟，有许多问题需要解决，所以需要在老鼠身上进一步做实验。 Q：所以还不是改变人，而是能更好地理解人，或帮助人。 A：帮助人来做更多的事。 Q：这个有意义，您说把原子转化成数字，但是原子本身没有变化，只是观察到了这样一个数字。您能不能确保我观察到转成的这个数字真的是原子，就是事情的真相呢？ A：我估计您问的可能是量子力学方面的。 Q：包括测不准定律。 A：量子力学系统确实有物理试验证明，观察和被观察是分不开的，我这里是假设在量子力学之上，观察和被观察是可以分开的，对于今天大部分的科学我们都可以客观地观察一个被观察的东西。 Q：都是在量子之上的。 A：量子之内，我觉得这套结构不适合。 Q：您说最后是能源变了，现在都说数据是新能源，我们其实把物质和能源看成了两个不同的概念，能源是个驱动力。 A：我想进一步讲一下。计算机科学对世界的描述其实不够完整，要真正做好必须是计算机科学加上经济学家。比如，今天的广告体系，一般开发团队里一定有一位优秀的经济学家。 回到能源和信息，这里很重要的一个底层逻辑是世界只有能源和信息，没有别的东西了，但信息可以变成知识，知识就是潜在的能源。比如有两个人，一个人懂杠杆原理，一个人不懂，他需要搬一个大石头，不懂杠杆原理的人就没办法，知识就是能源，懂的人能量就大。 核心在于，人类社会是一个复杂体系，用能源和信息不断减熵。信息是潜在的能源。在农业时代，太阳能是免费能源，所以人基本上不需要做太多东西，就是种种地。在工业时代，使用了化石能源，产生了电，这就需要人的技能了，有裁缝、厨师、律师等各个领域的人。到智能数字化时代后，计算技术的发明使人类获取信息以及从信息当中抽取知识的能力大大提高，所以图10.1中的第三条曲线是高速发展即最为陡峭的。今天市值最大的上市公司都在这条曲线上，如果创业，也一定要在这条最陡峭的曲线上。 今天，确实历史上很少有的各种因素都聚在一起，是挑战也是机会。众所周知，化石能源有时间限制，不久以后将被消耗殆尽，所以必须要用新能源来替代，至于究竟是氢能还是核能，这还有赖于将来的探索。总之，对于整个人类社会，信息和能源是最重要的两大驱动力。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E9%99%86%E5%A5%87-%E6%95%B0%E5%AD%97%E5%8C%96%E6%9C%AA%E6%9D%A5-%E6%91%98%E5%BD%95/"},{"title":"《高效能人士的七个习惯》","text":"变化的世界，不变的原则。————因为人还是人。 我对生命的一种最深刻的感悟就是：要完成最渴望的目标，战胜最艰巨的挑战，你必须发掘并应用一些原则或自然法则，因为它们恰好左右着你苦苦期待的成功。 《高效能认识的七个习惯》最重要的方面是强调“塑造性格”而不是“实现成功”，因此本书不仅实用而且深刻。 现代社会，太多的人饱受恐惧感的折磨。他们恐惧将来，恐惧失业，恐惧无力养家。这种弱点，常常助长了一种倾向：无论在工作时，还是回到家中，都倾向于零风险的生活，并逃避与他人互相依赖和合作。面对这种问题，我们的文化通常会教导人们要独立、独立、再独立。“我要专注于‘我和我的’，我要工作，要好好工作，要通过工作获得真正的快乐。”独立是一种重要的，甚至带有决定性的价值观和成就观，而我们生活在一个互赖的社会中，最辉煌的成就要靠互赖和合作才能成就，远远不是个人能力可企及的。 谴责周围人和事的必然结果是变成犬儒主义，绝望无助。当我们最后向命运低头，认为自己是环境的牺牲品，屈服于宿命论带来的厄运时，我们就丢弃了希望，抛却了理想，习惯了听天由命，选择了停滞不前。 现代社会，资讯发展一日千里，生活日益复杂多元，对人要求更为苛刻，让人感觉更加紧迫和心力交瘁。尽管我们付出良多，尽量有效地利用时间，努力工作，积极进取，并利用现代科技不断提高效率，然而让人不解的是，我们越来越陷在一些鸡毛蒜皮的小事上不能自拔，而把健康、家庭、品德以及许多重要的事情放在了工作之后，舍本逐末。我们不能把问题归咎于工作，或社会的复杂和变迁，而在于我们的流行文化提倡：“早来，晚走，高效，从现在起就要懂得牺牲”——可事实上，心灵的平和宁静远非这些技巧所能带来的，而是取决于人们是否明白什么是最重要的事情，是否懂得轻重缓急，并能抓住生活的重点，客观地面对现实。 在知识时代，千载难逢的机遇和卓越的成就，通常是留给那些深谙什么是“我们”————团队精神————的人们。真正的大视野，通常只会由思维开阔、内涵丰富的头脑，经由忘我的合作精神————互敬和双赢————取得。 谁也无法说服他人改变，因为我们每个人都守着一扇只能从内开启的改变之门，不论动之以情或说之以理，我们都不能替别人开门。 凡是秉持自己的信念而活，就能产生自尊自重与自制力，并且内心平和。你会以内在的价值标准，而不是旁人的好恶或与别人比较的结果，来衡量自己。 不论你的现况如何，都请相信你与你的习惯是两码事，你有能力改变不良旧习，代之以意味着高效、幸福和互信的人际关系的新习惯。 当我们舍弃回答心，改以了解心去聆听别人，便能开启真正的沟通，增进彼此关系。对方获得了解后，会觉得受到尊重与认可，进而卸下心防，坦然而谈，双方对彼此的了解也就更流畅自然。知彼需要仁慈心；解己需要勇气，能平衡两者，则可大幅提升沟通的效率。 每个人的思维定式都是那么根深蒂固，仅仅研究世界是不够的，还要研究我们看世界时所戴的“透镜”，因为这透镜（即思维定式）往往走有着我们对世界的看法。 我们决定从自身下功夫，不再研究技巧，而是着重调整内心的真正动机和对孩子的看法。我们不再设法改变他，转而从客观的角度去发现和了解他的特色、个性与价值。另一方面，我们也自觉地改变了自己的动机，培育了内在的安全感，不再用孩子的表现来判断自己的价值。 从教育儿子的经验、对人们认知过程的研究以及成功论著的阅读中，我顿悟了品德的强大影响力，也认清了自己从小所学并且深植于心的价值观，其实与现在流行的追求捷径的速成哲学相去甚远，而这种差异经常被有意地忽略。 归根到底，我们的本质要比言行更具说服力，这个道理人人都懂。有些人是我们绝对信任的，因为我们了解他的品德，不论他是否能说会道、擅长交际，我们就是信任他们，而且能够与之合作顺畅。William George Jordan 曾说：人性可善可恶，冥冥中影响着我们的一生，而且总是如实反映出真正的自我，那是伪装不来的。 我们每个人脑中都有很多地图，可以分成两大类：一类是依据世界本来面目绘制的地图，反映现实情况；另一类是依据思维定式绘制的地图，反映个人价值观。我们用这些地图诠释所有的经验，从来都不怀疑地图的正确性，甚至意识不到它们的存在。我们理所应当地假定自己的所见所闻就是真实的世界。 以前我们总以为只有自己清楚而客观地看到了事物的本质，但这个实验却让我们开始认识到，别人的观点虽然有异，但也是清楚而客观的。 我们越是认识到思维定式、地图或者假定以及经验在我们身上的影响力，就越是能够对自己的思维定式负责，懂得审视它，在现实中检测它，并乐于聆听和接受别人的看法，从而获得更广阔的视野和更客观的看法。————换位思考的能力 看清事实是我们的日常生活中是极其关键的一环。 一个人的思维定式或者地图越符合这些原则或者自然法则（道的层次），就越多能正确而高效的生活。比起为改变态度和行为所做出的努力，正确的地图对于个人和人际关系效能的影响要大得多。 个人魅力论————他们了解的只是别人期望中的自己。 与配偶、子女、朋友或同事相处一定要学会聆听，这需要情感力量的支撑。聆听需要耐心、坦诚和理解对方的愿望，属于品德的高级范畴。相较之下，以低投入的情感给出“高高在上”的建议要容易得多。 一旦孩子体会到了真正拥有的感觉，自然会乐于与他人分享。 教导孩子也要因时制宜，在关系和气氛紧张的时候，教导会被视为一种评判与否定；关系融洽的时候，在私下里对孩子循循善诱效果会加倍。 或许只有真正经历过拥有，才会真正懂得分享。许多人在家庭或婚姻中只知机械式地付出，或者拒绝付出和分享，可能正是由于他们从未体验过拥有，而且缺乏自我认同和自尊。所以教育孩子应该要有充分的耐心让他们体会拥有的感觉，同时用足够的智慧告诉他们付出的价值，另外还要以身作则。 以原则为中心，以品德为基础，要求“由内而外”地实现个人效能和人际效能。 如果你想拥有美满的婚姻，那么就做一个能产生助力而非阻力的人，不要一味强求对方。 我们必不可停止探索，而一切探索的尽头，就是重回起点，并对起点有首次般的了解。 为人和观念的改变是螺旋式向上的过程——为人改变观念，观念反过来改变为人，如此反复循环，螺旋式向上成长。通过在知识、技巧与意愿三方面的努力，我们可以突破多年思维定式的伪保护，使个人和人际关系效能都更上一层楼。 由依赖到独立，再到互赖。 生理上独立的人可以自食其力；智力上独立的人可以有自己的思想，兼具想象、思考、创造、分析、组织与表达的能力；情感上独立的人信心十足，能自我管理，不因他人好恶而影响自我价值评价。 互赖是一个更为成熟和高级的概念。生理上互赖的人，可以自力更生，但也明白合作会比单干更有成效；情感上互赖的人，能充分认识自己的价值，但也知道爱心、关怀以及付出的必要性；智力上互赖的人懂得取人之长，补己之短。 一个能做到互赖的人，既能与人深入交流自己的想法，也能看到他人的智慧和潜力。 但只有独立的人才能选择互赖，尚未摆脱依赖性的人则无此条件，因为他们无论在品德还是在自我把握方面都尚有欠缺。 唯有在金蛋（产出）与鹅的健康和幸福（产能）之间取得平衡，才能实现真正的效能。虽然你常会因此面临两难选择，但这正是效能原则的精髓所在。它是短期利益与长期目标之间的平衡，是好分数与刻苦努力之间的平衡，是清洁的房间与良好的亲子关系之间的平衡。 在刺激与回应之间，人有选择的自由。 选择的自由包括人类特有的四种天赋。除自我意识外，我们还拥有“想象力（Imagination）”，即超越当前现实而在头脑中进行创造的能力；“良知（Conscience）”，即明辨是非，坚持行为原则，判断思想、言行正确与否的能力；“独立意志（Independent Will）”，即基于自我意识、不受外力影响而自行其是的能力。 积极主动是人类的天性，即使生活受到了外界条件的制约，那也是因为我们有意或无意地选择了被外界条件控制，这种选择成为消极被动。这样的人很容易被自然天气做影响，比如风和日丽的时候就兴高采烈；阴云密布的时候就无精打采。而积极主动的人则心中自有一片天地，无论天气是阴雨绵绵还是晴空万里，都不会对他们产生影响，只有自己的价值观才是关键因素，如果认定了工作第一，那么即使天气再坏，敬业精神依旧不改。 消极被动的人还会受到“社会天气”的影响。别人以礼相待，他们就笑脸相迎，反之则摆出一副自我守护的姿态。心情好坏全都取决于他人的言行，任由别人的弱点控制自己。 积极主动的人理智胜于冲动，他们能够慎重思考，选定价值观并将其作为自己行为的内在动力；而消极被动的人则截然相反，他们感情用事，易受环境或条件作用的驱使。但这并不意味着积极主动的人对外界刺激毫无感应，只不过他们会有意无意地根据自己的价值观来选择对外界物质、心理与社会刺激的回应方式。 伤害我们的并非悲惨遭遇本身，而是我们对于悲惨遭遇的回应。 采取主动是实现人生产能与产出平衡的必要条件，对于培养七个习惯来说也不例外。本书的其余六个习惯，都以积极主动为根基，而每个习惯又都会激励你采取主动，但是如果你甘于被动，就会受制于人，面临截然不同的发展与机遇。 我们有能力以积极态度应对现状和未来。 在所有进步的社会中，爱都是代表动作，但消极被动的人却把爱当做一种感觉。好莱坞式的电影就常灌输这种不必为爱负责的观念————因为爱只是感觉，没有感觉，便没有爱。事实上，任由感觉左右行为是不负责任的做法。积极主动的人则以实际行动来表现爱。就像母亲忍受痛苦，把新生命带至人世，爱是牺牲奉献，不求回报。又好像父母爱护子女，无微不至，爱必须通过行动来实现，爱的感觉由此而生。 把外在环境视作问题症结的想法本身就成问题，应该说是我们给了外部环境控制自己的权力，这种“由外而内”求变的思维定式就是以外在环境改变作为个人改变的先决条件。 积极的做法应该是“由内而外”地改变，即先改变个人行为，让自己变得更充实，更具创造力，然后再去施加影响，改变环境。 满意源自内心，那些对人性一无所知的人总是妄图在维持自我的前提下追求幸福，结果必是徒劳无功，而本来想摆脱的痛苦却会与日俱增。 和内在力量相比，身外之物显得微不足道。 虽然以始为终适用于不同的环境和生活层面，但最基本的应用，还是应该从现在开始，以你的人生目标作为衡量一切的标准，你的一言一行，一举一动，无论发生在何时，都必须遵循这一原则，即由个人最重视的期许或价值观来决定一切。牢记自己的目标或者使命，就能确信日常的所作所为是否与之南辕北辙，而且每天都向着这个目标努力，不敢懈怠。 “以终为始”的一个原则基础是“任何事都是两次创造而成”。我们做任何事都是先在头脑中构思，即智力上的或第一次的创造（Mental/First Creation），然后付诸实践，即体力上的或第二次的创造（Physical/Second Creation）。 管理是正确地做事，领导则是做正确的事。管理是有效地顺着成功的梯子往上爬，领导则判断这个梯子是否搭在正确的墙上。 再成功的管理也无法弥补领导的失败，而领导难就难在常常陷于管理的思维定式而难以自拔。 休太长的假，看太多的电影或电视，打太多的电子游戏，长期无所事事，都等于浪费生命，无益于增长智慧，激发潜能，增进安全感或指引人生，只不过制造更多的空虚而已。 首先，这是主动的选择，没有受到环境或他人的影响，是通盘考虑后选择的最佳方案，是有意识的明智选择。 最后，对自己的选择胸有成竹，无论结果怎样，都能专注于此，并且心安理得，无所牵挂。 以原则为生活中心的人总是见解不凡，思想与行为也独具一格，而坚实、稳定的内在核心赐予他们高度安全感、人生方向、智慧与力量，会让他们度过积极而充实的一生。 其实不是你询问生命的意义何在，而是生命正提出质疑，要求你回答存在的意义为何。换言之，人必须对自己的生命负责。 事实上，有效的个人领导、心灵演练和确认方法都源于对人生目标和原则的深思熟虑，并在改写人生剧本，深入理解人生目标和基本原则方面有无穷力量。我相信所有久经考验的宗教的核心也是这些原则和实践，只是名称稍有出入，比如静坐、祈祷、圣餐礼、神圣十月、经文研究等，都与良知和想象力有关。尽管心灵演练威力无穷，但也必须以品德和原则，而不是以性格魅力为基础才行，否则就会被误用或滥用，尤其容易被用来谋取个人名利。 有效管理是掌握重点式的管理，它把最重要的事放在第一位。由领导（人生目标、原则）决定什么是重点后，再靠自制力来掌握重点，时刻把它们放在第一位，以免被感觉、情绪或冲动所左右。 要牢记管理与领导迥然不同。从本质上说，领导是一种高效率的右脑型活动，常被人们成为一门艺术，其基础是一种哲学理念。如果你需要解决一些个人领导方面的问题，通常都要先自问一些人生最本质的问题。一旦确定了人生方向，你就应该对自己进行有效的管理，让生活与设想一致。相对于自我领导来说，有效的自我管理所涉及的大都是左脑所擅长的能力：分解、分析、排序，具体运用以及在规定时间内完成任务等。关于提高个人效能的方法，我总结出一句话：左脑进行管理，右脑进行领导。 除了自我意识、想象力和良知之外，想要真正实现成功的自我管理，就必须发挥人类的第四大天赋————独立意志。独立意志指的是做出决定和主动选择，并根据这些决定和选择采取具体行动的能力。有了独立意志，我们就可以主动作为，而不是被动听命，而且在发挥其他三大天赋拟定出计划之后，就能够积极实施这些计划。 因为重要，才会使生活大为改观，却因为不够紧迫，所以受到忽略。但是只要我们立即着手进行，效能变回大为增进。 以配偶或金钱、朋友、享乐等为重心，容易受第一与第三类事务羁绊。至于自我中心者难免被情绪冲动所误导，陷溺于能博人好感的第三类活动，以及可逃避现实的第四类事务。这些诱惑往往不是独立意志所能客服，只有发乎志诚的信念与目标，才能够产生坚定说“不”的勇气。 以第二类事物为生活中心的时间管理方法只有一个目标，那就是有效地管理生活。这需要我们有完善的原则，对个人使命有明确的认识，能兼顾重要的和紧迫的事情，能平衡产出和产能的关系。 让第二类事务成为生活中心的有效工具必须满足以下六个重要标准： 和谐一致 个人的理想与使命、角色与目标、工作重点与计划、欲望与自制之间，应和谐一致。 平衡功能 管理方法应有助于生活平衡发展，提醒我们扮演不同的角色，以免忽略了健康、家庭、个人发展等重要的人生层面。有人以为某方面的成功可补偿他方面的遗憾，但那终非长久之计。难道成功的事业可以弥补破碎的婚姻、孱弱的身体或性格上的缺失？ 围绕中心 理想的管理方法会鼓励并协助你，着重虽不紧迫却极重要的事。我认为，最有效的方法是以一星期为单位制订计划。一周7天中，每天各有不同的优先目标，但基本上7天一体，相互呼应。如此安排人生，秘诀在于不要就日程表订立优先顺序，应就事件本身的重要性来安排行事历。 以人为本 个人管理的重点在人，不在事。行事固然要讲求效率，但以原则为中心的人更重视人际关系的得失。因此有效的个人管理偶尔须牺牲效率，迁就人的因素。毕竟日程表的目的在于协助工作推行，并不是要让我们为进度落后而产生内疚感。 灵活变通 管理方法并非一成不变，视个人作风与需要而调整。 便于携带 管理工具必须便于携带，随时可供参考修正。 充分认可他人的自我意识、想象力、良知以及独立意志。 所谓情感账户，储存的是增进人际关系不可或缺的“信赖”，也就是他人与你相处时的一分“安全感”。能够增加情感账户存款的，是礼貌、诚实、仁慈与信用。反之，粗鲁、轻蔑、威逼与失信等等，会降低情感账户的余额，到最后甚至透支，人际关系就要拉警报了。 维系人与人之间的情谊，最要紧的不在于言语或行为，而在于本性。言不由衷、虚伪造作的表面功夫很快就会被识破，何以建立圆满的互赖关系？由此可见，修身是公众成功的基础，完成修身的功夫后，再向前看，面前又是一片崭新的领域。良好的互赖关系可以使人享有深厚丰富的情感交流，不断跃进的成长以及为社会服务奉献的机会。 越是持久的关系，越需要不断的储蓄。由于彼此都有所期待，原有的信赖很容易枯竭。 速战速决是不切实际的，建立和维护关系都需要时间。如果因为他反应冷淡或者不以为然就不耐烦起来，那就是前功尽弃。 建立并维持人际关系是一种长期的投资行为。 如果你重视一个人，那么必须同样重视他所重视的事情。 很多人都倾向于主观臆断他人的想法和需要，觉得在自己身上适用的感情投资，一定也适用于他人。一旦发现结果并不如自己所期望的那样，就会觉得自己一片好意成了空，变得心灰意冷起来。 如果你希望别人了解你的实际需要，首先要了解他们每一个人的实际需要，然后据此给与帮助和支持。 人的内心都是极其柔弱和敏感的，不分年龄和资历。哪怕是咋最坚强和冷漠的外表下，也往往隐藏着一颗脆弱的心。 很多期望都是含蓄的，从来没有明白地说出来过，但是人们却想当然地认为这些事是心照不宣的。实际情况并非如此。如果没有明确的期望，人们就会变得感情用事，原本简单的小误会也会变得很复杂，原本很小的事情也会导致严重的冲突和人身攻击，最终不欢而散。 绝不在背后攻击他人。 弱者才会残忍，只有强者懂得温柔。 在互赖关系中，问题就代表机会————增加情感账户存款的机会。 双赢者把生活看作一个合作的舞台，而不是一个角斗场。一般人看事情多用二分法：非强即弱，非胜即败。实际上这种想法是站不住脚的，它以力量和地位，而非原则为准绳。其实世界之大，人人都有足够的立足空间，他人之得不必就视为自己之失。 一旦爱被附加条件，孩子们就会认为自我价值只有通过比较和竞争才能实现。 成熟就是在表达自己的情感和信念的同时又能体谅他人的想法和感受的能力。 敢作敢为和善解人意是双赢的必备条件，其间的平衡点是成熟的重要标志。如果我足够成熟，我就会乐于聆听，善于沟通并勇于面对。 一般人都会担心有所匮乏，认为世界如同一块大饼，并非人人得而食之。假如别人多抢走一块，自己就会吃亏，人生仿佛一场零和游戏。难怪俗语说：“共患难易，共富贵难。”见不得别人好，甚至对至亲好友的成就也会眼红，这都是“匮乏心态”（Scarcity Mentality）作祟。 抱持这种心态的人，甚至希望与自己有利害关系的人小灾小难不断，疲于应付，无法安心竞争。他们时时不忘与人比较，认定别人的成功等于自身的失败。纵使表面上虚情假意地赞许，内心却妒恨不已，惟独占有能够使他们肯定自己。他们又希望四周环境的都是唯命是从的人，不同的意见则被视为叛逆、异端。 相形之下，富足的心态源自厚实的个人价值观与安全感。 公众领域的成功的意思不是压倒旁人，而是通过成功的有效交往让所有参与者获利，大家一起工作，一起探讨，一起实现单枪匹马无法完成的理想，这种成功要以知足心态为基础。 双赢的精髓就是信用，即情感账户。 首先寻求去了解对方，然后再争取让对方了解自己。 大部分人在聆听时并不是想理解对方，而是为了做出回应。这种人要么说话，要么准备说话，不断地用自己的模式过滤一切，用自己的经历理解别人的生活。 移情聆听是指以理解为目的的聆听，要求听者站在说话者的角度理解他们的思维模式和感受。移情聆听的本质不是要你赞同对方，而是要在情感和理智上充分而深入地理解对方。聆听是为了理解，是心和心得深刻交流。移情聆听本身就是巨额的感情投资，它能够给人提供一种“心理空气”，极具治疗作用。 除了物质，人类最大的生存需求源自心理，即被人理解、肯定、认可和欣赏。你的移情聆听等于是给了对方“心理空气”，满足了对方这个基本需求后，你就可以着重于施加影响力和解决问题了。 当你学习认真倾听时，你会发现自己对别人的感知有了天壤之别。人们在互相依靠的环境中时，这种差别将带来极大影响。你看到的画像可能是少妇，我看到的是老妇，但是我们都没错。你可能以配偶为中心，我则以金钱为中心。你的精神世界丰富多彩，我的则是一片荒芜。你看待问题的角度也许高度形象、有整体性和感情色彩，是典型的右脑思维；而我则是逻辑性强、善于分析和表达的左脑思维。我们感知会非常不同，而且从小便有自己的思维方式，理所当然地认定某些事实，当别人不这么认为时，就会质疑他人的性格或者精神状态。 读了这本书才发现，我从未真正聆听你说话，但今后会尽力而为，可能起初不能做得很好，希望你助我一臂之力。 在了解别人的过程中，你也会产生新的见解。 你越深入了解别人，就会越欣赏和尊敬他们。触及对方的灵魂是一件很神圣的事情。 我们还模拟家中可能发生的摩擦，通过设身处地的倾听技巧，预设有效的处理方式。通常我扮演儿子或女儿，桑德拉则扮演母亲。通过着这样的交流方式，我们不但能够发现事情的真相，还学到很多东西，让我们能够继续作为榜样，向孩子们传授正确的原则。对于曾经处理不当的问题和事件，我们也会用这种方式重演，结果让我们受益匪浅。 先理解别人。在问题出现之前，在评估和判断之前，在你表达个人观点之前，先理解别人，这是有效的相互依赖关系中最有用的习惯。 综合综效的基本心态是：如果一位具有相当聪明才智的人跟我意见不同，那么对方的主张必定有我尚未体会的奥妙，值得加以了解。与人合作最重要的是，重视不同个体的不同心理、情绪与智能，以及个人眼中所见到的不同世界。与所见略同的人沟通，益处不大，要有分歧才有收获。 缺乏安全感的人认为所有的人和事都应该依照他们的模式。他们总想利用克隆技术，以自己的思想改造别人。他们不知道人际关系最可贵的地方就是能接触到不同的模式。相同不是统一，一致也不等于团结，统一和团结意味着互补，而不是相同。相同毫无创造性可言，而且沉闷乏味。综合综效的精髓就是尊重差异。 一个偏重于语言和逻辑的惯用左脑思维的人会发现自己在面对要求极高创造力的问题时常常无能为力，于是开始醒悟，并调动右脑来接受新的模式。我并不是说他们原来没有右脑，而是说那时候右脑正在休眠，尽管细胞还在，但可能已经萎缩，因为从他们小时候起，接受的所有学校教育和社会教育就只偏重左脑的发展。 右脑主管直觉、创造和印象，左脑主管分析、逻辑和语言，只有左右贯通，整个大脑才能发挥作用。 人生最值得的投资就是磨炼自己，因为生活与服务人群都得靠自己，这是最珍贵的工具。工作本身并不能带来经济上的安全感，具备良好的思考、学习、创造与适应能力，才能立于不败之地。拥有财富，并不代表经济独立，拥有创造财富的能力才真正可靠。 身体层面：健康饮食，充足休息以及定期锻炼 耐力：源于有氧运动————快走、跑步、骑车、游泳、越野、滑雪 韧性：源于伸展运动———— 跑前拉伸、慢慢停止、跑后拉伸 力量：源于持久的肌肉运动————需要柔软体操，即拉伸 锻炼的所有好处几乎都产生于最后阶段。想增强力量，就必须等到肌肉纤维断裂，神经纤维感到疼痛才行，因为这时候自然机制才会予以过渡补偿，纤维在 48 小时后会变得更加坚韧。 精神层面是人的本质、核心和对价值体系的坚持，是生活中非常私人而又至关重要的领域。它能够调用人体内具有激励和鼓舞作用的资源，把你同所有人类的永恒真理紧紧联系在一起。 动机不正，则诸事不顺。 每天人生最重大的战争都在灵魂深处的密室中进行。如果你能够在这些战争中获胜，将内心的矛盾和冲突平息下来，就会感到一片祥和，并领悟到生命的真谛。自然而然地，你会取得公众领域的成功，即秉持着合作精神，为他人造福，由衷地为他们的成功感到快乐。 智力层面的更新主要靠教育，借此不断学习知识，磨砺心志，开阔视野。积极处世的人有能力摸索出无数种自我教育的方法。 养成定期阅读优秀文学作品的习惯是拓展思维的最佳方式，这是第二类事务，人们可以借此接触到当前或历史上最伟大的思想家。 磨砺心智的另一种有效方式是写作。通过不断记录自己的想法、经历、深刻见解和学习心得，我们的思路就会更加明晰、准确和连贯。如果能够在写信的时候与他人深入交流思想、感受和理念，而不是肤浅地停留在事物表面，也有助于我们提高思考、推理和获取他人理解的能力。 至于增进内在安全感的方式，包括：坚守原则，肯定自我；与人为善，相信人生不止输赢两种抉择，还有双方都是赢家的第三种可能性； 每个人都是社会的一面小镜子，反映出身边人的想法、判断和模式，每个人都从镜中获知自己在周围人眼中的形象，而社会之镜是由周围人的舆论、认知和思维决定的。作为相互依赖关系的一分子，我们都有这样一种潜意识，即自己是社会的大镜子的一部分。 犹如生命少不了食物，但人绝非为吃而活。 越是积极主动（习惯一），就越能在生活中有效地实施自我领导（习惯二）和管理（习惯三）；越是有效管理自己的生活（习惯三），就能从事越多的第二类事务的更新活动（习惯七）；越能先理解别人（习惯五），就越能找到统合综效的双赢解决方案（习惯四和习惯六）；越是改善培养独立性的习惯（习惯一、二、三），就越能在相互依赖的环境下提高效能（习惯四、五、六）；而自我更新则是强化所有这些习惯的过程（习惯七）。 稳定的经济基础并非来自工作，而是来自个人的产能（思考、学习、创造、调整）。真正的经济独立指的不是家财万贯，而是拥有创造财富的能力，这是内在的。 良知的声音如此微弱，可以被轻而易举地淹没；但又如此清晰，不可能被错误地解释。 那次谈话让我们热泪盈眶，不只是因为这些新发现，还因为我们更加尊重彼此了。我们发现，看似琐碎的小事，往往也源自刻骨铭心的情感经历，如果只看表面，而没有挖掘深层的敏感问题，无异于在践踏对方心中的圣土。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E3%80%8A%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%84%E4%B8%83%E4%B8%AA%E4%B9%A0%E6%83%AF%E3%80%8B/"},{"title":"付鹏-经济世界观-全文","text":"视频学习。来源：华尔街见闻大师课 1.1 什么是大类资产开篇先跟大家讲一下什么叫大类资产。 我经常会被问到，付总你怎么看猪肉？我说我没法看。还有朋友问我，4月30日红枣期货上市你怎么看？我说我没法看。或者有人问付总你怎么看某某公司的股价？我说我没法看。 我确实没法回答这些问题，因为我们这个所谓的大类资产框架，它有一个最基本的原则-不是所有的资产都放在一起的。换句话说，不是所有的资产价格都只是一个价格，看涨看跌，什么都可以看，那是不是跑到澳门赌场看大看小也可以用同样的方法？当然不是。 这里面对于资产的定性是很关键的，对于大类资产，我们可以遵循这种宏观策略的逻辑框架，但是对于小众资产，你可能根本不需要研究今天宏观怎么样，明天全球怎么样，因为不重要，你更多的需要关注的，实际上是小众资产本身微观要素正在产生的这种变量。 为什么要区分大类资产和小众资产呢？因为它们的侧重点是不同的。所以说我们后面分享的，更多的是大类资产框架，并不适用于小众资产。 即便是对商品来讲，可以放到框架中的、真正可以去使用的，铜和原油就够了，其他小众的，比如说咖啡期货、红枣期货、苹果期货，这些跟宏观体系有什么关系？没有，你可能要看的更多的是它的交割、它的仓库、它的品级、它的参与者、它的交易制度，你可能会看得非常微观。所以并不是说期货就叫大类资产，这是错的。 很多人会说股票是大类资产，这从另外一个维度上来讲也不完整。前几年经常有人问我，付总对新西兰的股市怎么看？我说很简单，它不属于大类资产框架，你可以观察它，但是不可能把它放进来。他说为什么？我说第一，流动性不够，纵深不够；第二，它的交易制度不是T+0，甚至不像中国，连T+1都不是，前后需要5天。 所以你会发现它的性质决定了它是一个小众资产，但是它可能会受到宏观的影响。股票里面很多的，比如香港的小盘股、仙股，它们跟经济的好坏有什么关系？没有任何关系。所以说不能把股票笼统的放到我们这个框架里。 大类资产框架包含什么呢？FICC，基本上就那几样东西，债券、权益，加上一部分的商品。其实有的时候框架里包含什么取决于你的交易策略，还有你的特点。我经常跟大家讲，我说资金属性决定了你的行为，而你的行为又决定了你的可选项是不一样的。 有人问房地产算不算？比如说做一个私募或者公募基金，可以看涨或者看跌房地产，但是我没法把它做成一个资产配置进去。但是后面我们讲到全球的FICC框架的时候，你们会发现房地产又会作为一个非常重要的市场存在着。其实很简单，从我的角度来讲房地产可以算作大类资产，无非就是有些人能做，有些人不能做，有的资金属性可以配，有的资金属性不能配，仅此而已。但是这些手段原则上来讲大家应该了解，因为它对于整个体系的影响还是很大的。 债券方面，主要的利率债有美国、欧洲各国、日本、中国、澳洲的债券，工具我们选择ETF和衍生产品。 权益方面，大家会发现我很少选择个股，我很少去讨论股票，我跟很多人说过我是从一级市场做到二级市场的，我的原则是只做那些我很熟悉的上市公司，熟悉是要加引号的，我要熟悉到非常熟悉。否则的话，像美国证券市场一样，与其这样主动的去选择，不如进行被动的投资，选择ETF就好了，或者说选择特定的一些产品作为我的配置就好了，我不会特别的去涉足某个特定的公司，这其实已经非常微观了。 做权益的人其实会有一种困惑，有的时候不需要去在乎宏观经济到底发生了什么，更多的需要关注这家上市公司的经营情况，这其实是比较偏微观的，原则上来讲这不是大类资产框架擅长的，怎么办呢？配合就好了，所以只看一些特定的龙头类的权益就可以了。涉及的市场，主要是美国、欧洲、日本、香港、中国，这些其实都是全球化进程的一部分。 其次会关注多一点的是澳洲市场，但是仅限于极个别的、跟我们后面讲到全球经济一体化相关的这些行业龙头。新兴市场属于关注类，比如说我们经常会讨论土耳其的市场怎么样了、巴西的市场怎么样了，但我要告诉大家的是它们都属于关注类，只有很少部分的对冲基金会涉及这类资产。 大部分的时间我们更多的会去寻找一种替代关系，就是说逻辑关系很清晰的时候我可能对于对标资产会做一些替代，并不会直接涉足这一类。所以说土耳其也好，俄罗斯也好，巴西也好，真正能够参与这些新兴市场的人其实是很少的，华尔街的投资机构还可以，像我们国内或者华人圈子里真正能参与进去的比例还是很小的，它属于关注序列，并不属于真正意义上我们马上可以参与的。 汇率部分，大家都在参与的，主要是G7汇率，但是研究和关注类我这里列举了韩元、台币、南非的兰特、墨西哥的比索、巴西的雷亚尔等，这其实跟刚才我们讲新兴市场的配置道理是一样的。它的交易成本、交易的通道、交易的可选择的类别，实际上比较受限，流动性也受影响，所以原则上来讲不建议真的去交易，你要关注它，在整个反馈过程中寻找替代即可。 商品中最重要的是原油，但是我之前也跟大家分享过，原则上我们把原油更多的当成一个利率性的影响变量在看，虽然它具有商品属性，但是跟利率高度相关。其他的基本金属，主要看铜，当然，剩下的比如说作为对冲手段的一些跨品种的交易，可以选择铝、锌等等。 贵金属里面，其实黄金就是一个债券，我之前跟大家讲过，它虽然放在商品里，但是更多的是按照债券的逻辑去考虑。白银是一定要按照商品去考虑的，这里就会产生一个偏差，也导致了后面我们会讲到的一些案例，2011年、2012年中资在白银上犯了巨大的错误，其实本质上来讲就是错在把白银当成了跟黄金一样，完全忽略了它的基本的商品属性，所以最后被华尔街给逮住了。 铂、钯这类品种不在交易范围之内，但是我们会研究它，为什么呢？它具有很多小众商品的特点。这几年大热的钴、锂、锗、锌这种小众的基本金属，大家已经陆陆续续发现它们的玩法和套路了，其实这些事情在当年的华尔街市场上都出现过。 小众的资产是会有人惦记的，比如说大家最早从业的时候应该都接触过白银的亨特兄弟的案子，再比如说当年的钯金的案例很多人并不知道，也就是通过我写的日记大家才知道19972000年前后的钯金价格操纵案，最后让福特这种下游的汽车公司掏了钱埋了单等等。其实越小众的商品，套路越相似，无非就是有的时候它的供应和需求并不像很多人理解的那样，越小越容易改变。 大家看美国的商品市场那么庞大，但你们什么时候听说过一个纯交易者去交易橙汁、去交易活牛、交易活猪的？我接触的不少的中国交易者其实挺奇怪的，这个基本的原理他们都不太明白。 我经常会看到我们的群里讨论，哎呀美国的猪肉又暴涨了，炒！我觉得好像在他们眼中，所有东西的价格都是一样的，比特币、狗狗币，各种币没有区别，管它叫什么名字，他们只是在看单纯的价格。我觉得这从原则上来讲是一个大忌讳，单纯看价格的话可能更多的考验的是你盘面交易的能力，但是资金量稍微一大，这个游戏你就没法玩了。 所以在讨论大类资产的时候我们必须注意纵深的维度。 农产品属于研究序列，它的交易思维跟大类资产的逻辑框架不一样，所以农产品是比较倾向于纯商品的框架，跟宏观也好，跟我们说的大类资产框架也好，关系不是特别的大，它属于观察序列。 铁矿石、煤炭、乳制品也都属于观察和研究序列。当然了，你要么就干脆让纯交易者去交易，你也可以理解成金融属性比重重的我们拿过来放在大类资产框架里，自身属性比较重的，越重的越偏向于对它自身的研究，这个道理其实原则上是对的。 这就是我们原则上来讲大部分的大类资产的路径。 1.2 打通宏观经济学家和交易者之间的秘诀在开篇的部分我们并不是说直接就开始分享，因为很多的问题其实不是在我们的框架中就可以解决的。在一开始，我想跟大家分享的其实是我的世界观的形成，这会影响到我们对于现有的很多问题的探索。 之前戴老板问我说，宏观经济学家和交易者之间似乎是很难打通的。我说没错。他说这里面的秘诀在哪？我说这里面的秘诀很简单，记住一点，宏观经济学家讨论的永远是没有对错的问题，他们讨论的是产生的原因、可能产生的结果以及可能产生的方法但是对于交易者来讲，我们并不需要去参与这样的讨论，因为有时候这样的讨论是没有任何意义的。 比如说很多人喜欢讨论中国是否存在崩溃的可能性，反对者会说你这样的想法是错的，但这种讨论有意义吗？这种问题写成泛财经的文章可能点击率很高，但是实际上对于很多金融市场的直接参与者来讲，我们没必要陷入这样的纠结当中，我们需要搞清楚的是怎么去做，这个体系怎么传导。 所以说有的时候交易者去看宏观，更多的是要看其中的矛盾和逻辑关系，由此推测经济的走势，然后才能知道在下面的体系里自己该干什么。这实际上才是宏观和交易者之间所谓的脉络，如果没有理解这个脉络会犯很多错误。 比如说过去的10年间，许多大家认为很好的宏观经济学家可能会讲一大段中东的故事，讲一大段中东的战略问题、美国能源战略问题，讲完了以后直接得出结论一油价要涨。这在以前投资者结构不成熟的情况下，非常容易抓住投资人，为什么呢？你左边讲的我能听懂，右边的结论我也能听懂，好，就按照你的结论去做。但是这中间缺失了很多。 这两年我通过跟华尔街见闻做的《付鹏说》的节目，其实跟大家分享的更多的不是结论，我很少跟大家直接说结论，我觉得那样做没有任何意义，我更多的是把中间缺失的这一块讲给大家。 比如说这两天大家看到原油价格在涨，不理解的人会说因为伊朗的问题油价在涨，现货溢价在往上推，但是为什么付总非常紧张油价可能会出现较大幅度的调整？我会跟他解释，现在发生的宏观事件，比如说沙特承诺的增产，其实已经作用在了远端价格上，但是在近端这个事情只影响情绪，并不影响实际的供应和需求，因此就会出现高位的现货溢价。 你会发现我把中间的传导路径讲出来，后面的结果就很好推了。但是很多做纯宏观的人会犯这样一个错误，前面讲完了直接给出结果，但其实中间这一段要比前面更重要。我认识的几个朋友就吃了这样的亏，他们说你没讲这些东西之前我们觉得这样的推导没问题，比如说黄金保值、黄金通胀，经济学家先讲一大段黄金的历史，然后直接得出的结论说黄金必涨无疑，买吧。 这实际上就是从纯泛财经直接到结论，并不能形成一个完整的交易体系，中间缺失了一块。但是这不等于说左边的宏观研究没有用。 我前几天写了一篇日记，主题是宏观真的无用吗？因为有人写了一篇文章说宏观是无用的，这是另一种极端主义，他认为宏观没用，直接看左边的交易手段、交易方法就好了，他认识到了纯宏观的弊端，他认识到其实很多的宏观经济问题讨论半天却没有一个实质性的结果，对交易者没有什么帮助，于是他得出的结论可能就是宏观无用。 我认为这两种观点都走向了极端：宏观完全有用，它可以替代中微观的研究，我可以告诉你错了；宏观完全没用，直接就抓中微观、抓纯交易的手段，我可以告诉你也错了。 原则上来讲我们要尽量保证这个链条的完整性，但是你要明确在每个点上到底要去聊什么。比如说大家坐在一起侃大山，我可以说政策不应该这么去做，应该怎么去做，这叫侃大山、聊天，但是在具体执行的时候，我不会依靠这个东西去做交易决策，但是必须得了解正在发生的是什么。 所以我们第一篇是一个非常泛的宏观的东西，但它很重要。 1.3 经济世界观的三大核心问题大家如果有经济学基础的话，经济世界的三大问题其实很简单。这三大问题可以从经济学的课本里，从最早的《国富论》里找到，我把它们总结为分工&amp;分配债务&amp;杠杆和收入&amp;贫富。这里面涉及的问题不一样，我们这种金融从业者，其实更多的是在中观层面关注债务和杠杆。但如果我们是真正的政策制定者，或者宏观战略的思考者，其实还要涉及一个人文社科的问题，就是收入和贫富的问题，否则就会被有些问题迷惑。比如说很多人认为经济就是一个货币现象，大水漫灌，一切太平，挺好的，为什么不能这么做？当你把这三个问题合到一起的时候会发现，它产生的矛盾会跳出经济学领域，变成一个人文社科的问题，也就是最后一个问题-收入和贫富的问题。 其实很早以前，我们的这些前辈、大师们就看得很明白了。所以说经济周期的循环，原则上来讲就是在释放它的利的过程中积攒了大量的弊，所以它需要利用这种萧条、衰退的过程去进行再平衡，平衡社会的问题、平衡财富分配的问题。所以说西方的整个经济周期，我们看到的一轮又一轮的繁荣、衰退、萧条，其实准确的说都是在这个过程中处理它的矛盾。 事实上来讲，我现在对于2008年金融危机实际上是比较忧心忡忡的，虽然说大家看到资产价格涨也好跌也好，有波动，但是如果单纯的从世界观的角度来讲，我一直认为2008年金融危机到现在为止还在延续，而且它延续到了一个非常危险的境地，就是它已经在影响我们最后也是最害怕的问题一收入和贫富的矛盾。事实上来讲，如果大家观察到一些社会现象，不管是我们内部的社会现象还是全球的动荡格局，或多或少都会理解我要讲的这个问题。 这三个问题之间是怎么样一个关系？《国富论》告诉我们，有了分工、分配，有了激励的方式，才有收入的增长，才有经济的增长。这话是对的，其实最原始的财富就来自收入的分工和分配。这个东西几百年前《国富论》就跟大家讲得很清楚，它讲到的是一个单一社会里的分工和分配，但是由它进一步延伸出来，就是大家非常熟知的全球经济一体化。全球经济一体化无非就是国家和国家之间的分工和分配关系。但是任何的分工和分配本质上来讲，都有利和弊，尤其是加上债务和杠杆以后，它的利弊就会产生得非常明显。 为什么大家都喜欢从事金融业？很简单，因为金融行业或者叫金融服务业的从业者，要么是创造债务和杠杆的人，要么是利用债务和杠杆的人，我们掌握着财富扩张的命脉，财富的扩张究竟来自什么？其实就来自债务和杠杆的运用。如果说没有了金融，世界会不会好呢？我可以告诉你没有金融世界不一定会差。很多人会有一个错误的认知，认为做大做强金融行业是为了服务实体经济，这其实是我们给自己披上的一层圣衣。原则上来讲金融行业一半天使一半恶魔，我们创造财富的同时也带来灾难，灾难是什么？巨大的贫富差距。所以说很早大家就开始认知到，债务和杠杆的运用会拉大收入和贫富的差距，社会的阶层会错开，然后你会发现富者恒富、穷者恒穷，劳动的价值在减弱。这是一种非常泛宏观的认知，但是把它糅合在一起就会生成一个通用的模型，不仅可以用于解释我们的宏观问题，还可以用于解释我们的微观资产。单一的资产也是一样的道理，都是财富的创造、财富的扩张和财富的分配问题，实际上任何资产的路径都可以用这个模型解释。 下面我要讲的这两个人是真正的大师，我们只能算师者，我想跟大家分享一下他们认知中的精华部分。第一个人是索罗斯，我记得最早的时候，二三十年前很多人去解读索罗斯先生的《金融炼金术》，很多人的解释就是，哎呀，好像看不懂前面那段偏理科的系统性东西在讲什么，好，我们直接给它的反身性理论冠上一个哲学的名义，哲学这东西好讲，也好理解。但大家别忘了，索罗斯是一个标准的理科生。《金融炼金术》中大量的内容，其实是标准的全球经济一体化的反馈路径的一个组合，可不是简单的哲学人生心灵鸡汤。我们只能说当时的大部分读者对这个理解并不深刻，可能一些学者很容易看明白前面他在讲什么，但是我仍然要推荐这本书。我认为索罗斯最荣光的地方，就是他对于国际分工、分配的理解，他1997年狙击香港，就是利用了他在国际分工和资本流动中间造成的中微观的矛盾，但是他的世界观更多的是基于对分工、分配，以及收入分配的极值的理解。 第二位是达利欧先生，他的书其实大家也都看了，更多的是对于债务问题，债务的生成、债务的毁灭、债务的处理、债务的解决方案的讨论，他对于债务和杠杆的理解应该说是非常深刻的。 最后关于收入和贫富，我想金融圈里没有人对这个问题探讨过多，因为它不属于我们的范畴，我们唯一在乎的重点是赚钱。当然了，当你的钱赚到一定程度，开始思考改变社会的时候，你就成功进入到第三层级，开始考虑关于收入和贫富的问题，你可以把自己的财富捐出去，可以去做慈善，去改变这个世界，这是第三层级的问题，但是基本上不会有人去写书讨论它。但是我们的社会现在需要我们这么做。 1.4 三大核心问题解读模型（1）我们可以做一个简单的模型，虽然说是模型，但我们没办法用纯数学的方式去解释，所以说这里做的模型非常简单。 从我的角度理解，经济的增长和效率的提升，原则上来讲来自两部分，分工、分配，就是收入，我们把它放在分母部分，分子部分是债务和杠杆，换句话说，财富的创造和财富的扩张加在一起，形成了整个经济的增长和效率。 所有人都知道技术创新是提升效率的唯一方法，这点没错，就是在分工、分配的前提下，我们去创造一个增速，去创造一个斜率，技术的斜率。 但是劳动到一定程度，并不决定你能够分享经济增长带来的红利，这个时候就会有一个偏值，这个偏值就会开始受到其他因素，就是债务和杠杆的影响，我们把它对应到这两个函数上，然后就会生成这样两张图。其实很多人对此并不陌生，只是很少有人把这三个东西放到一起思考。 先看右侧这张图，它反映的其实就是经济世界的这三大问题。大家会发现图中有两条斜线，这两条斜线斜率不同，这个斜率不同就是因为刚才我讲的生产效率的提升，技术的提升会改变产出的效率，于是斜率就会发生变化。 简单讲，随着人类文明的进步，随着技术的提升，我们的整个收入水平，在单位时间内获得的财富的量也会增加，这是自然法则。但是大家会发现图中还有一条叫金融化程度的黑色曲线，这条曲线里面就蕴含了我们现在面临的很多问题 在第一阶段，大家会发现黑色曲线跟斜线基本上是吻合的，这就是劳动价值。简单讲，所有的年轻人只要辛勤的努力劳动、不放弃，原则上来讲你们一辈子能够获得的就是这条斜线上面正常的增长。 举个最简单的例子，你18岁，你的师傅比如说是厨师，你的师傅可能月收入已经是两三万块钱，甚至更高，但你只有两千块，没关系，这中间只是一个时间价值的问题。换句话说，只要你付出了努力，只要你认真学习，只要你跟着你的师傅兢兢业业，随着时间的推移，你的收入是会按照这个比例增长的，等你到师傅那个年龄的时候你也会获得同样的财富。 假设所有人的寿命都是60岁，加权起来你会发现大家的斜率几乎是一样的，也就是说劳动创造的价值在这一辈子里几乎是一致的。当然了，不是说所有人都一致，这中间会有一些差异，比如说家庭背景、社会资源、教育程度等会导致每个人的斜率不一样，虽然它造成贫富差距，但是不造成最严重的贫富差距问题。 第二阶段大家会发现这个曲线偏离了，偏离得非常大。换句话说，哪怕你已经进入到中产阶级，你已经在公司里努力的工作了，但是你会发现有的人可能就比你赚的多得多得多。这部分在我的框架中叫债务价值，就是说到此为止的第二阶段中，一部分人开始明白一个道理，只有收入是不够的，能不能看到一个赚钱的生意以后我去借钱？ 负债产生更高的收入这个结论开始产生，这个时候负债者跟储蓄者的财富差距就会拉开，简单讲，纯储蓄的人，到老了就哭了，越借钱的开始变得越富裕，债务价值在这个阶段中体现在大家的收入分配上。 再往后，最高的这个阶段，也就是人人都愿意干的金融行业。为什么大家愿意从事金融行业不愿意下工厂呢？道理其实很简单，杠杆。 债务价值阶段过了以后，我们要想的是怎么能够借更多的钱才能够在短时间内获得更高的收益，杠杆的原理就出现了。现在大家在做的任何金融交易也好，金融设计也好，金融产品也好，它的基本原理就是在一个资产负债表中如何拿到债务的问题，如何增加杠杆的问题，所有的设计都是这么来的。 当进入到高杠杆年代，大家会发现财富是会在极短时间内累积起来的，这个曲线的斜率会更高。这部分在我的框架中叫金融化程度，什么意思呢？简单讲，金融化程度越高，大家就越有机会在短期内实现改变人生的暴富。 这三个阶段，劳动价值部分、债务价值部分杠杆价值部分，合在一起就生成这样的一条曲线，中间的这个差值部分就是贫富差距。 如果我们把它放到宏观经济里面是什么？这三部分分别对应实体经济、房地产为首的债务、金融为首的杠杆。所以说大家会有一种困惑，叫干房地产比干实体好，干金融比干房地产好。当然了，金融也不能纯虚，所以说拉个实体部分，加上杠杆形成金融，所以我们都希望自己的孩子去学金融。虽然说你从事一个技术性的工种，可能一个月能拿到两三万块钱的工资，但是大家觉得不够，财富分配就此拉开。 所有的国家都一样，大家不要认为我在说中国，不是这样的，这个模型适用于所有的国家。 它带来的问题也很简单，贫富差距。其实这个道理可以解释现在大家看到的一些问题，就是债务和杠杆的急速累积会使收入部分发生偏移，这个时候其实所谓的泡沫也就随之出现了，无非就是这个债务和杠杆体现在什么领域，是居民部门、政府部门，还是企业部门，但早晚有一天它是会回来的。 所以说一般来讲，把它反过来就是去杠杆、去负债的一个过程。其实在足够长的经济周期中，我们一直在经历复苏、繁荣、衰退、萧条，循环往复，无非就是我们在哪个部门完成债务和杠杆的累积，完成去债务、去杠杆的过程，完成效率部分的回归。 一个简单的模型加上它的反向运转，然后叠加，就形成了大家看到的经济的路径。 1.5 三大核心问题解读模型（2）大家可以想一想2008年的美国次贷危机，英国的情况也差不多。我说自己比较幸运，是因为到这个年龄我已经经历了两轮这样的完整过程。一般来讲，这样的一个周期差不多在20一30年，正常人经历两年基本上就可以退休了，幸运点的人经历一轮就够了。所以有的时候说人生七十就是一两次机会，这话其实没错，但是有的人比较幸运，比如我，在东西方各经历了一轮。 大概到2002年、2003年，英国的劳动价值这部分，也就是大家称之为实体的部分已经结束了。2002年左右英国的房地产市场开始繁荣，加债务、加杠杆开始启动。那个时候很简单，如果你还是工人你就完蛋了，这20年你的收入不会有明显的增长；但是如果你开始加杠杆，开始买房子，你的人生就会改变。这波房地产的繁荣一直持续到2006年左右，当时英国的ITV、Channel5，最好的节目都在教你如何拍卖一个破房子，先去银行做抵押，拿到钱后把它重新装修一下，然后放到市场中去卖。 经历了托尼·布莱尔政府的金融改革和第二次金融大爆炸之后，伦敦金融城重新复苏。金融的加杠杆实际上不是我们想加就加的，它不是自然生成的，一定是在制度的监管下实现的，也就是一小部分人决定什么时候可以加，什么时候可以减。无论是在欧美还是在中国，都一样。很多人认为它是一个自然的周期，我可以告诉你不是，都是人为的。为什么很多时候我们会去盯政策，盯政策到底在盯什么？看新闻联播到底在看什么？那个时候看英国的报纸，就是要看它的大选，看谁会上台，看是不是安倍晋三会赢，有人会说这些东西跟你的这个宏观框架有什么关系？很简单，这部分人将决定你后面的路。 2009年为什么要回到国内？如果没有2009年两会提出做大做强金融，国家开始逆周期加杠杆，如果没有2009年3月31日证监会第61号令开始放开中小板！创业板和前端的股权投融资，回来干嘛？金融从业者，很简单，说俗点我们追逐钱，但是说得更专业点，我们追逐负债和杠杆，哪里有负债哪里有杠杆就去哪，哪里去负债哪里去杠杆当然不能在那。大家可以想想，如果过去十几年待在英国从事金融行业，是很悲惨的。很多人并不明白我为什么要回国，是因为2008年金融危机吗？不，是因为杠杆从西方迁移到了东方，从伦敦、纽约迁移到了上海、北京，金融从业者自然而然也要随之迁移，但如果，举个例子，未来的10年或者20年中国开始收紧了，金融从业者理论上就应该是走的。所以可以说金融从业者的所在地也是由金字塔尖的一小部分人的政策决定的，这就是观察政策的目的。 伦敦金融城复苏之后，居民债务大量增加，伦敦金融城赚得盆满钵满，大家其实并不在乎收入到底能不能还上债务，这造成了居民债务和收入之间巨大的差值，也就是贫富差距。这个东西积累到一定程度就该有人埋单了，实际上这就是次贷危机，无非就是债务在哪个部门爆掉、由谁埋单的问题，简单讲就是这么一个情况。这就是经济的一个周期，但是真正的长期增长靠的一定是创新和生产效率，也就是斜率。这个框架理解了，大家也就明白不会有永远的加杠杆、加负债的过程，不会说偏离程度那么大还可以维持，终究是要有人埋单的。 这张图同样适用于中国，2002年以前，很简单，干实体经济。那个时候我们斜率的提升并不是来自生产效率的提升，原则上来讲当时斜率的提升更多的是因为全球经济一体化对于我们的影响，所以那个时候就是干实体。2002年之后，正常来讲你应该明白，要干房地产，2008年之后干金融，这就是人生的三大阶段。为什么我们说总有一代人是倒霉的？很简单，干实体的是这一代人的父辈，或者父辈的父辈，干房地产的是他们的长辈，干金融的是他们的前辈，等他们毕业的时候发现只能去扛负债。这就是我们说有的时候年轻人的命运是天生注定的，改变不了的。每个时代都有这样的例子，比如20世纪80年代英国的那一代、1997年香港的那一代，本质上来讲他们都是赶上了所谓的资产泡沫的顶峰期，对不对？所谓的资产泡沫的顶峰期就是左图中的红色圆点，也就是债务、杠杆和收入偏离最大的那个点，那时的收入已经不足以填补债务。 这个时候其实又衍生出另外一个小的函数——债务可以等于收入的函数，这其实跟股票的道理是一样的。最简单的股票定价是什么？把未来的现金流折现回来。其实这跟借贷人的人生是一样的，我给你的债务越来越多，我折现你未来的时间就越来越多。我现在折现你20年，你拿青春还我。后来发现房价还在涨，资产价格还在涨，但是你的收入不涨，也很简单，总量在增加，你的单一收入没有增加，乘以时间函数就行了，20年变成40年，40年变成80年，如果干80年还不够还我怎么办呢？儿子还，孙子还。但是如果你没有儿子没有孙子，那负债就不可持续了。 当然也有人说债务最后的问题是人口问题，这句话是对的。现在欧美日韩存在的情况是什么呢？说到底就是所有这些负债坍塌之后没有人能够去承担，没有人口时间函数去承担它，债务不可持续，资产价值就会保持长期的低迷。货币政策在这里面会犯一个巨大的错误，大家对货币政策的理解就是放水、宽松，从放量到放信用，大家认为只要这个东西一放，就一定能够让资产价格复苏起来。对不起，日本证明过，欧洲正在证明，不一定会这样。 有人会问为什么？很简单，放水只是在稀释债务，但是如果长期收入提不上去，债务再怎么稀释，只要不让它崩，都会集中在某一部分的富人身上，这个时候大家会发现货币政策会导致一个现象叫富者恒富、穷者恒穷，并不解决债务问题。所以说简单的说货币一漫水，所有债务等于被稀释掉了，这就是不对的。这个漫水的过程会造成富者，或者说掌握着资产、掌握着债务和杠杆的人是最大的受益者，受益得越来越多，而下面的人并不受益，他们要承担更大的负债，但是总收入并不增长。紧接着我们就会看到同样的问题，债务仍然无法可持续。所以说不是简单的说任何经济问题都可以用放水去解决，那样的话还讨论结构性矛盾干什么？其实原则上来讲，结构性的矛盾要远比货币政策重要得多。结构问题是什么？在我们这张图上结构问题就是收入、贫富、人口、债务的可持续性。它在微观层面也可以应用，大家会发现，这么大的一个宏观框架，降维到微观层面它照样可以用。 举一个最简单的例子——股票，我们可以把股票价格想象成一个社会，其中同样涉及价值的创造、价值的扩张和价值的分配。我在这里和大家分享的关于股票内容，其实和大部分讲股票的人讲的东西是一样的，只是理解和认知不一样。我们之前构建的经济增长和效率模型也可以用来股票价格，换句话说，股票价格的上涨对应的就是经济增长和效率的提升，原则上来讲只要企业是不断盈利的，就应该有一个均值的斜率。 大家会发现股票价格的两个影响变量是杠杆和投机性波动。我在和惠特尼蒂尔森讨论时说，其实有的时候你也必须得承认投机也是一种价值。大家经常讲价值投资，其实讨论的更多的是企业能不能给我创造回报，讨论的是那个斜率，但投机也是一种价值，无非就是这个价值怎么看怎么用的问题，所以不能把这块完全忽略掉。跟之前对于经济增长和效率模型的讨论一样，股票价格理解起来也很简单，当债务、杠杆推升的股价已经大幅度的偏离了长期增长收入的时候，也就是所谓的高估。 1.6 债务、杠杆与收入模型的应用股票市场处在不同阶段的差异性这样一个简单的应用之后，我们来看下面这两张图，左边这张图是成熟阶段市场的一个简单模型，大家其实也都看到了，之前我们只是把经济周期的不同阶段拆分了，现在我们把它组合在一起。 成熟阶段市场的长期增长价值部分的斜率比较高，能够给予股东足够的尊重、股息、分红、盈利，在此基础上还有一点投机性的波动。这样的市场原则上来讲，只要斜率不改变，就是一个长期增长的过程，但是大家注意这是成熟阶段市场。 右边这张图是发展阶段市场，价值部分的斜率偏低，股价的波动大部分是由投机性波动造成的。 之前和大家聊过，在2014年、2015年股灾中后段的时候，如果有）明保进中国的资本市场600（点钚是梦，一万点刚起步，长期的大牛市开始了，未来的目标是一万、一万二、一万三、一万五。你马上就知道，他没想明白。 在过去的100年中，美国的证券市场大概只有两次进入了长达10年左右的停滞阶段，但停滞阶段也只是横着，类似于右图这样的状态，其余大部分时间都是长期增长。比如说这一轮美国的牛市大概是从1993年开始，大家不要以为是从2008年金融危机开始的，真正意义上的长周期的增长的启动大概是在1993年。 我之前跟大家分享过，从1980年里根的改革开始，1980-1993年其实美国更多的进行的是一个结构性的改革。在1993年完成了这样一个改革之后，长期增长的基底开始出现，中间虽然经历了两次投机性的波动、扰动，当然原因不一样，一次是1997一2000年的互联网泡沫，另外一次是2008年的金融危机，但是基本上没有偏离长期增长，投资回报率很高。 所以说在美国做权益，尤其像我这种做大类资产的人，其实是很懒的，被动性投资的回报率就已经是最好的了。在美国证券市场长期增长斜率非常高的情况下，只要被动性的买一堆ETF一直持有，10年后，20年后，你的投资回报率会非常好。 不需要去挑股票、挑公司，除非你要追求极致。什么叫极致呢？想要跑赢所有的人，那你付出的努力和你的回报一定是成正比的，但是其实没有必要。 有些人说巴菲特这10年连持续性的跑输大盘，没错，因为从1993年开始的长期增长斜率的改变，也就是效率的改变，他老人家确实有点看不懂。我记得我讲过一句话，不是巴菲特成就了美国证券市场，是美国证券市场成就了长期价值投资，市场进入到成熟阶段以后，它的管理、制度、监管、市场成熟度、参与者程度所有这些市场发展要素决定了投资者在这个市场里应该怎么做。 大家为什么迷信长期价值投资？就是因为在这个市场里可以实现。所以原则上来讲美国证券市场被动性的跟踪就可以，也不用去纠结究竟是微软好还是苹果好，一个ETF持有五六年，从原则上来讲就是最好的。 在中国能不能这么干？我相信有人这么干，但应该积累了比较惨痛的经验。因为原则上来讲，大概筛选一不我们的权益市场，最多只有150只企业的股票具备这个属性，大部分的公司还是处在发展阶段市场环境下。所以在中国，可能更重视的是交易，而不是长期配置。你可以做长期价值投资，但是我相信你锁定的标的物不会超过那150只，这就是我们说的市场处在不同阶段的差异性。 中国股市的波动更多的来自投机性波动，所以我们的证券市场很有意思，每一次暴涨的时候一定是放量高换手。其实我也特别明白两位大师的对话，一边说我们要尊重价值，另一边说这么做没有用。其实两边都对，只是讨论的情况不一样。 中国股市就是发展阶段市场，它的特点就是我不关心它是真的假的，我只关心对手盘相不相信。投机性波动要考虑的问题并不是真和假，而是你的对手信不信它，你有没有对手盘，你能不能完成换手。很多人比较喜欢的交易性手法，其实讨论的更多的就是这个问题，但是长期资产配置考虑的更多的是成熟阶段市场的特点。 所以在中国证券市场上，我的原则就是从来不去讨论股票，但可以根据特点对它们进行分类。而且每一波牛市的末端大家更多关注的是什么？很简单，从右边这张图可以延伸出来，大家更关注的是能不能换手，杠杆率是不是已经到达了极值，这些东西都不够的时候市场还能够持续多久？ 当然了，一般到了那个时候就要靠理想让投资者进来了，什么理想呢？中国会开启大牛市。但是大家冷静的思考一下，想要具备这样的条件，答案并不在什么经济上，而是在市场成熟度上。只有中国证券市场建立完善的市场制度以后、大部分公司都开始转向这个方向的时候，整个指数才会具备这样的条件，否则你就得从发展阶段市场的维度去思考。 美国基金从业人员的三种类型有人会问美国股市里面没有投机吗？当然有，区别只是比重的不同。所以说大家会发现美国要防御的风险其实更多的是一个估值偏离的问题，或者是流动性冲击的问题。美国证券市场的调整，更多的实际上都是因为这两个变量一估值过高了、泡沫化了，要么就是其他债务问题导致整个金融系统流动性收缩了。 其实从1993年到现在，美国股市的两次大的波动就是因为这两个变量，2008年跟估值没有任何的关系，就是流动性风险，1997-2000年就是估值泡沫，仅此而已。大家会发现看多或看空美国证券市场是没有意义的，如果拉到足够长的周期里，斜率足够高的话，任何时间都是买点，很简单，大部分时间是低波动率，小部分时间是高波动率。 正是因为这个特点，美国的基金从业人员可以分成这么几类。 第一类，活得足够长的，这类从业人员可以用生命去烫平中间的这种一两年的高波动率回撤，所以他给你展示业绩的时候，不会告诉你说这一两年他的表现不好，他会说过去10年他的平均投资汇报率是多少。 第二类，在低波动率下干个三五年，拿到分红退休，然后该写书的写书，该演讲的演讲。 第三类，低波动率的那三五年让别人投资，这类投资者比较少见，但是我比较崇拜的。什么呢？既然我已经知道了证券市场的基本框架，我为什么要那么辛苦的自己去做投资呢？人生很美好，可干的事情非常多。这种事我付管理费你干，这就叫被动性投资。我不需要去挑股票、做调研、天天盯盘，没有必要，我都委托给你，你去做交易，我给你管理费。因为我知道在这种环境下，市场中大部分人的收益都是以相同的均值增长的，它是增量，创造财富。我要干什么呢？我要帮你防御风险，比如说延续了三五年、五六年的低波动率之后偶尔出现高波动率，这个时候我并不一定会撤资，没必要，因为我知道你的中长期投资年化回报率是多少，它是固定的。 我要干一件什么事情呢？我要在这个过程中烫平我的风险，我选择只关注空头信号，也就是我更关注的是风险，我并不是没有意识到这三五年是一个大牛市，但我想要实现的是对冲你可能规避不掉的风险。所以说大家会发现很多的做空者其实就是做多者，但是价值投资没法规避这部分风险，所以大家看到的只是做空者。 还有一类是比较极端的，就是观察到信号以后，比如说一只基金刚开，开到2006年，在这个时间节点上就要选择是做长期的多头，还是一战成名，类似于电影《大空头》演的那样。但是那类人一般来讲，赌对了金融危机以后就不干了，记住一点，一定要不干，如果你认为自己未来也可以保持这样的收益率，那就完了，之后会全部吐回去的，为什么呢？这个市场的特点就是这样的，那样的机会可能10年里只会出现一两次。赌对了以后应该干什么？收益率翻个几倍后马上分掉，解散公司，退休。 华尔街成功的这些人的履历，应该不会超过我分的这几类，这其实跟人家的市场特点有关系这就是对之前讲到的模型所做的一个简单的展开。 1.7 经济世界观下的债务、杠杆与科技国家与国家之间的分配我们接着这个话题往下聊。 这两个模型涉及的是不同的市场，大家要有针对性的进行考虑。对于我个人而言，参与每个市场的方法是完全不一样的。比如说国内市场，既然已经了解了它的特点，原则上来讲可以做一个分散。第一，我可以去买那种，其实我不是买，更多的是直接当一些投资公司的股东，占一个很小的比例。比如说你是一个比较固执的长期价值投资者，我知道你的特点，在中国证券市场上你能提供给我的应该就是图中的长期斜率的增长，但你不擅长交易，换句话说，你的公司适合长期投资。你的另外一个特点是不会犯大错，你不会挑那些什么都不知道、纯靠交易的公司，但是我也知道你是无法获得超额收益的。所以这就是一个配置问题，左边的那个公司，你投它15%的股份，把你的一部分自有资金交给它长期打理；右手，把剩余的资金打散，举个例子，我可能会把它打散成10份甚至20份，去投很小的交易型的产品或者交易型的基金经理，他们的特点是并不在乎有没有价值，只在乎交易对手，但是这也意味着他们的风险是极大的，有可能今年赚个两三倍，也有可能到明年净值就彻底归到0.1。我要抓住这两种特点，然后做一个搭配。 美国证券市场其实一样，持有长期价值部分的ETF，其实我就是要获得图中黄线代表的投资回报。我左手把持着流动性风险和估值风险这两个风险的时候，我会用其他衍生产品去对冲这部分的头寸，并不需要平掉它。这就是交易，其实也不是交易，因为原则上来讲，到这个维度就已经跳开交易了，更多的应该是配置的一个思考。 关于债务和杠杆的理解，我这里面就不去细讲了，因为基本上达利欧先生已经把所有内容讲得很清楚了。我在这里只是做一点点补充，就是这个债务的问题不能按照传统思路去思考，认为债务和收入达到一定的比值就一定要出问题，而且出了问题以后一定要去出清。如果这样去思考，好像就看不懂中国的情况了。不同的政府、不同的企业、不同的金融框架、不同的居民部分的属性，还有不同的制度，都将决定不同国家的债务在处理的时候会延展出不同的结果。大家可以看到欧洲、日本、美国和中国的债务问题，都是各不相同的，而且在处理方法上也是不一样的。当然，这里面比较差的应该是日本和欧洲，无论是政府部门、企业部门、居民部门，还有货币政策、财政政策，基本上都受限，行政政策也受限，所以当时我说欧洲可能会日本化。但是中国和美国，整体来讲要优于其他国家。中国和美国，目前货币政策、财政政策和行政政策这三大政策的空间，原则上来讲，都比日本和欧洲要多。 世界观的陈述很关键，因为它直接涉及我们全球资产配置的一个考量。换句话说，对于我来讲，毕竟大部分时间参与的是海外市场，所以最重要的实际上就是全球经济一体化背景下分工和分配的结构。这里展示了科技革命的过程，比如说工业革命等等，这其实就是长期增长的斜率部分。但是我认为最重要的实际上是信息技术和全球化的共进。过去30年，我们全球投资路径的主线就是全球经济一体化的正反馈和负向正反馈，以及信息技术革命带来的长期斜率的增长。简单讲，在全球投资路径中，过去几十年我们遵循的核心框架都是这个。第一，如果你长期投资美国证券市场的比如说科技类板块，实际上你获得的就是信息技术时代的红利，因为它是一个成熟市场，所以说它是一个增量，你在获得它带来的收益；第二，你在享受全球经济一体化带来的投资红利，包括中国的经济增长、中国的房地产，以及全球资本的流动，各个国家也会在这个框架中完成国家和国家之间的分配关系。 有人会说我们是悲观者，我觉得不是，我们是思考者。思考什么呢？思考这两个弊端是否都出现问题了。如果是，其实也有可能我们这一代的投资的最好的年代已经结束了。第一，信息技术革命带来的红利是否已经完全释放出来，我们现在是否很难找到下一个技术革命是什么，这是一个问题。第二，全球经济一体化带来的弊端是否在2008年金融危机以后凸显。2002年索罗斯先生写过一本书，叫《索罗斯论全球化》，在那本书中索罗斯先生把未来10年的利讲得非常清楚，中国是得利者。但是同样在那本书里，他点到了全球经济一体化的弊，这个弊就是分工和分配的弊端。当总的蛋糕不能增长的时候，各国的分配就会成为严重的问题。索罗斯先生讲得非常清晰，这个时候民粹主义会滋生。用克鲁格曼的话讲，国家主义才是真正的核心概念，就是每个国家都是为了自己的利益，民粹对峙就会产生。也就是我们说的，分配失衡以后，就会产生社会问题，道理是一样的，放到国家层面，就是国家和国家之间的分配问题。 2008年金融危机之后，全球面临的实际上是蛋糕增量不够的情况下分配失衡的问题。所以说，如果真的进行全球投资，我认为大家应该尽量避免索罗斯先生讲的民粹化的概念，就是我们在思考各大问题的时候，不要带有太强的民粹主义色彩，否则很多问题会有偏差。冷静的去看待这个世界的问题，然后找到自己下一步该干什么就好了。这是我们要关注的两个巨大的问题。 1.8 全球三级化分工框架二战后全球化的分工和分配模型 由此生成的模型，就是我之前跟大家讲得很多的全球三级化分工的框架。换句话说，我们所有的大的全球经济一体化的宏观模型，都是基于这个架构，它适用于几乎所有资产。 这个框架有三个重要的组成部分消费者、生产者、原材料输出国，在之前的《见面》中我已经跟大家解释过。全球的经济增长来自国际化分工，但是跟商品一样，商品价格想要持续上涨靠的不是供给，靠的一定是需求曲线，我们的经济增长，一定是靠生产出来的东西要有人用，要有人消费。 为什么说如果没有债务和杠杆，技术改进对经济效率的提升会非常缓慢？很简单，在效率的提升过程中，如果没有债务和杠杆，总需求曲线的扩张也是呈线性的，但是当金融介入的时候，我们的需求可以一次性释放出来。 看看现在的年轻人就知道了，赚两千块钱，没关系，该买什么买什么。他们的钱从哪来呢？这种借条，那种借条，这种信用卡，那种民间借贷。金融本质上来讲提供的就是“存贷投汇融”这五大金融服务，原则上来讲，就是提供债务和杠杆。 如里你是一个生产者，你的负债将大量的集中在生产部门，也就是企业部门。如里你是一个消费者，你的负债将大量的集中在消费部门，也就是居民部门。换句话说，中国的债务关系变成了生产部门和收入之间的关系，欧美国家的债务关系则是居民部门和收入之间的关系，金融机构在这中间加了杠杆，所以它要承担这个责任。由此大家可以看到，国际分工中的角色的不同导致债务研究的侧重点也就不一样。 原材料输出国也很有意思，比如澳大利亚，你会发现它的生产部门和居民部门都背负着债务，而且两个部门之间是相互牵连的。它既具有美国的属性，又具有中国的属性，所以大家就明白为什么澳大利亚是一个三段式，它一定是生产部门出了问题以后，马上就要牵连到它的居民部门、房地产，因为它没有储蓄去垫底。 这就是我们在整个的这个三级架构中的分工。所以说无论正反馈、负反馈，其实所有的变量都来自外部。外部债务扩张、杠杆扩张的过程中，生成我们的生产、加工、制造，生成我们的对内投资，生成我们的储蓄，生成我们外汇储备的增长，生成我们的货币投放，然后生成我们的利润，然后带动着原材料的需求，这个过程就是整个正反馈的路径。 但是，问题也会随之而来，第一，外部的债务扩张存在着周期性，它加杠杆、收杠杆，对于全球影响非常大。为什么我说2008年到现在，原则上来讲问题还没结束呢？因为2008年之后作为消费者的欧美国家在调结构，所以我们马上面临的就是产能过剩、利润不足、总需求不足，那个时候我们率先根到的办法是说周期调控下保证总需求，启动4万亿计划，由政府部门来扩杠杆，用内部需求抵住外部需求的下滑。 所以说正是因为逆周期调整，才有了那几年中国经济的高速发展。 当然了，澳大利亚或者新西兰那种原材料输出的国家，它们是被动的随着我们走的。这几年大家会发现，对于澳大利亚或新西兰这种处于我们产业链上游的国家，中国的逆周期政策调整对于它的边际效应越来越弱。 所以不难理解很多人会问，我们供给侧改革了，钢铁行业利润恢复了，铁矿石价格也上涨了，为什么澳洲的经济还在变差？很简单，我们进行的调整，第一，不是总需求的调整，如果是类似于2009年、2010年，澳洲是跟着我们一起繁荣的。 但现在并不是，我们不再采用总需求的手段，开始采用供给的手段，开始采用结构性的手段，开始注重结构性的比重，这时候你会发现，外部这些国家就没法得到我们的红利了。这就是这几年我们看到的一个分化的现象，其实都是从全球经济一体化中衍生出来的。 中国不是第一个生产部门的得利者，“二战”之后早期的得利者是德国、日本，然后是亚洲四小龙，然后是中国。现在实际上是有小部分拆分的，举个例子，如果现在越南是国际分工中的生产者，当然越南也有自己的特点，你就应该知道过去的五六年你应该到越南干嘛。当然是实体，不是炒房子。对方的收入还没增长上来，储蓄还没增长上来，你跑去炒房子，拉高房价，负债转给谁？负债的转移一定是基于收入的增长的，大家什么时候见过一个国家，总收入还没有增长起来、总储蓄没有增长起来的情况下就炒房的？ 我记得之前见过一个温州的老板跑到非洲去搞房地产开发，当时我就说你怎么根得那么不明它呢，当地的收入没有增长上来，储蓄没有增长上来，房子卖谁啊。所以，第一步一定是让它收入增长起来，再拿走它的未来时间价值。所以说第一步一定是生产加工制造，对于任何国家都是这样，先做生产加工制造，再做产业链投资，储蓄增厚了以后再做房地产，然后再干金融，最后撤出去。当年的亚洲四小龙基本上就是这样的路径。 在这个框架下，就形成了我们的反馈机制，一个中长期的资产配置和投资路径也就在这个基础上产生了。早在我写《十年大宗背后那些不为人知的故事》的时候，我就提到了一个非常重要的因素一-欧美金融监管的放松，包括英国在内，我都会讲到它的金融政策和金融监管，因为没有这个口子，就不存在债务扩张的基础。 所以大家就知道，全世界说到底，还是一小部分制定政策的人决定了我们这个机器的引擎能否运转起来。 1.9 分工与分配的最大问题分蛋糕游戏 很多国内的学者，包括社科院的余永定，余老都研究过全球经济一体化下的分工、分配问题。生产国和消费国之间存在着严重的问题，首先，在初期的时候，消费国依赖于过度的消费拉动全球的经济增长，简单讲，就是经济增长越高，内部的消费就会越过度，而且还会造成一个现象一内部的收入和贫富差距会拉大。 全球经济一体化的弊端就是产业迁移带来的失衡，非常有意思。一个社会是分层的，所以并不像教科书上讲的，全球化分工、分配，你干高端的，把低端的扔给别人干就行了，这仅仅停留在理论上。在现实世界中，任何一个国家都存在着高、中、低的分工，所以当发达国家把所有的低端产业全部迁移到中国的时候，它会面临一个巨大的问题：原来承担低端生产加工制造的这部分人怎么办？有人说得很简单，让他们升级。请问如果一个人干了一辈子汽修，干到三四十岁了，突然间告诉他越南的工人比他便宜，然后让他去升级换代，去写代码，大家觉得可能吗？大国内部的收入分配问题会在全球经济一体化进程中随着时间的推移越来越突出。 大家可以想想美国的铁锈区，英国的纽卡斯尔、谢菲尔德，以及长桥工厂，这些传统生产加工制造业大量迁移到中国以后，原本从事这部分工作的人的收入在过去十几年是没有增长的。但是随着债务、杠杆、金融服务性行业的扩张，华尔街开始赚得盆满钵满，伦敦金融城赚得盆满钵满大伦敦地区的富人赚得盆满钵满，贫富差距越来越大。这中间有一个最重要的资产价格会被抬高，那就是土地和房子的价格。西方虽然有社会福利保障体系，但是房地产并不包含在这个分配机制内。中国的两种分配机制，原则上来讲，都不足以满足底层人民的需求。 大家可以试想，如果我们的底层生产加工制造业被东南亚国家全部拿走，我们又没有顺利的完成产业的大幅度升级，升级到能够让这部分人都能够完成转型，我只能告诉你，你在上海是一个世界，出了上海是另外一个世界，我们也会出现类似于英国和美国的这种差异。 这个矛盾出现以后，西方的问题就暴露出来了。民选制度下是选票说了算，虽然说少部分人富裕，大部分人贫穷，但这个时候你会发现，政客就会利用这样的一个制度，只要他打着民粹的旗号，只要喊出让就业回来、让工资回来、让民众的生活好起来、被中国拿走的让它吐回来的口号，放心，选票就回来了。所以特朗普的上台、英国的退欧，包括将来欧洲内部可能会出现的分崩，一切都是意料之内的事情。 但是对于中国来讲，我们作为生产国，和消费国之间的矛盾就出现了。真正完美的分工是什么？完美的分工是没有过度的消费，也没有过度的储蓄，双方之间没有竞争。举个例子，我开一个餐厅，你开一个洗脚房，你晚上到我这来吃饭，我拿着钱又去你那洗了脚，财富只是我们中间的-个媒介。但是过度的储蓄和消费都会破坏这样一个经济体的平衡。我把父母留给我的钱都花掉了，都去你那按脚了，你自己在家做饭，这个游戏怎么玩？换句话说，你开始储蓄了，我过度消费了，财富分配就失衡了。 全球经济一体化并没有实现完美的分工，所以过去十几二十年，我们是日子越过越好，但是欧美的问题是过度的负债，压力越来越大，而随着资产价格的传导，底层人民的收入无法填补负债，这个时候大家会发现民怨开始增加，要靠另外一种方式进行全球再平衡了。所以说全球经济一体化的弊端在这个维度上就开始暴露。 第二，中国的成长。我们以这种模式高速增长的结果是什么？结果就是所有赚钱的我们都想拿过来。于是就产生了一个大问题：别人怎么办？两个国家都存在着阶层的分配，都存在着债务和收入之间的关系，如果两个国家的总收入不增长的话，你的收入增长将必然对应着对方收入的减少，对方收入的减少和它居高不下的债务一定会生成社会问题，社会问题会推着民选政府，民选政府会推着政治和政策的变动。 举个例子，芯片，从爱国主义的角度来讲，我特别希望中国能够强大，但从另外一个维度上来讲，如果整个芯片技术的瓶颈取得突破，等到我们做得越来越多、什么都能干的时候，我的交易策略就非常简单，做空台湾、做空韩国就可以了，因为你的好必然是它的差。你假设的条件是你拿走的只是它不要的，但如果你拿走的是它总收入的核心部分的话，它的负债就会成为巨大的雷，这就是我们的关系。换句话说，只有总蛋糕不停的增长，我们才具备分配的基础，否则就不是合理的、和平的分配，我们将会处在一个对峙的分配状态下，你多必然是我少，你赢必然是我输，零和博弈。这其实是现在全球经济一体化面临的最大的一个问题，它在阻断全球经济一体化的进程。 1.10 全球经济的核心矛盾三大失衡 如果把生产国和消费国的债务、收入放在一起，我们就不难看出，这两类国家的分配方式和机制是不一样的。 如果一个国家在国际分工中得到的是经常项目顺差，也就是通过生产加工制造出口的话，它的分配机制是自下而上的税赋式分配，比如老百姓获得了100块钱，国家通过税收收他20，通过卖地、盖房子收他20，通过其他途径再收他20，没关系，他仍然高兴，因为总收入在增长。 但是，对于靠资本和债务扩张的这些经济体来说，问题就大了。比如有人说，在全球经济一体化进程中，美国的华尔街也好，大公司也好，都获得了巨额的利润。没错，它们是获得了巨额的利润，但是分配就有问题了。美国的大公司，真正拿走几千亿利润的是谁？大股东、二股东、三股东、投资人，还有一少部分成为中高层管理者的员工，他们拿走了大部分的奖金、工资，跟华尔街一样。 但是底层呢？举个例子，美国麦当劳的工资增长速度是多少？麦当劳赚了那么多钱，股价涨了那么多，跟店里的员工有什么关系？但是如果他们居住的地区，房价从15万美元涨价到30万美元，工资却没有增长一倍，他们的生活压力就加大了。 消费国的分配方式是自上而下的，小部分人拿走大部分钱以后，通过社会福利保障体系去支撑底层。这种分配方式最大的问题是，当底层的收入完全被拿走以后，矛头就会直接针对拿走大部分钱的那些人。这就是全球经济一体化在分配上造成的问题。 这个一讲完，其实大家在网上看很多分析的时候，马上就知道他讲的那个点为什么不对、他忽略了一些什么东西，这并不复杂，但这确实是现在影响我们的一个很大的问题。所以我们的初步判断是全球经济一体化已经结束了。 逆一体化，准确的说叫区域经济一体化，各国之间竞争关系的加剧，应该是主导全球框架的一个路径。而且由于各个国家在分工体系内的角色不同，影响要素就完全不同，如果对内的调控手段也比较薄弱，这些国家未来的发展并不会特别好。 所以日本化将蔓延到大部分的国家，像欧洲、澳大利亚、新西兰、加拿大，谁的要素越缺失，谁越依赖于外部，谁的结构矛盾就可能越突出，既然外部环境是刚才我定性的那个样子，矛盾的化解就将是一个较长周期的过程。 这是在刚才那张图的基础上稍微完善了一下，把债务、杠杆、经常项目顺差、资本项目顺差、资本流动和盈利都罗列了出来。在这个过程中很多大类资产之间的关系其实就生成了，比如说汇率关系、利率关系、通胀关系，其实都是经济一体化的结果。 生产国是处在被剥削阶层的，所以大家应该明白为什么美国以前买中国制造的东西很便宜。换句话说，生产国的经济是过热的，它的内生性循环从外部的经常项目顺差到资本项目顺差，到国内的加杠杆行为，再到国内的投资带动资产价格增长、带动储蓄增长，所以本国的利率和通胀都是高的。 所以说货币政策能够刺激经济增长，这句话我认为是伪命题。准确的说，是结构、分工、分配决定了经济增长。那个时候中国的利率水平很高，经济该增长的增长。再比如现在的越南，越南的民间借贷成本是17%、18%，很正常，大家再去看看银行的储蓄成本是多少、放贷成本是多少，经济该增长的照样增长。谁告诉你高息一定会抑制经济增长？ 如果一国的需求不来自内生，结构、分工不来自内生，都是外部力量给予的，很简单，它的经济一定是过热的。在这个过程中，大家会发现利差会推动资本项目的流动，资本会涌向生产国，生产国的实体部分投资回报率很高，所以双顺差或者单顺差就出现了。利率高，本币升值，相对来讲美元就是贬值的。 全球失衡的背后所以大家会发现，全球经济一体化分配下，美元相对来讲在好的时候一定是贬值状态。并不是说美国要贬值，而是因为生产国的利差高。分工决定了我们的利率、通胀，收入决定了我们的投资和杠杆，这就是我们整个状态的正反馈路径。 消费国靠资本项目维持债务、杠杆、收入和分配生产国靠双顺差维持，所以它就要牺牲劳动价值，所以说生产国的产品出口价格是偏低的。消费国大量讲口生产国的商品，所以消费国的通胀是偏低的，货币政策就会压在低端。 越低的利率越会刺激消费国总需求的扩张，消费国的总需求扩张又会转化成生产国的对外总需求，然后转化成生产国的生产、加工、制造、投资，生产国的经济就会过热，从生产的过热到资产价格的过热，利率水平就会更高，这个时候资本会继续涌进去套利，但是会从简单的实体投资转化成资产的投资。 这个时候，生产国对内就开始失衡，资产价格越高，实体投资回报率越低；实体投资回报率越低，本国的投资就会越倾向于虚拟性的资产，也就是包括房产在内的这些金融性资产，金融性资产的投资回报率高，本国就会跨过实体部分进入债务部分，进入杠杆部分。这张图跟前面那张图可以完整的对在一起，如果能做动画片的话，大家就会明白整个路径的传导。 生产国的债务增加、贫富差距拉大、资产价格抬升，最后会促使底层人民对总收入的要求增加，简单讲，就是我要加薪，我要更好的劳动待遇，劳动力成本的抬升会使得传统生产加工制造的实体部分外迁，这就叫经济一体化的第二次转移分工。前面几轮的生产国全部是小国，比如韩国、日本，日本产业一外迁，资产价格肯定跟不上了，没关系，技术、储备、人才，对外投资，它马上转化成了一个这样的角色。 但是中国的问题，也就是全球经济一体化现在面临的问题是，中国是一个超级生产国，我们的人口基数、对内贫富、分配，这个调整周期会非常长。面临的问题不仅仅是外迁，你不能够外迁。大家想想看，我们所有人都去干高精专，那是不可能的，大部分底层人民就会陷入我们之前提到的美国底层人民的状态，债务和收入之间不匹配，而且很难获得收入，因为你没法去跟东南亚、欧洲竞争了。你需要一代或者两代人才能够完成向中产、中高产和白领的转化。 大家有没有想过，十几亿人口全部转化成白领是个什么状态，你有多少的研发工作、服务性的工作能够去吸纳十几亿人口？没有制造业，问题就大了，唯一的方法就是低端被拿走，升级高端，而高端制造业将直接面临如果你这十几亿人口做了，德国人怎么办、英国人怎么办、欧洲人怎么办。这就是现在我们在这个框架中面临的所有问题。","link":"/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E4%BB%98%E9%B9%8F-%E7%BB%8F%E6%B5%8E%E4%B8%96%E7%95%8C%E8%A7%82-%E5%85%A8%E6%96%87/"}],"tags":[{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"2021","slug":"2021","link":"/tags/2021/"},{"name":"redis 进阶","slug":"redis-进阶","link":"/tags/redis-%E8%BF%9B%E9%98%B6/"},{"name":"mac","slug":"mac","link":"/tags/mac/"},{"name":"terminal","slug":"terminal","link":"/tags/terminal/"},{"name":"java","slug":"java","link":"/tags/java/"},{"name":"2020","slug":"2020","link":"/tags/2020/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"reading","slug":"reading","link":"/tags/reading/"},{"name":"license","slug":"license","link":"/tags/license/"},{"name":"economy","slug":"economy","link":"/tags/economy/"},{"name":"life","slug":"life","link":"/tags/life/"},{"name":"memory","slug":"memory","link":"/tags/memory/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"time management","slug":"time-management","link":"/tags/time-management/"},{"name":"future","slug":"future","link":"/tags/future/"}],"categories":[{"name":"知识体系","slug":"知识体系","link":"/categories/%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"感悟","slug":"感悟","link":"/categories/%E6%84%9F%E6%82%9F/"}]}